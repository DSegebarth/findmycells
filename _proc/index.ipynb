{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: An end-to-end bioimage analysis pipeline with state-of-the-art image\n",
    "  feature segmentation tools for non-coding experts\n",
    "output-file: index.html\n",
    "title: findmycells\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hi there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> \n",
    "    <img src=\"https://github.com/Defense-Circuits-Lab/findmycells/blob/main/media/findmycells_logo_low_res.png?raw=true\" style=\"float:right;width:300px;\">\n",
    "    <font size=\"3\">\n",
    "    Over the past years, deep-learning-based tools have become increasingly popular and abundant, particularly in the image processing domain. In fact, even the image shown next to this text was created by such a tool - with nothing but a few keywords as input (go checkout <a href=\"https://starryai.com/\">starryai</a>). Similarly, deep-learning-based image analysis tools also have a growing impact on biomedical research. However, such deep-learning-powered scientific software tools are rarely as user-friendly as starryai (or <a href=\"http://www.mackenziemathislab.org/deeplabcut\">DeepLabCut</a>, to name at least one positive exception). And make no mistake, also <i>findmycells</i> will not be able to make such a giant leap forward. Instead, it was developed to narrow the gap by bringing state-of-the-art deep-learning-based bioimage analysis tools to users with little or even no coding experience. This is achieved, as it integrates them in a full end-to-end bioimage analysis pipeline that comes with an intuitive and interactive graphical user interface that runs directly in Jupyter Notebooks. But enough introduction - please feel free to test it yourself! Either follow the installation instructions below, or head over for instance to the <a href=\"https://defense-circuits-lab.github.io/findmycells/tutorials/gui_tutorial.html\">GUI tutorial</a> to get a first impression! \n",
    "    </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*findmycells* is currently only available via pip. Also, please be aware that *findmycells* was so far only tested in a Linux subsystem run under Windows (Ubuntu 20.04.5 in WSL2 on both Windows 10 and Windows 11). Moreover, having a CUDA-capable GPU is highly recommended when using [deepflash2](https://github.com/matjesg/deepflash2) or [cellpose](https://github.com/MouseLand/cellpose) for the segmentation of your images. For local installation, please follow the steps below:\n",
    "\n",
    "We highly recommend that you use [Anaconda](https://www.anaconda.com/products/distribution). In your terminal (command line, or Anaconda Prompt), run the following line to create a new conda environment, called \"findmycells\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> conda create -n findmycells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the environment is created, activate it as suggested by conda by running:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> conda activate findmycells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see `(findmycells)` at the beginning of the line. Continue by installing pip:\n",
    "\n",
    "> conda install pip\n",
    "\n",
    "Once the installations are done, all you need to do is run:\n",
    "\n",
    "> pip install findmycells\n",
    "\n",
    "And all required packages should come with it.\n",
    "\n",
    "\n",
    "## Confirming that your GPU is accessible:\n",
    "\n",
    "If you would like to use your GPU (again: using a GPU is highly recommended, if you want to use the integrated segmentation tools deepflash2 and cellpose), you can test whether it is accessible for python by running the following commands again in the terminal (with the findmycells environment still activated):\n",
    "\n",
    "> python\n",
    "\n",
    "This will now launch a python interface right in your terminal. Now continue with importing torch:\n",
    "\n",
    "> import torch\n",
    "\n",
    "As soon as torch is imported, you can check for GPU accessability by running:\n",
    "\n",
    "> torch.cuda.is_available()\n",
    "\n",
    "This will now output either `True` (whoop whoop - everything is working - well done!) or `False` ( :( ). In case you have a local CUDA-capable GPU installed & you still got a `False`, confirm that you have the latest GPU driver installed, and that you are using the latest available Windows, WSL2, and Linux builds. If you're still not able to access the GPU, it may sometimes help to start by installing pytorch first (mix & match the correct versions for you [here](https://pytorch.org/get-started/locally/)), and to first confirm that the GPU is indeed accessible. If it is, you can now continue with the installation of findmycells & hope that nothing breaks! Fingers crossed, that you can find a version that satisfies your local requirements & also those of deepflash2 & cellpose!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For developers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This package is developed using [nbdev](https://nbdev.fast.ai/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
