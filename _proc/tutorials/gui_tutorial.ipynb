{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: How to use the GUI of *findmycells*\n",
    "output-file: gui_tutorial.html\n",
    "title: GUI tutorial\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26853a18-5579-437d-8e86-0d20be4a3663",
   "metadata": {},
   "source": [
    "## Launching the GUI:\n",
    "\n",
    "The GUI of *findmycells* is intended to be used by users with limited python programming expertise. Therefore, launching the GUI is kept as simple as possible. All you need to do is run the following two lines of code in a Jupyter Notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3fad3e-fe79-4868-8c3e-3f7cff3a8361",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e878b387d0543ec939317b4a66c1e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<br><br><div style=\"font-size: 26px\" align=\"center\"><b>Welcome to <i>findmycells</i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from findmycells.interfaces import launch_gui\n",
    "launch_gui()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f881cf-496d-49b6-b12a-9d0f74629cbe",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "\n",
    "This tutorial uses the *findmycells* sample dataset for the most part. If you want to recreate the same steps on your local machine, feel free to download the sample dataset (including images, ROI files, and a trained model ensemble), which is hosted on [Zenodo](https://zenodo.org/record/7655292#.Y_Nw0B-ZNhE). Checkout the \"Download the full sample dataset\" section below for how and where you can download it.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99faa5ad-631d-49c6-a08d-6855a7cc520c",
   "metadata": {},
   "source": [
    "## The individual steps of creating and running a *findmycells* project:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fab3b3-4dfc-4b81-adae-a06f1d890dd3",
   "metadata": {},
   "source": [
    "### 1) Start a project:\n",
    "\n",
    "You can start a project either in an completely empty directory (*findmycells* will then automatically create all subdirectories that are required), or with an already existing subdirectory structure. Here, we will start completely from scratch in an empty directory:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cf26de-1152-45f6-9b26-c56c578d328e",
   "metadata": {},
   "source": [
    "![gui_launch_project](https://github.com/Defense-Circuits-Lab/findmycells/blob/major_refactoring/media/gui_launch_project.gif?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f8c3bc-f13e-4fdc-9b44-909cd7f4291d",
   "metadata": {},
   "source": [
    "### 2) Add all your data\n",
    "\n",
    "Now, please grab some snacks, as the following piece of information is quite important, but unfortunately also quite a bit to read - bare with us!\n",
    "\n",
    "Before we can continue with our project in the GUI, we first have to add all our data to the project. This needs to be done by adding the image data in a very specific structure to the \"microscopy_images\" subdirectory. This structure consists of three subdirectory levels that correspond to different metadata information of your experiment: \n",
    "\n",
    "- 1st level: main group IDs\n",
    "- 2nd level: subgroup IDs\n",
    "- 3rd level: subject IDs\n",
    "\n",
    "Simply start by creating one folder for each of your main experimental groups (for instance \"wildtype\" and \"transgenic\", not limited to any specific number) inside of the \"microscopy_images\" subdirectory. Now, into each of these main group folders, you have to add a folder for each experimental subgroup within this main group. This can be for instance different timepoints (e.g. \"week_01\" and \"week_04\"; again, not limited to any number). However, this may of course not be applicable for all experimental designs. Sometimes, you may simply not have any subgroups within your main groups. Nevertheless, this subdirectory level is **required**. In such a case, simply add a single directory and feel free to give it any name (note, that also in the sample dataset, there will only be a single subgroup ID folder). Finally, in each of these subgroup folders, please create a folder for each experimental subject from which you acquired the image data (unique IDs required!). Into each of these subject ID folders, you can now add all corresponding image files. Phew - done!\n",
    "\n",
    "Please have a look a the following tree to see an example of how this could look like. Note, that there is no specific number of images required in each of the subject folders, that the images in the different subject folders can even have the same names, and that subject IDs have to be unique. Obviously, subject folders places inside the \"wildtypes\" main groub directory, are consequently considered to belong to this main group (and likewise to the respective subgroup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ea6ff2-db91-4fd0-8c89-cdf9c217ce69",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_root_dir:\n",
      "│ \n",
      "└── microscopy_images:\n",
      "    │ \n",
      "    ├── wildtypes:\n",
      "    │   ├── week_01:\n",
      "    │   │   ├── mouse_01:\n",
      "    │   │   │   └── image_01.png\n",
      "    │   │   │   └── image_02.png\n",
      "    │   │   └── mouse_02:\n",
      "    │   │       └── image_01.png\n",
      "    │   │       └── image_02.png\n",
      "    │   │       └── image_04.png\n",
      "    │   └── week_04:\n",
      "    │       └── mouse_03:\n",
      "    │           └── image_08.png\n",
      "    │ \n",
      "    └── transgenics:\n",
      "        ├── week_01:\n",
      "        │   ├── mouse_04:\n",
      "        │   │   └── image_01.png\n",
      "        │   │   └── image_05.png\n",
      "        │   └── mouse_05:\n",
      "        │       └── image_01.png\n",
      "        │       └── image_02.png\n",
      "        └── week_04:\n",
      "            ├── mouse_06:\n",
      "            │   └── image_01.png\n",
      "            │   └── image_02.png\n",
      "            │   └── image_03.png\n",
      "            └── mouse_07:\n",
      "                └── image_01.png\n",
      "                └── image_08.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#|echo: false\n",
    "print(('project_root_dir:\\n'\n",
    "       '│ \\n'\n",
    "       '└── microscopy_images:\\n'\n",
    "       '    │ \\n'\n",
    "       '    ├── wildtypes:\\n'\n",
    "       '    │   ├── week_01:\\n'\n",
    "       '    │   │   ├── mouse_01:\\n'\n",
    "       '    │   │   │   └── image_01.png\\n'\n",
    "       '    │   │   │   └── image_02.png\\n'\n",
    "       '    │   │   └── mouse_02:\\n'\n",
    "       '    │   │       └── image_01.png\\n'\n",
    "       '    │   │       └── image_02.png\\n'\n",
    "       '    │   │       └── image_04.png\\n'\n",
    "       '    │   └── week_04:\\n'     \n",
    "       '    │       └── mouse_03:\\n'\n",
    "       '    │           └── image_08.png\\n'\n",
    "       '    │ \\n'\n",
    "       '    └── transgenics:\\n'\n",
    "       '        ├── week_01:\\n'\n",
    "       '        │   ├── mouse_04:\\n'\n",
    "       '        │   │   └── image_01.png\\n'\n",
    "       '        │   │   └── image_05.png\\n'\n",
    "       '        │   └── mouse_05:\\n'\n",
    "       '        │       └── image_01.png\\n'\n",
    "       '        │       └── image_02.png\\n'\n",
    "       '        └── week_04:\\n'     \n",
    "       '            ├── mouse_06:\\n'\n",
    "       '            │   └── image_01.png\\n'\n",
    "       '            │   └── image_02.png\\n'\n",
    "       '            │   └── image_03.png\\n'\n",
    "       '            └── mouse_07:\\n'\n",
    "       '                └── image_01.png\\n'\n",
    "       '                └── image_08.png\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96e28cd-7222-4db0-8d02-6a723817c3c7",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "\n",
    "You will always be able to update the files that are associated with your project. So, for instance, you can already start with an intial subset of your image data and keep on adding files later on to the same project, if you aquire more data along the way!\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a027a5-0d6b-4932-9b4a-a9e710f64a2a",
   "metadata": {},
   "source": [
    "You also have the chance to investigate only specific regions of your images. This can speed up computation times and reduce memory load, but might also add more specificity to the insights you can derive from your image analyses. In *findmycells*, this can be done by providing a ROI file associated to each microscopy image. To do this, simply copy the exact same directory structure you just created for your images and copy-paste it into the \"rois_to_analyze\" subdirectory. Now replace each image file with a ROI file (see below for how you can & should create these), **while that the ROI-file has the exact same filename as the corresponding image**. For instance, for the image with the filepath:\n",
    "\n",
    "project_root_dir/**microscopy_images**/wildtypes/week_01/mouse_01/**image_01.png**\n",
    "\n",
    "The ROI file should be named & placed like this:\n",
    "\n",
    "project_root_dir/**rois_to_analyze**/wildtypes/week_01/mouse_01/**image_01.zip**\n",
    "\n",
    "Currently, only ROI-Sets created with ImageJ are fully supported (and highly recommended). Please have a look at the following gif, to see how you can easily create such a ROI-Set:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5d6065-e3cc-4801-9248-17f73c4a8251",
   "metadata": {},
   "source": [
    "~~ to be recorded ~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3927d588-039e-4db8-b73d-1495ea8d53d0",
   "metadata": {},
   "source": [
    ":::{.callout-important}\n",
    "\n",
    "To ensure full functionality of *findmycells* it is highly recommended to provide a ROI-Set (.zip file!) created with ImageJ for each of your images, in which you renamed all individual ROIs accordingly (see gif above). This is true **even if you only want to analyze a single area** in an image, as ImageJ does not support to rename the ROI to anything different than the filename. However, since the filenames are used to match ROI-files with the corresponding images - this causes inconsistencies. Thus, even if you only want to analyze a single area in an image, simply add a second ROI (can for instance be small and placed anywhere inside the actual ROI) and rename it to something that does not match with your actual area IDs (like \"not_a_real_area\").\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed069525-ae65-4174-9469-4eca8e4540e8",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "This structure may be complicated to grasp at the beginning. Therefore, please feel free to check out our sample dataset and compare the directories, filenames, images, and corresponding ROI files. Even if you don't want to download the full dataset, you can also just browse through it in our GitHub repository [here](https://github.com/Defense-Circuits-Lab/findmycells/tree/main/test_data/cfos_fmc_test_project).\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f980dca-2605-4914-b382-2dfae27a3c42",
   "metadata": {},
   "source": [
    "### 3) Import all metadata information into your project\n",
    "\n",
    "*findmycells* creates and maintaines a database for you that keeps track of all your files & how (and when) you processed them. Once you placed all image files (and, optionally, all associated ROI files) in the corresponding subdirectory trees, your good to go & can use the \"update project files\" button. *findmycells* will now confirm that your file structure is indeed as expected and will then infer all the relevant metadata information. Note: the actual image or ROI data will not be loaded into memory at this moment. If successfull, you should now see a table that lists the detected files with the inferred metadata information:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcd96be-5589-43cf-a4d1-8a061903586b",
   "metadata": {},
   "source": [
    "![gui_import_metadata](https://github.com/Defense-Circuits-Lab/findmycells/blob/major_refactoring/media/gui_import_data.gif?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064e20be-08d7-41a1-b5ed-5a521ddc86e9",
   "metadata": {},
   "source": [
    "### 4) Specifying how to import image & ROI files:\n",
    "\n",
    "Next, you have the option to specify how the image data and the ROI files shall be imported in the \"data import settings\" tab, still on the settings page. Since this time it's really about how these data will be loaded into memory, it may make sense to limit everything right away only to a certain color channel or only to a few specific planes, in case you're working with a z-stack. However, this is entirely up to you & you can also play around a bit and try different options until you found the perfect settings for you. Please remember to click on the \"confirm settings\" button for both, the Microscopy images **and** the ROI files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e607cdb-d28e-4e73-af0e-47083fef588e",
   "metadata": {},
   "source": [
    "![gui_data_reader_settings](https://github.com/Defense-Circuits-Lab/findmycells/blob/major_refactoring/media/gui_data_import_settings.gif?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10f4cb3-c9b3-4d03-9060-5074b6a19105",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "To *preview* whether the selected data import settings meet your expectations, you can simply continue with the preprocessing of your images (see the next section below) on a limited number of files and then confirm that the created preprocessed images in the \"preprocessed_images\" subdirectory match your expectations. If not, simply return to this widget, adjust some of the values & re-run the preprocessing (remember to check \"overwrite previously processed files\").\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a719216-ab2d-4e03-895c-87cbfd96b232",
   "metadata": {},
   "source": [
    "### 5) Preprocessing of your data:\n",
    "\n",
    "Now you finally made it to the core part of *findmycells* - the processing of your image data. All of the following processing pages (i.e. \"preprocessing\", \"segmentation\", \"postprocessing\", and \"quantification\") will look very similar to each other and, therefore, also work very similarly. Thus, let's discuss the preprocessing page in great details, and then go through the other pages a littler quicker.\n",
    "\n",
    "#### a) Select a processing method:\n",
    "\n",
    "For all processing steps, you will be prompted to select one (or several) of the available processing methods. These resemble different options how your data gets processed. On each processing page, you will have a so-called accordion widget that you can expand by clicking on it to reveal its content. In the expanded accordion, you will see a dropdown menu that lists all available processing methods for the respective processing step. For preprocessing, these include for instance \"Convert into 8-bit format\", \"Adjust brightness and contrast\", or \"Maximum intensity projection\". Once you select a option, a more detailed description of this method will appear below, alongside some additional customization options (if applicable). To include a processing method in your project, select it in the dropdown menu, adjust the customizable settings, and then click the \"confirm selection & export configurations\" button. This will then cause the accordion to collapse again and to create a second accordion. The first accordion will now display the name of the processing method you selected. You can always click on it to expand it's content again & use the \"remove method\" button to remove it from the list of processing methods again, in case you changed your mind. Feel free to add as many processing methods as you like, but please be aware that they will be executed in the order that you selected them in (i.e. in which they are displayed to you - top to bottom)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f41308b-9f4f-4e0a-a3ed-3d94e5d91ed5",
   "metadata": {},
   "source": [
    "![gui_preprocessing_strats](https://github.com/Defense-Circuits-Lab/findmycells/blob/major_refactoring/media/gui_processing_strats_selection.gif?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c4b1ea-5344-4bf3-9281-8508313b04b7",
   "metadata": {},
   "source": [
    ":::{.callout-important}\n",
    "\n",
    "Currently, *findmycells* evolves entirely arround deepflash2 and cellpose as segmentation tools. While this may change in future versions, it is strongly recommended to run the \"Convert into 8-bit format\" as last preprocessing method, to ensure full compatibility with these tools.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc33856d-cb77-4c69-a6b9-0eddd883e8d1",
   "metadata": {},
   "source": [
    "#### b) Customize general processing settings:\n",
    "\n",
    "Once you are happy with the selection of processing methods, you need to confirm some general processing configurations. These include, for instance whether *findmycells* should try to save the progress of your project as soon & wherever possible (autosave progress after each file), or whether files that you may have processed earlier already shall be overwritten or skipped. Please click the \"confirm & export configurations\" button to fix your current selection. In case you'd like to change anything again - use the \"refine configurations\" button to make the widgets interactive again. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78ed728-1ce0-4338-ae01-5ef80124bcd8",
   "metadata": {},
   "source": [
    "![gui_preprocessing_configs](https://github.com/Defense-Circuits-Lab/findmycells/blob/major_refactoring/media/gui_processing_configs.gif?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38699ba-12d8-42e4-9478-6d2d5a075185",
   "metadata": {},
   "source": [
    "#### c) Select files to process & launch processing step:\n",
    "\n",
    "The last thing that remains to do is to specify the range of file IDs you'd like to process. By default, all files will be selected. Feel free to had back to the \"project files\" tab on the \"settings\" page, to take a look at the overview table that shows what file ID refers to which of your original files. When you're ready - it's finally time to hit that \"launch processing\" button!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2633121e-66fc-4844-a3db-1c5cccea0864",
   "metadata": {},
   "source": [
    "![gui_run_preprocessing](https://github.com/Defense-Circuits-Lab/findmycells/blob/major_refactoring/media/gui_preprocessing_run.gif?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d7254b-2249-4307-bbd9-408edc37358c",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "You will find the preprocessed images in the \"preprocessed_images\" subdirectory. We highly recommend to confirm that they all look as expected, before you continue with the following, more time consuming processing steps.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404104f2-afec-4e99-8331-b5dd49e79a75",
   "metadata": {},
   "source": [
    "### 6) Segmentation of your data:\n",
    "\n",
    "You will need to specify the path to the directory of where the corresponding trained models of the deepflash2 model ensemble can be found. Remember, they have to be compatible with the version 0.1.7 of deepflash2. Feel free to store them in your project root directory, to have them always clearly associated with this project - or to load them from a directory outside of your project root. For now, you only have the options to create semantic segmentations only (by using deepflash2 alone), or to create instance segmentations derived from these semantic segmentations (by using cellpose after deepflash2). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ddff4e-48b0-434b-ac6b-8ce135e75828",
   "metadata": {},
   "source": [
    ":::{.callout-important}\n",
    "\n",
    "If you want to create instance segmentations, you will need to either finish semantic segmentations of all files first, or to specify a diameter that cellpose is supposed to use. Why? Well, cellpose tries to separate touching features based on flow gradients that rely on an estimated mean diameter of these features. This diameter can be estimated by cellpose (recommended - just leave the \"diameter\" slider at 0), or be provided by you. However, if you want cellpose to compute it, it will require all semantic segmentations first, to make the estimate as accurate as possible.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f92e528-e38a-4e80-9c13-79bfd9dcce22",
   "metadata": {},
   "source": [
    "![gui_segmentation](https://github.com/Defense-Circuits-Lab/findmycells/blob/major_refactoring/media/gui_segmentation.gif?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeff52a6-c871-4019-a37c-25c1f48e8944",
   "metadata": {},
   "source": [
    "### 7) Postprocessing:\n",
    "\n",
    "Once you managed to get all segmentations, you're almost done! Next up, you can run some post-processing on the segmentation masks, for instance applying exclusion criteria to filter for clearly biological relevant & meaningful features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267e3830-4a81-4f9b-9623-e4a9f75e1c67",
   "metadata": {},
   "source": [
    "![gui_postprocessing](https://github.com/Defense-Circuits-Lab/findmycells/blob/major_refactoring/media/gui_postprocessing.gif?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f71e982-e0bd-4aec-b313-62be4030ee2b",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "\n",
    "In case you are working with a 3D (2.5D) dataset and created instance segmentations, you also have the option to re-construct the features in 3D by running the \"Reconstruct features in 3D\" method. This method also needs to be run before applying exclusion criteria. \n",
    "\n",
    "If you don't run this strategy, the instance labels will most likely not be matching across the individual planes.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197872d0-e89a-4d36-8d4c-7bf1b481bf5a",
   "metadata": {},
   "source": [
    "### 8) Quantification:\n",
    "\n",
    "Not much to say here - runs the quantification of the detected features in your postprocessed segmentation masks per area."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4561ce74-3c87-4ce2-8fd3-cef9befb93d2",
   "metadata": {},
   "source": [
    "### 9) Inspection:\n",
    "\n",
    "The GUI of *findmycells* also comes with some in-built functions that allow you to create interactive plots to take a very close look at how the final, postprocessed and ultimately quantified segmentations look like. For this, head over to the \"inspection\" page & chose one of two inspection methods: 2D or 3D. You can also run 3D inspection on a 2D dataset and 2D inspection, on a 3D dataset - but usually 2D inspection on 2D data, and 3D inspection of 3D data, makes most sense. \n",
    "\n",
    "After selecting a file ID, the area ID, and which plane(s) should be included in the plot, you will be prompted with some additional configuration options. Since the images used in *findmycells* are usually quite large, the inspection plot will be focused only on a particular section of the image. You can use the customization widgets to specify how big this section should be, and where it should be centered. Among these widgets, you will find three features that support you in your selection process. You can either open an interactive plot that allows you to zoom in and and out of the image-mask-overlay, while displaying the exact pixel coordinate of where your cursor is pointing in the bottom right corner. Alternatively, you can also select one of the unique IDs of the detected features in this image from the dropdown menu. Upon selection, the coordinates of this features centroid will be computed and printed to the right of the dropdown menu. In case of a 3D dataset in which you run the \"Reconstruct features in 3D\" postprocessing method, you might also have some feature IDs listed in the \"multi-match-traceback\" dropdown menu. These features were found to partially overlap also with other features and, hence, might be of particular interest to take a closer look at. \n",
    "\n",
    "The following gif shows you the inspection of the 2D data in the cfos_fmc_test_project sample dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1262dab-af3b-4754-a98a-6b43ba38029b",
   "metadata": {},
   "source": [
    "![gui_inspect_2d](https://github.com/Defense-Circuits-Lab/findmycells/blob/major_refactoring/media/gui_inspect_2d.gif?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b49b731-da0a-4635-9eb5-1b23c0e066ff",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "You can also save the current view of the interactive plots that open in a separate window, if you'd like to! Simply use the little save icon in the bottom left corner.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b970b2aa-444c-46b8-af1e-577928a7ee00",
   "metadata": {},
   "source": [
    "While processing of 3D (2.5D) datasets works just as demonstrated for the 2D sample dataset shown above, let's have a look at a more interesting 3D inspection plot below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec9e72f-ae56-40be-9702-820eb4024de1",
   "metadata": {},
   "source": [
    "![gui_inspect_3d](https://github.com/Defense-Circuits-Lab/findmycells/blob/major_refactoring/media/gui_inspect_3d.gif?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eae5c97-b55e-4adc-b9ce-70004d552655",
   "metadata": {},
   "source": [
    "### 10) Detailed file history:\n",
    "\n",
    "As mentioned before, *findmycells* keeps a detailed record of your files and how you processed them. To take a look at this information, head over to the \"settings\" page, click the \"browse file history\" tab & then select a file ID you'd like to know more about:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c184587-71c4-4a8b-8a03-e71cddb497c0",
   "metadata": {},
   "source": [
    "![gui_browse_file_histories](https://github.com/Defense-Circuits-Lab/findmycells/blob/major_refactoring/media/gui_browse_file_history.gif?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8731af-c6e1-4c3d-bb87-dd86b4cd0487",
   "metadata": {},
   "source": [
    "### 11) Save & load projects:\n",
    "\n",
    "Of course *findmycells* supports saving & loading of your current project status. This can be done again on the \"settings\" page, in the \"save & load project\" tab. The two files that store all relevant information of your project (.dbase and .configs) will be saved by default in your project root directory. Please do not move these files anywhere else! You can delete older versions of the files, though (as determined from the date as prefix)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49e5503-77ef-401c-8444-43a15416955d",
   "metadata": {},
   "source": [
    "### 12) Export quantification results:\n",
    "\n",
    "As soon as any quantification results are computed by your *findmycells* project, you can use the \"export results\" tab on the settings page to export these results either as .csv or as .xlsx spreadsheets. The quantification results will be separated by area IDs into different different files & *findmycells* will also add some additional metadata that might come in handy for your subsequent statistical analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71dd694-0353-4fa1-83a7-0e17411ea52a",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "The output format of the quantification results is designed to match the expected input format of the python tool [stats_n_plots](https://github.com/Defense-Circuits-Lab/stats_n_plots), which was also developed by the [Defense-Circuits-Lab](https://github.com/Defense-Circuits-Lab) and represents - just as *findmycells* - an interactive jupyter-widget GUI that helps you perform statistical analyses and create appealing plots of your data in no time!\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af265aae-603e-4d16-894e-0f8ec200c56a",
   "metadata": {},
   "source": [
    "## Advanced functionalities:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837bd422-8838-4494-8549-4f51714ef54d",
   "metadata": {},
   "source": [
    "Well, let's face it. Most likely, you will run into an error and something will stop working / not work as intended. In these cases, it may be beneficial to have the *findmycells* project object (an instance of the [`API`](https://Defense-Circuits-Lab.github.io/findmycells/api/interfaces.html#api) class) available as variable in your jupyter notebook, rather than just as GUI-widget. Therefore, we recommend that users who are in general familiar with objects and basic python syntax, use the following lines to launch the GUI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af11dc6e-4811-4a32-bd20-cee5b4f72356",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from findmycells.interfaces import GUI\n",
    "\n",
    "gui = GUI()\n",
    "gui.displayed_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fb63fc-b941-4d07-bc72-2ebd78cbe1f0",
   "metadata": {},
   "source": [
    "This allows you to access everything stored in the project also via the `gui` variable. For instance, after initializing a project and updating the project files, you can use:\n",
    "\n",
    "> gui.api.database.file_infos\n",
    "\n",
    "to see what files are currently associated with your project. Or:\n",
    "\n",
    "> gui.api.database.file_histories\n",
    "\n",
    "to browse through the individual [`FileHistory`](https://Defense-Circuits-Lab.github.io/findmycells/api/database.html#filehistory) objects of each file ID."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5758235e-a391-4a4a-b96a-b437d011c3f6",
   "metadata": {},
   "source": [
    "## Download the full sample dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e39f90-11de-47aa-9336-877f9fbcf21e",
   "metadata": {},
   "source": [
    "If you are interested in downloading our full sample dataset, including images, ROI-files, and a trained model ensemble, you can do so either manually from our [Zenodo repository](https://zenodo.org/record/7655292#.Y_Nw0B-ZNhE), or by using the following lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293a0dda-2c9b-4eb2-8f60-7289042432b4",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from findmycells.utils import download_sample_data\n",
    "from pathlib import Path\n",
    "\n",
    "destination_dir = Path('/please/provide/a/path/to/an/empty/directory/on/your/local/machine/here')\n",
    "# If you wish to run the download, simply remove the hashtag at the beginning of the following line:\n",
    "#download_sample_data(destinatin_dir_path = destination_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
