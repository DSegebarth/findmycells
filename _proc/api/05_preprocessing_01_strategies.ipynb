{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Defines all options you can use for preprocessing of your image data\n",
    "  (findmycells.preprocessing.strategies)\n",
    "order: 10\n",
    "output-file: preprocessing_01_strategies.html\n",
    "title: preprocessing options\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Defense-Circuits-Lab/findmycells/blob/main/findmycells/preprocessing/strategies.py#L19){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CropStitchingArtefactsRGBStrat\n",
       "\n",
       ">      CropStitchingArtefactsRGBStrat ()\n",
       "\n",
       "When you acquire microscopy images that are essentially several individual \n",
       "images (= tiles) stitched together, you may end up with some artefacts on the\n",
       "borders of the image as a result from the stitching process. These pixels are\n",
       "usually either fully black or fully white and can therefore interfere with \n",
       "other processing strategies that you might want to apply to your images (for \n",
       "instance, if you´d like to adjust brightness and contrast). This strategy aims\n",
       "at identifying these pixels that were added to account for some offset between\n",
       "the individual tiles and eventually remove them. As these artefacts might \n",
       "interfere with other processing steps, it is recommended to add this (or any other\n",
       "cropping strategy to get rid of these artefacts) prior to other preprocessing \n",
       "strategies."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Defense-Circuits-Lab/findmycells/blob/main/findmycells/preprocessing/strategies.py#L19){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CropStitchingArtefactsRGBStrat\n",
       "\n",
       ">      CropStitchingArtefactsRGBStrat ()\n",
       "\n",
       "When you acquire microscopy images that are essentially several individual \n",
       "images (= tiles) stitched together, you may end up with some artefacts on the\n",
       "borders of the image as a result from the stitching process. These pixels are\n",
       "usually either fully black or fully white and can therefore interfere with \n",
       "other processing strategies that you might want to apply to your images (for \n",
       "instance, if you´d like to adjust brightness and contrast). This strategy aims\n",
       "at identifying these pixels that were added to account for some offset between\n",
       "the individual tiles and eventually remove them. As these artefacts might \n",
       "interfere with other processing steps, it is recommended to add this (or any other\n",
       "cropping strategy to get rid of these artefacts) prior to other preprocessing \n",
       "strategies."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(CropStitchingArtefactsRGBStrat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Defense-Circuits-Lab/findmycells/blob/main/findmycells/preprocessing/strategies.py#L126){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CropToROIsBoundingBoxStrat\n",
       "\n",
       ">      CropToROIsBoundingBoxStrat ()\n",
       "\n",
       "You might not be interested in analyzing the entire image, but only to quantify\n",
       "image features of interest in a certain region of your image (or actually also\n",
       "several regions). Now, chances are that it is possible to find a bounding box that\n",
       "contains all regions of the image that you are interested in, which is, however,\n",
       "smaller than the original image. Cropping your original image down to that smaller \n",
       "size will then significantly reduce computation time, required memory space, and also\n",
       "required disk space. Therefore, it is highly recommended to add this strategy to your\n",
       "preprocessing. You can also combine it with additional cropping strategies, like the\n",
       "one that tries to remove stitching artefacts."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Defense-Circuits-Lab/findmycells/blob/main/findmycells/preprocessing/strategies.py#L126){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CropToROIsBoundingBoxStrat\n",
       "\n",
       ">      CropToROIsBoundingBoxStrat ()\n",
       "\n",
       "You might not be interested in analyzing the entire image, but only to quantify\n",
       "image features of interest in a certain region of your image (or actually also\n",
       "several regions). Now, chances are that it is possible to find a bounding box that\n",
       "contains all regions of the image that you are interested in, which is, however,\n",
       "smaller than the original image. Cropping your original image down to that smaller \n",
       "size will then significantly reduce computation time, required memory space, and also\n",
       "required disk space. Therefore, it is highly recommended to add this strategy to your\n",
       "preprocessing. You can also combine it with additional cropping strategies, like the\n",
       "one that tries to remove stitching artefacts."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(CropToROIsBoundingBoxStrat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Defense-Circuits-Lab/findmycells/blob/main/findmycells/preprocessing/strategies.py#L229){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ConvertTo8BitStrat\n",
       "\n",
       ">      ConvertTo8BitStrat ()\n",
       "\n",
       "This strategy converts your image to an 8-bit format. Adding this strategy is\n",
       "at the moment mandatory, as all implemented segmentation tools (deepflash2 & cellpose)\n",
       "require 8-bit as input format. So you actually don´t really have a choice but adding it! :-)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Defense-Circuits-Lab/findmycells/blob/main/findmycells/preprocessing/strategies.py#L229){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ConvertTo8BitStrat\n",
       "\n",
       ">      ConvertTo8BitStrat ()\n",
       "\n",
       "This strategy converts your image to an 8-bit format. Adding this strategy is\n",
       "at the moment mandatory, as all implemented segmentation tools (deepflash2 & cellpose)\n",
       "require 8-bit as input format. So you actually don´t really have a choice but adding it! :-)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ConvertTo8BitStrat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Defense-Circuits-Lab/findmycells/blob/main/findmycells/preprocessing/strategies.py#L285){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MaximumIntensityProjectionStrat\n",
       "\n",
       ">      MaximumIntensityProjectionStrat ()\n",
       "\n",
       "If you acquired your microscopy images as z-stack, you can use this strategy to\n",
       "project it from a 3D image stack (commonly referred to as 2.5D) into a two\n",
       "dimensional single plane image. If you select this strategy, the brightest (= maximal)\n",
       "pixel value from the z-stack will be used in the final 2D projection. Alternatively,\n",
       "feel free to use the \"Minimum intenstity projection\" strategy, if you´d like to \n",
       "keep only the darkest (= minimal) value of each pixel."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Defense-Circuits-Lab/findmycells/blob/main/findmycells/preprocessing/strategies.py#L285){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MaximumIntensityProjectionStrat\n",
       "\n",
       ">      MaximumIntensityProjectionStrat ()\n",
       "\n",
       "If you acquired your microscopy images as z-stack, you can use this strategy to\n",
       "project it from a 3D image stack (commonly referred to as 2.5D) into a two\n",
       "dimensional single plane image. If you select this strategy, the brightest (= maximal)\n",
       "pixel value from the z-stack will be used in the final 2D projection. Alternatively,\n",
       "feel free to use the \"Minimum intenstity projection\" strategy, if you´d like to \n",
       "keep only the darkest (= minimal) value of each pixel."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(MaximumIntensityProjectionStrat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Defense-Circuits-Lab/findmycells/blob/main/findmycells/preprocessing/strategies.py#L345){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MinimumIntensityProjectionStrat\n",
       "\n",
       ">      MinimumIntensityProjectionStrat ()\n",
       "\n",
       "If you acquired your microscopy images as z-stack, you can use this strategy to\n",
       "project it from a 3D image stack (commonly referred to as 2.5D) into a two\n",
       "dimensional single plane image. If you select this strategy, the darkest (= minimal)\n",
       "pixel value from the z-stack will be used in the final 2D projection. Alternatively,\n",
       "feel free to use the \"Maximum intenstity projection\" strategy, if you´d like to \n",
       "keep only the brightest (= maximal) value of each pixel."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Defense-Circuits-Lab/findmycells/blob/main/findmycells/preprocessing/strategies.py#L345){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MinimumIntensityProjectionStrat\n",
       "\n",
       ">      MinimumIntensityProjectionStrat ()\n",
       "\n",
       "If you acquired your microscopy images as z-stack, you can use this strategy to\n",
       "project it from a 3D image stack (commonly referred to as 2.5D) into a two\n",
       "dimensional single plane image. If you select this strategy, the darkest (= minimal)\n",
       "pixel value from the z-stack will be used in the final 2D projection. Alternatively,\n",
       "feel free to use the \"Maximum intenstity projection\" strategy, if you´d like to \n",
       "keep only the brightest (= maximal) value of each pixel."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(MinimumIntensityProjectionStrat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Defense-Circuits-Lab/findmycells/blob/main/findmycells/preprocessing/strategies.py#L405){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AdjustBrightnessAndContrastStrat\n",
       "\n",
       ">      AdjustBrightnessAndContrastStrat ()\n",
       "\n",
       "This strategy allows you to automatically adjust brightness and contrast\n",
       "of your images. For this, please specify the percentage of pixels that\n",
       "you want to be saturated (default: 0.35 % - same as in ImageJ2). This \n",
       "strategy will then ensure that this specified percentage of pixels will\n",
       "be fully saturated in all of your images. If you have z-stack images,\n",
       "you can furthermore also specify whether you´d like to run this operation\n",
       "on the full z-stack (chose \"globally\"), or on each individual plane of the\n",
       "z-stack (chose \"individually\"). I would rather recommend using \"globally\" \n",
       "to keep a somewhat consistent meaning of pixel intensities. And, finally, \n",
       "if you are anyhow dealing with 2D images (either from the get-go, or since\n",
       "you applied a maximum or minimum intensity projection strategy prior to\n",
       "this one - both \"globally\" and \"individually\" will lead to the same result."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Defense-Circuits-Lab/findmycells/blob/main/findmycells/preprocessing/strategies.py#L405){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AdjustBrightnessAndContrastStrat\n",
       "\n",
       ">      AdjustBrightnessAndContrastStrat ()\n",
       "\n",
       "This strategy allows you to automatically adjust brightness and contrast\n",
       "of your images. For this, please specify the percentage of pixels that\n",
       "you want to be saturated (default: 0.35 % - same as in ImageJ2). This \n",
       "strategy will then ensure that this specified percentage of pixels will\n",
       "be fully saturated in all of your images. If you have z-stack images,\n",
       "you can furthermore also specify whether you´d like to run this operation\n",
       "on the full z-stack (chose \"globally\"), or on each individual plane of the\n",
       "z-stack (chose \"individually\"). I would rather recommend using \"globally\" \n",
       "to keep a somewhat consistent meaning of pixel intensities. And, finally, \n",
       "if you are anyhow dealing with 2D images (either from the get-go, or since\n",
       "you applied a maximum or minimum intensity projection strategy prior to\n",
       "this one - both \"globally\" and \"individually\" will lead to the same result."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(AdjustBrightnessAndContrastStrat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0050a0f462f84ddda54d27698857eefc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {}
     },
     "287f42e048964e1c9287397554341cb3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "500px"
      }
     },
     "cc02d8aa67a34cbe8da8c62b608aee3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "layout": "IPY_MODEL_fb35796326b24027ab5da0df48dc4139",
       "style": "IPY_MODEL_0050a0f462f84ddda54d27698857eefc"
      }
     },
     "fb35796326b24027ab5da0df48dc4139": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "height": "30px"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
