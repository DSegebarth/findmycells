[
  {
    "objectID": "configs.html",
    "href": "configs.html",
    "title": "configs",
    "section": "",
    "text": "Configurations\nThere are several layers that require & allow configuration of findmycells. However, only the top most level (ProjectConfigs) is implemented here. All lower level configs (e.g. configs for each processing type like “preprocessing” or “quantification”, or even lower level configs like for each individual processing step represented by ProcessingStrategy subclasses), will be defined by each of these classes using the DefaultConfigs - which is implemented here. For an example of how the DefaultConfigs shall be used, please have a look at the general implementation of ProcessingObject and ProcessingStrategy in the core module, and then check out the “specs.py” file of the corresponding processing sub-module!\n\nsource\n\nProjectConfigs\n\n ProjectConfigs (root_dir:pathlib.PosixPath)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nDefaultConfigs\n\n DefaultConfigs (default_values:Dict[str,Any],\n                 valid_types:Dict[str,List[type]],\n                 valid_value_ranges:Optional[Dict[str,Tuple]]=None,\n                 valid_value_options:Optional[Dict[str,Tuple]]=None)\n\nThis class has to be specified as an attribute in several classes throughout findmycells and allows / ensures that each novel class defines its own set of default config values. Moreover, the ‘valid_types’ dictionary also defines which types of values are allowed.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndefault_values\ntyping.Dict[str, typing.Any]\n\nKeys are identifier of config options, values the corresponding default value\n\n\nvalid_types\ntyping.Dict[str, typing.List[type]]\n\nKeys must match with keys of “default_values”, values are lists of allowed types\n\n\nvalid_value_ranges\ntyping.Optional[typing.Dict[str, typing.Tuple]]\nNone\nRequired for every config option that allows floats or integers. Keys must match with keys of “default_values”. Expected format: (start_idx, end_idx) or (start_idx, end_idx, step_size)\n\n\nvalid_value_options\ntyping.Optional[typing.Dict[str, typing.Tuple]]\nNone\nKeys must match with keys of “default_values”. Expected format: (‘option_a’, ‘option_b’, …)\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\n\nGUIConfigs\n\n GUIConfigs (widget_names:Dict[str,str], descriptions:Dict[str,str],\n             tooltips:Optional[Dict[str,str]]=None)\n\nNote for developers: The docstrings of each processing strategy will also be used to display the description of each strategy in both the GUI and in the online hosted documentation. To improve the layout of these displayed HTML elements, we introduced some custom “string commands”. Their use is described in detail in the docstring of the “_convert_docstring_to_html()” method of this class."
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "Handling data processing\nThe following two classes, ProcessingObject and ProcessingStrategy, provide the blueprints for all processing strategies and objects that are used throughout the findmycells package. As you can see in the corresponding processing step modules (i.e. “preprocess”, “segment”, or “quantify”), these abstract base classes provide the basic structure of the more specific objects and strategies in each of these modules (e.g. QuantificationObject and QuantificationStrategy within the “quantify” module inherit from ProcessingObject and ProcessingStrategy, respectively). While this makes these two classes highly relevant for any developer, regular users of findmycells won´t be interacting with them, even if they want to use the API instead of the GUI.\n\nsource\n\nProcessingObject\n\n ProcessingObject ()\n\nAbstract base class (inherits from ABC) that defines the general structure of ProcessingObjects in findmycells. A ProcessingObject combines all information needed for the corresponding processing step, i.e. what files are supposed to be processed & how. It also interfaces to the database of the project, such that it can automatically update the database with the latest progress.\nSubclasses that inherit from ProcessingObject need to implement the following two abstract methods:\n\nsource\n\n\nProcessingObject.processing_type\n\n ProcessingObject.processing_type ()\n\nAbstract method that requires its subclasses to define the processing_type as a property of the class. Thus, this will be specified in each individual processing module (e.g. the “preprocess” or “quantify” modules). It will be used in the database to keep track of the processing progress of the project. Has to be a string.\n\nsource\n\n\nProcessingObject._add_processing_specific_infos_to_updates\n\n ProcessingObject._add_processing_specific_infos_to_updates (updates:Dict)\n\nAbstract method that that requires its subclasses to define what updates need to be passed to the database, in addition to those that are already covered by the corresponding ProcessingStrategies or the “self.update_database()” method. If there are no more information to add, simply return the input ‘updates’ dictionary without any alterations.\nReturns a dictionary with all updates that need to be passed to the database.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nupdates\ntyping.Dict\nA dictionary with updates that need to be passed to the database\n\n\nReturns\ntyping.Dict\nA dictionary with all updates that need to be passed to the database\n\n\n\nIn addition, ProcessingObject defines two core functions that will be called on all its subclasses, which are:\n\nsource\n\n\nProcessingObject.run_all_strategies\n\n ProcessingObject.run_all_strategies (strategies:List,\n                                      strategy_configs:List[Dict])\n\nRuns all ProcessingStrategies that were passed upon initialization (i.e. self.strategies). For this, the corresponding ProcessingStrategy objects will be initialized and their “.run()” method will be called, while passing “self” as “processing_object”. Finally, it updates the database and deletes the ProcessingStrategy object to clear it from memory.\n\nsource\n\n\nProcessingObject.update_database\n\n ProcessingObject.update_database (mark_as_completed:bool=True)\n\nFor each microscopy file that had to be processed (self.file_ids), the database will be updated with the respective processing progress information. Interfaces back to the abstract method “self.add_processing_specific_infos_to_updates()” that enables the corresponding subclasses to add more specific details before triggering the update method of the database.\n\nsource\n\n\nProcessingStrategy\n\n ProcessingStrategy ()\n\nAbstract base class that defines the general structure of ProcessingStrategies in findmycells. A ProcessingStrategy combines all functions that are required for one particular processing step, e.g. ConvertTo8Bit is a ProcessingStrategy in the “preprocess” module and converts the corresponding images into 8-bit.\n\n\n\nHandling data reading\nFurthermore, the following two classes DataLoader and DataReader will be re-used throughout the findmycells package to load data into your findmycells project.\n\nsource\n\nDataReader\n\n DataReader ()\n\nAbstract base class that defines the general structure of DataReader subclasses. Essentially, it demands the corresponding subclasses to define the “readable_filetype_extensions” attribut, as well as the “set_optional_configs()” and the “read()” methods.\n\nsource\n\n\nDataLoader\n\n DataLoader ()\n\nInitialize self. See help(type(self)) for accurate signature."
  },
  {
    "objectID": "readers_02_rois.html",
    "href": "readers_02_rois.html",
    "title": "ROI readers",
    "section": "",
    "text": "source\n\nROIReaders\n\n ROIReaders ()\n\nReturn the roi(s) as shapely.geometry.Polygon(s) in a nested dictionary with structure: {plane_id: {roi_id: Polygon}} In case plane-specific ROIs are required / requested at some point, having the additional level that enables the reference to plane_id(s) should foster the implementation. The current implementation, however, only supports the use of ROIs for all planes - the corresponding plane_id is hence: ‘all_planes’ Ultimately, this file_id specific dictionary can then be integrated into the ‘rois_as_shapely_polygons’ attribute of the database.\nNote: If multiple ROIs are used for one image, the individual ROIs must be named properly in the ROIManager-Tool in ImageJ. For instance, if images of the hippocampus are investigated & they can contain images of the DG, CA3 and CA1, the corresponding ROIs that mark the respective area have to be named consistenly for all .zip files. This makes it possible, that findmycells can handle the analysis even if not all ROIs are present for each image, e.g. for some files only DG and CA3.\n\nsource\n\n\nImageJROIReader\n\n ImageJROIReader ()\n\nReturn the roi(s) as shapely.geometry.Polygon(s) in a nested dictionary with structure: {plane_id: {roi_id: Polygon}} In case plane-specific ROIs are required / requested at some point, having the additional level that enables the reference to plane_id(s) should foster the implementation. The current implementation, however, only supports the use of ROIs for all planes - the corresponding plane_id is hence: ‘all_planes’ Ultimately, this file_id specific dictionary can then be integrated into the ‘rois_as_shapely_polygons’ attribute of the database.\nNote: If multiple ROIs are used for one image, the individual ROIs must be named properly in the ROIManager-Tool in ImageJ. For instance, if images of the hippocampus are investigated & they can contain images of the DG, CA3 and CA1, the corresponding ROIs that mark the respective area have to be named consistenly for all .zip files. This makes it possible, that findmycells can handle the analysis even if not all ROIs are present for each image, e.g. for some files only DG and CA3."
  },
  {
    "objectID": "preprocessing_01_strategies.html",
    "href": "preprocessing_01_strategies.html",
    "title": "Preprocessing strategies",
    "section": "",
    "text": "source\n\nCropStitchingArtefactsRGBStrat\n\n CropStitchingArtefactsRGBStrat ()\n\nWhen you acquire microscopy images that are essentially several individual images (= tiles) stitched together, you may end up with some artefacts on the borders of the image as a result from the stitching process. These pixels are usually either fully black or fully white and can therefore interfere with other processing strategies that you might want to apply to your images (for instance, if you´d like to adjust brightness and contrast). This strategy aims at identifying these pixels that were added to account for some offset between the individual tiles and eventually remove them. As these artefacts might interfere with other processing steps, it is recommended to add this (or any other cropping strategy to get rid of these artefacts) prior to other preprocessing strategies.\n\nsource\n\n\nCropToROIsBoundingBoxStrat\n\n CropToROIsBoundingBoxStrat ()\n\nYou might not be interested in analyzing the entire image, but only to quantify image features of interest in a certain region of your image (or actually also several regions). Now, chances are that it is possible to find a bounding box that contains all regions of the image that you are interested in, which is, however, smaller than the original image. Cropping your original image down to that smaller size will then significantly reduce computation time, required memory space, and also required disk space. Therefore, it is highly recommended to add this strategy to your preprocessing. You can also combine it with additional cropping strategies, like the one that tries to remove stitching artefacts.\n\nsource\n\n\nConvertTo8BitStrat\n\n ConvertTo8BitStrat ()\n\nThis strategy converts your image to an 8-bit format. Adding this strategy is at the moment mandatory, as all implemented segmentation tools (deepflash2 & cellpose) require 8-bit as input format. So you actually don´t really have a choice but adding it! :-)\n\nsource\n\n\nMaximumIntensityProjectionStrat\n\n MaximumIntensityProjectionStrat ()\n\nIf you acquired your microscopy images as z-stack, you can use this strategy to project it from a 3D image stack (commonly referred to as 2.5D) into a two dimensional single plane image. If you select this strategy, the brightest (= maximal) pixel value from the z-stack will be used in the final 2D projection. Alternatively, feel free to use the “Minimum intenstity projection” strategy, if you´d like to keep only the darkest (= minimal) value of each pixel.\n\nsource\n\n\nMinimumIntensityProjectionStrat\n\n MinimumIntensityProjectionStrat ()\n\nIf you acquired your microscopy images as z-stack, you can use this strategy to project it from a 3D image stack (commonly referred to as 2.5D) into a two dimensional single plane image. If you select this strategy, the darkest (= minimal) pixel value from the z-stack will be used in the final 2D projection. Alternatively, feel free to use the “Maximum intenstity projection” strategy, if you´d like to keep only the brightest (= maximal) value of each pixel.\n\nsource\n\n\nAdjustBrightnessAndContrastStrat\n\n AdjustBrightnessAndContrastStrat ()\n\nThis strategy allows you to automatically adjust brightness and contrast of your images. For this, please specify the percentage of pixels that you want to be saturated (default: 0.35 % - same as in ImageJ2). This strategy will then ensure that this specified percentage of pixels will be fully saturated in all of your images. If you have z-stack images, you can furthermore also specify whether you´d like to run this operation on the full z-stack (chose “globally”), or on each individual plane of the z-stack (chose “individually”). I would rather recommend using “globally” to keep a somewhat consistent meaning of pixel intensities. And, finally, if you are anyhow dealing with 2D images (either from the get-go, or since you applied a maximum or minimum intensity projection strategy prior to this one - both “globally” and “individually” will lead to the same result."
  },
  {
    "objectID": "readers_01_microscopy_images.html",
    "href": "readers_01_microscopy_images.html",
    "title": "microscopy image data readers",
    "section": "",
    "text": "source\n\nMicroscopyImageReaders\n\n MicroscopyImageReaders ()\n\nThe read method of MicroscopyImageReaders subclasses has to return a numpy array with the following structure: [imaging-planes, rows, columns, color-channels] For instance, an array of a RGB z-stack with 10 image planes of 1024x1024 pixels will have a shape of: [10, 1024, 1024, 3] To improve re-usability of the same functions for all different kinds of input images, this structure will be used even if there is just a single plane. For instance, the shape of the array of a grayscale 2D image with 1024 x 1024 pixels will look like this: [1, 1024, 1024, 1]\n\nsource\n\n\nCZIReader\n\n CZIReader ()\n\nThis reader enables loading of images acquired with the ZEN imaging software by Zeiss, using the czifile package. Note: the first three dimensions are entirely guessed, it could well be that they reflect different things and not “version_idx”, “tile_row_idx”, “tile_col_idx”!\n\nsource\n\n\nRegularImageFiletypeReader\n\n RegularImageFiletypeReader ()\n\nThis reader enables loading of all regular image filetypes, that scikit-image can read, using the scikit-image.io.imread function. Note: So far only single plane images are supported (yet, both single-color & multi-color channel images are supported)!\n\nsource\n\n\nFromExcelReader\n\n FromExcelReader ()\n\nThis reader is actually only a wrapper to the other MicroscopyImageReaders subclasses. It can be used if you stored the filepaths to your individual plane images in an excel sheet, for instance if you were using our “prepare my data for findmycells” functions. Please be aware that the corresponding datatype has to be loadable with any of the corresponding MicroscopyImageReaders!"
  },
  {
    "objectID": "readers_00_specs.html",
    "href": "readers_00_specs.html",
    "title": "Specification of default values of available data readers",
    "section": "",
    "text": "source\n\nReaderSpecsABC\n\n ReaderSpecsABC ()\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nMicroscopyReaderSpecs\n\n MicroscopyReaderSpecs ()\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nROIReaderSpecs\n\n ROIReaderSpecs ()\n\nfindmycells enables analyses of multiple ROIs in the image data. To do so, they will be matched based on their ID that will be retrieved from the ROI file. Some softwares that create these ROI-files, however, create default IDs for the individual ROIs that will interfere with this matching. For instance, in Fiji / ImageJ2, created ROIs get its centroid (?) pixel coordinates as default ID (e.g. something like “523-378”). Since such default IDs most likely won´t be consistent throughout your entire image dataset, findmycells provides you with two options to adress this: a) You can set ‘load_roi_ids_from_file’ to False (default): This will cause findmycells to ignore the IDs of the ROIs that are saved in the provided ROI file and assign them with new IDs starting at “000”. Note: Essentially, this requires you to have always the same type of ROIs present in the exact same order in all your ROI-files. It is therefore only recommended if you have just a single ROI you´d like to analyze. b) You can set ‘load_roi_ids_from_file’ to True (recommended if you have more than a single ROI): This will enforce that findmycells uses the IDs that each ROI was saved with. Therefore, it requires that you use consistent naming of the ROIs with your preferred software. For instance, if you´re using Fiji / ImageJ2, you can rename each ROI in the ROIManager (e.g. “CA3”, “vlPAG”, or “ipsilateral_SNc”). Analyses and quantifications will then be matched and pooled across all ROIs with the respective IDs (e.g. all “CA3” ROIs)."
  },
  {
    "objectID": "quantification_00_specs.html",
    "href": "quantification_00_specs.html",
    "title": "Specifications of quantification specific subclasses",
    "section": "",
    "text": "source\n\nQuantificationStrategy\n\n QuantificationStrategy ()\n\nNote for developers: When implementing a new quantification strategy, remember to add the following line at the end of the “.run()” method, to ensure that the quantification results are added to the database:\nquantification_object = self._add_quantification_results_to_database(quantification_object = quantification_object, results = quantification_results)\n\nsource\n\n\nQuantificationObject\n\n QuantificationObject ()\n\nExtending the ProcessingObject base class for quantification as processing subtype."
  },
  {
    "objectID": "preprocessing_00_specs.html",
    "href": "preprocessing_00_specs.html",
    "title": "Specifications of preprocessing specific subclasses",
    "section": "",
    "text": "source\n\nPreprocessingStrategy\n\n PreprocessingStrategy ()\n\nExtending the ProcssingStrategy base class for preprocessing as processing subtype.\n\nsource\n\n\nPreprocessingObject\n\n PreprocessingObject ()\n\nExtending the ProcessingObject base class for preprocessing as processing subtype. Responsible for loading the microscopy image(s) and corresponding ROI(s) for each file, running the specified preprocessing strategies, updating the database, and eventually for saving the preprocessed images to disk for further processing steps down the line.\nNote: Even though the file_ids argument accepts (and actually expects & requires) a list as input, only a single file_id will be passed to a PreprocessingObject upon initialization. This is handled in the api module of findmycells."
  },
  {
    "objectID": "segmentation_01_strategies.html",
    "href": "segmentation_01_strategies.html",
    "title": "Segmentation strategies",
    "section": "",
    "text": "source\n\nDeepflash2SemanticSegmentationStrat\n\n Deepflash2SemanticSegmentationStrat ()\n\nRun semantic segmentation using deepflash2. Requires that you have already an ensemble of trained models ready to use and to provide the path to the directory where these models can be found. If you choose to process the files in your project in smaller batches (which is highly recommended, due to a huge memory load), make sure to run the segmentations “strategy-wise” in the processing configs below before launching the processing (i.e. keep the box checked).\n\nsource\n\n\nLosslessConversionOfDF2SemanticSegToInstanceSegWithCPStrat\n\n LosslessConversionOfDF2SemanticSegToInstanceSegWithCPStrat ()\n\nExtending the ProcssingStrategy base class for segmentation as processing subtype. Also adding another property that denotes the type of segmentation (i.e. instance or semantic)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "findmycells",
    "section": "",
    "text": "Development using nbdev just started, README and docs will be updated soon"
  },
  {
    "objectID": "segmentation_00_specs.html",
    "href": "segmentation_00_specs.html",
    "title": "Specifications of segmentation specific subclasses",
    "section": "",
    "text": "source\n\nSegmentationStrategy\n\n SegmentationStrategy ()\n\nExtending the ProcssingStrategy base class for segmentation as processing subtype. Also adding another property that denotes the type of segmentation (i.e. instance or semantic).\n\nsource\n\n\nSegmentationObject\n\n SegmentationObject ()\n\nExtending the ProcessingObject base class for segmentation as processing subtype. The clear_all_tmp_data() method allows to clear all chached results that might accumulate for instance while using deepflash2."
  },
  {
    "objectID": "postprocessing_01_strategies.html",
    "href": "postprocessing_01_strategies.html",
    "title": "Postprocessing strategies",
    "section": "",
    "text": "source\n\nReconstructCellsIn3DFrom2DInstanceLabelsStrat\n\n ReconstructCellsIn3DFrom2DInstanceLabelsStrat ()\n\nDescription; Include requirements Mention multi matches traceback which can be used in inspection\n\nsource\n\n\nFillHolesStrat\n\n FillHolesStrat ()\n\nSpecific conditions can lead to “holes” within the segmentations of your image features. This can make total sense, for instance if youre analyzing specifically the cells cytoplasm, and want to spare out the nucleus, or if youre analyzing ring-like features. In other cases, however, these “holes” may be artefacts and require correction. This strategy was designed for exactly this purpose: fill the “holes” in your segmented features, if they should not be there.\n\nsource\n\n\nApplyExclusionCriteriaStrat\n\n ApplyExclusionCriteriaStrat ()\n\nAnother typical postprocessing step is to filter your data by applying exclusion criteria. Please check the following list of exclusion criteria with detailed descriptions to see which criteria are currently implemented in your installed findmycells version. Importantly, if you would like to use this strategy, please make sure to run this strategy as the last postprocessing strategy, to ensure that all other processing steps have been completed. \b \u0001- Minimum feature position relative to area ROI: \u0001If you provided ROIs that denote in which area of each image you’d like to quantify the image features, you can use this criterion to specify when to exclude detected features from the quantification. These are the options you can chose from, in order of increasing distance of your feature from the area ROI: within < intersects < touches < no overlap The option you select will always be the first relative position to be included. For example, if you select “intersects”, all features that are fully within your area ROI (classified as “within”) and all features that are intersected by the area ROI border (classified as “intersects”) will be kept, while all features that only touch the area ROI border (classified as “touches”) or that lie completely outside of it (classified as “no overlap”) will be excluded from further analyses. Note: if you are analyzing an image stack, a features` position can be classified differently depending on the image plane. Findmycells will always use the nearest classification. That means, if a feature was classified in one plane as “within” but only as “intersects” or even as “no overlap” in the other planes, the entire 3D feature will be classified as “within”.\u0002\u0002 \b \u0001- Minimum feature size [px]: \u0001Every detected feature whose area is smaller than the specified pixel value will will be deleted from the segmentation masks. Note: if you are analyzing an image stack, this strategy will determine for each 3D feature the plane in which is has the largest area & then apply this exclusion criterion based on this area value.\u0002\u0002 \b \u0001- Minimum planes covered (only relevant for image stacks): \u0001Similarly to “minimum feature size”, which checks for the expansion of your image features in x-y-dimensions, you can use this exclusion criterion to also check for a minimum size of your features in the z-dimension. The number you specify here will represent the minimum number of consecutive planes each image feature needs to cover to remain in your segmentation masks. For instance, if you specify it to be 3, all features that are only present in a single or in two consecutive planes will be deleted. Note: this exclusion criterion is, obviously, only relevant for projects that analyze image stacks. If you are working only with 2D images, this value will be ignored and 1 will be used as default.\u0002\u0002"
  },
  {
    "objectID": "interfaces.html",
    "href": "interfaces.html",
    "title": "interfaces",
    "section": "",
    "text": "Application programming interface (API)\nThe following class defines the API of findmycells, which represents the intended way of how users interact with and use findmycells, if they are not using the graphical user interface (GUI; defined below).\n\nsource\n\nAPI\n\n API (project_root_dir:pathlib.PosixPath)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\nGraphical user interface\nThe following classes are used to create the graphical user interface of findmycells. Please note that classes will be listed here in an inverted hirarchy, such that you can find the main GUI class at the very end, and classes that handle much more specific details at the beginning.\n\nclass StrategyConfigurator:\n    \n    \"\"\"\n    This class implements the interface that let´s the user choose and \n    configurate the processing strategies. It will be placed inside of\n    an accordion that is implemented in the `ProcessingStepPage`.\n    It gets a list of all available processing strategies from the parent\n    `ProcessingStepPage` and, thus, eventually from the `API` that checks\n    for all available processing strategies in the corresponding processing\n    submodule (e.g. \"findmycells.preprocessing.strategies\"). Upon initializing\n    it´s dropdown widget, which let´s the user browser through the different\n    available strategies, it also initializes an object of each strategy.\n    This object can then be used to run it´s associated method \n    \".initialize_gui_configs_and_widget()\" to build the specified widget, \n    using its `GUIConfigs` instance. Essentially, this contains a\n    description of what the processing strategy does and, if applicable,\n    widgets to specify all parameters that can be configurated for this \n    strategy. Finally, a \"confirm & export\" and a \"remove\" button allow\n    the user to load or delete the current to or from the findmycells\n    project, respectively.\n    \"\"\"\n    \n    def __init__(self,\n                 available_strategy_classes: List,\n                 parent_accordion: w.Accordion,\n                 target_for_configs_export: List) -> None:\n        self.available_strategy_classes = available_strategy_classes\n        self.parent_accordion = parent_accordion\n        self.target_for_configs_export = target_for_configs_export\n        self.widget = self._initialize_widget()\n        self._link_widgets_with_eventhandlers()\n\n        \n    def _initialize_widget(self) -> WidgetType:\n        info_text = w.HTML(value = ('Please select one of the available processing methods from the dropdown menu below. '\n                                    'Feel free to click through all listed methods, as each of them will display a '\n                                    'short description of what exactly to expect and may also prompt you with some '\n                                    'customization options. To select a method with all selected customization options, '\n                                    'click on the \"confirm selection & export configurations\". Using the \"remove method\" '\n                                    'button allows you to remove previously loaded methods again.'))\n        self.dropdown = self._initialize_dropdown()\n        self.confirm_and_export_button = w.Button(description = 'confirm selection & export configurations', layout = {'width': '30%'})\n        self.remove_button = w.Button(description = 'remove method', layout = {'width': '20%'}, disabled = True)\n        self.displayed_strat_widget = w.VBox([self.dropdown.value.widget], layout = {'width': '95%'})\n        widget = w.VBox([info_text,\n                         GUI_SPACER,\n                         w.HBox([self.dropdown, self.confirm_and_export_button, self.remove_button]),\n                         GUI_SPACER,\n                         self.displayed_strat_widget])\n        return widget\n        \n        \n    def _link_widgets_with_eventhandlers(self) -> None:\n        self.confirm_and_export_button.on_click(self._confirm_and_export_button_clicked)\n        self.remove_button.on_click(self._remove_button_clicked)\n        self.dropdown.observe(self._dropdown_option_changed, names = 'value')\n        \n    \n    def _initialize_dropdown(self) -> WidgetType:\n        dropdown_option_tuples = []\n        for strategy_class in self.available_strategy_classes:\n            strategy_obj = strategy_class()\n            strategy_obj.initialize_gui_configs_and_widget()\n            dropdown_option_tuples.append((strategy_obj.dropdown_option_value_for_gui, strategy_obj))\n        return w.Dropdown(options = dropdown_option_tuples, layout = {'width': '50%'}) \n        \n        \n    def _get_own_position_idx_in_parent_accordion(self) -> int:\n        return self.parent_accordion.children.index(self.widget)\n        \n        \n    def _confirm_and_export_button_clicked(self, b) -> None:\n        self._export_configs()\n        self._change_disable_settings_of_customizable_widgets(disable_customizable_widgets = True)\n        self._add_new_strategy_configurator_to_parent_accordion()\n        self._change_own_accordion_tab_title(title = self.dropdown.value.dropdown_option_value_for_gui)\n        self.parent_accordion.selected_index = None\n        \n        \n    def _add_new_strategy_configurator_to_parent_accordion(self) -> None:\n        new_strategy_configurator = StrategyConfigurator(available_strategy_classes = self.available_strategy_classes,\n                                                         parent_accordion = self.parent_accordion,\n                                                         target_for_configs_export = self.target_for_configs_export)\n        self.parent_accordion.children = self.parent_accordion.children + (new_strategy_configurator.widget, )\n        position_idx = len(self.parent_accordion.children) - 1\n        self.parent_accordion.set_title(position_idx, 'Expand me to add a processing method')\n                                                         \n                                                         \n    def _change_own_accordion_tab_title(self, title: str) -> None:\n        position_idx = self._get_own_position_idx_in_parent_accordion()\n        self.parent_accordion.set_title(position_idx, title)\n\n        \n    def _export_configs(self) -> None:\n        selected_strategy_obj = self.dropdown.value\n        current_configs = selected_strategy_obj.gui_configs.export_current_config_values()\n        position_idx = self._get_own_position_idx_in_parent_accordion()\n        self.target_for_configs_export.insert(position_idx, (selected_strategy_obj.__class__, current_configs))      \n        \n        \n    def _change_disable_settings_of_customizable_widgets(self, disable_customizable_widgets: bool) -> None:\n        self.remove_button.disabled = not disable_customizable_widgets\n        self.dropdown.disabled = disable_customizable_widgets\n        self.confirm_and_export_button.disabled = disable_customizable_widgets\n        for widget in self.displayed_strat_widget.children[0].children:\n            if hasattr(widget, 'disabled'):\n                widget.disabled = disable_customizable_widgets\n            elif type(widget) == w.HBox:\n                if hasattr(widget.children[0], 'disabled'):\n                    widget.children[0].disabled = disable_customizable_widgets\n        \n        \n    def _remove_button_clicked(self, b) -> None:\n        self._remove_configs()\n        if len(self.parent_accordion.children) == 1:\n            self._change_disable_settings_of_customizable_widgets(disable_customizable_widgets = False)\n            self._change_own_accordion_tab_title(title = 'Expand me to add a processing method')\n        else:\n            currently_present_accordion_tabs = len(self.parent_accordion.children)\n            currently_confirmed_strategies = len(self.target_for_configs_export)\n            tabs_available_for_selection = currently_present_accordion_tabs - currently_confirmed_strategies\n            if tabs_available_for_selection > 1:\n                self._remove_own_tab_from_parent_accordion()\n            else:\n                self._change_disable_settings_of_customizable_widgets(disable_customizable_widgets = False)\n                self._change_own_accordion_tab_title(title = 'Expand me to add a processing method')\n                \n                \n    def _remove_own_tab_from_parent_accordion(self) -> None:\n        tmp_children = list(self.parent_accordion.children)\n        tmp_titles = []\n        for idx in range(len(tmp_children)):\n            tmp_titles.append(self.parent_accordion.get_title(idx))\n        position_idx = self._get_own_position_idx_in_parent_accordion()\n        tmp_children.pop(position_idx)\n        tmp_titles.pop(position_idx)\n        self.parent_accordion.children = tuple(tmp_children)\n        for idx, title in enumerate(tmp_titles):\n            self.parent_accordion.set_title(idx, title)\n            \n            \n    def _remove_configs(self) -> None:\n        position_idx = self._get_own_position_idx_in_parent_accordion()\n        self.target_for_configs_export.pop(position_idx)\n                \n                \n    def _dropdown_option_changed(self, change) -> None:\n        new_selection = change.new\n        self.displayed_strat_widget.children = (new_selection.widget, )\n\n\nsource\n\nPageButtonBundle\n\n PageButtonBundle (bundle_id:str,\n                   page_screen:traitlets.traitlets.MetaHasTraits,\n                   all_navigator_buttons:List, api:__main__.API)\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nSettingsPage\n\n SettingsPage (bundle_id:str,\n               page_screen:traitlets.traitlets.MetaHasTraits,\n               all_navigator_buttons:List, api:__main__.API)\n\nSubclass of PageButtonBundle that implements the GUI interface that allows the user to specify all settings relevant to the findmycells project. It also enables saving & loading of the project status, and to browse through the file history that is automatically created by findmycells.\n\nsource\n\n\nProcessingStepPage\n\n ProcessingStepPage (bundle_id:str,\n                     page_screen:traitlets.traitlets.MetaHasTraits,\n                     all_navigator_buttons:List, api:__main__.API)\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nInspectionPage\n\n InspectionPage (bundle_id:str,\n                 page_screen:traitlets.traitlets.MetaHasTraits,\n                 all_navigator_buttons:List, api:__main__.API)\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nGUI\n\n GUI ()\n\nInitialize self. See help(type(self)) for accurate signature."
  },
  {
    "objectID": "utils.html",
    "href": "utils.html",
    "title": "Utility functions",
    "section": "",
    "text": "source\n\nlist_dir_no_hidden\n\n list_dir_no_hidden (path:pathlib.PosixPath,\n                     only_dirs:Optional[bool]=False,\n                     only_files:Optional[bool]=False)\n\n\nsource\n\n\nload_zstack_as_array_from_single_planes\n\n load_zstack_as_array_from_single_planes (path:pathlib.PosixPath,\n                                          file_id:str,\n                                          minx:Optional[int]=None,\n                                          maxx:Optional[int]=None,\n                                          miny:Optional[int]=None,\n                                          maxy:Optional[int]=None)\n\n\nsource\n\n\nunpad_x_y_dims_in_3d_array\n\n unpad_x_y_dims_in_3d_array (padded_3d_array:numpy.ndarray, pad_width:int)\n\n\nsource\n\n\nget_polygon_from_instance_segmentation\n\n get_polygon_from_instance_segmentation (single_plane:numpy.ndarray,\n                                         label_id:int)"
  },
  {
    "objectID": "inspection_00_methods.html",
    "href": "inspection_00_methods.html",
    "title": "Inspection methods",
    "section": "",
    "text": "Note: This submodule does not use the abstract base classes ProcessingObject and ProcessingStrategy. The reason for this is to make specifying the settings and configurations for these inspection methods more interactive for the user - especially when accessed via the GUI. Unfortunately, this sacrifices a bit of overall code consistency. However, since inspection also does not really represent a processing step, this trade-off in favor of usability seemed reasonable. To make make the distinction ever more apparent, the classes that handle the different inspections will be referred to as “methods” instead of “strategies” in the class names.\n\nsource\n\nInspectionMethod\n\n InspectionMethod ()\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nInspectStackIn3D\n\n InspectStackIn3D ()\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nInspectSinglePlane\n\n InspectSinglePlane ()\n\nHelper class that provides a standard way to create an ABC using inheritance."
  },
  {
    "objectID": "postprocessing_00_specs.html",
    "href": "postprocessing_00_specs.html",
    "title": "Specifications of postprocessing specific subclasses",
    "section": "",
    "text": "source\n\nPostprocessingStrategy\n\n PostprocessingStrategy ()\n\nExtending the ProcssingStrategy base class for postprocessing as processing subtype.\n\nsource\n\n\nPostprocessingObject\n\n PostprocessingObject ()\n\nExtending the ProcessingObject base class for postprocessing as processing subtype."
  },
  {
    "objectID": "database.html",
    "href": "database.html",
    "title": "database",
    "section": "",
    "text": "source\n\nDatabase\n\n Database (project_configs:findmycells.configs.ProjectConfigs)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nFileHistory\n\n FileHistory (file_id:str, source_image_filepath:pathlib.PosixPath)\n\nInitialize self. See help(type(self)) for accurate signature."
  },
  {
    "objectID": "quantification_01_strategies.html",
    "href": "quantification_01_strategies.html",
    "title": "Quantification strategies",
    "section": "",
    "text": "source\n\nCountFeaturesInWholeAreaROIsStrat\n\n CountFeaturesInWholeAreaROIsStrat ()\n\nStrategy description"
  },
  {
    "objectID": "preprocessing/preprocessing_01_strategies.html",
    "href": "preprocessing/preprocessing_01_strategies.html",
    "title": "Preprocessing strategies",
    "section": "",
    "text": "source\n\nCropStitchingArtefactsRGBStrat\n\n CropStitchingArtefactsRGBStrat ()\n\nWhen you acquire microscopy images that are essentially several individual images (= tiles) stitched together, you may end up with some artefacts on the borders of the image as a result from the stitching process. These pixels are usually either fully black or fully white and can therefore interfere with other processing strategies that you might want to apply to your images (for instance, if you´d like to adjust brightness and contrast). This strategy aims at identifying these pixels that were added to account for some offset between the individual tiles and eventually remove them. As these artefacts might interfere with other processing steps, it is recommended to add this (or any other cropping strategy to get rid of these artefacts) prior to other preprocessing strategies.\n\nsource\n\n\nCropToROIsBoundingBoxStrat\n\n CropToROIsBoundingBoxStrat ()\n\nYou might not be interested in analyzing the entire image, but only to quantify image features of interest in a certain region of your image (or actually also several regions). Now, chances are that it is possible to find a bounding box that contains all regions of the image that you are interested in, which is, however, smaller than the original image. Cropping your original image down to that smaller size will then significantly reduce computation time, required memory space, and also required disk space. Therefore, it is highly recommended to add this strategy to your preprocessing. You can also combine it with additional cropping strategies, like the one that tries to remove stitching artefacts.\n\nsource\n\n\nConvertTo8BitStrat\n\n ConvertTo8BitStrat ()\n\nThis strategy converts your image to an 8-bit format. Adding this strategy is at the moment mandatory, as all implemented segmentation tools (deepflash2 & cellpose) require 8-bit as input format. So you actually don´t really have a choice but adding it! :-)\n\nsource\n\n\nMaximumIntensityProjectionStrat\n\n MaximumIntensityProjectionStrat ()\n\nIf you acquired your microscopy images as z-stack, you can use this strategy to project it from a 3D image stack (commonly referred to as 2.5D) into a two dimensional single plane image. If you select this strategy, the brightest (= maximal) pixel value from the z-stack will be used in the final 2D projection. Alternatively, feel free to use the “Minimum intenstity projection” strategy, if you´d like to keep only the darkest (= minimal) value of each pixel.\n\nsource\n\n\nMinimumIntensityProjectionStrat\n\n MinimumIntensityProjectionStrat ()\n\nIf you acquired your microscopy images as z-stack, you can use this strategy to project it from a 3D image stack (commonly referred to as 2.5D) into a two dimensional single plane image. If you select this strategy, the darkest (= minimal) pixel value from the z-stack will be used in the final 2D projection. Alternatively, feel free to use the “Maximum intenstity projection” strategy, if you´d like to keep only the brightest (= maximal) value of each pixel.\n\nsource\n\n\nAdjustBrightnessAndContrastStrat\n\n AdjustBrightnessAndContrastStrat ()\n\nThis strategy allows you to automatically adjust brightness and contrast of your images. For this, please specify the percentage of pixels that you want to be saturated (default: 0.35 % - same as in ImageJ2). This strategy will then ensure that this specified percentage of pixels will be fully saturated in all of your images. If you have z-stack images, you can furthermore also specify whether you´d like to run this operation on the full z-stack (chose “globally”), or on each individual plane of the z-stack (chose “individually”). I would rather recommend using “globally” to keep a somewhat consistent meaning of pixel intensities. And, finally, if you are anyhow dealing with 2D images (either from the get-go, or since you applied a maximum or minimum intensity projection strategy prior to this one - both “globally” and “individually” will lead to the same result."
  },
  {
    "objectID": "preprocessing/preprocessing_00_specs.html",
    "href": "preprocessing/preprocessing_00_specs.html",
    "title": "Specifications of preprocessing specific subclasses",
    "section": "",
    "text": "source\n\nPreprocessingStrategy\n\n PreprocessingStrategy ()\n\nExtending the ProcssingStrategy base class for preprocessing as processing subtype.\n\nsource\n\n\nPreprocessingObject\n\n PreprocessingObject ()\n\nExtending the ProcessingObject base class for preprocessing as processing subtype. Responsible for loading the microscopy image(s) and corresponding ROI(s) for each file, running the specified preprocessing strategies, updating the database, and eventually for saving the preprocessed images to disk for further processing steps down the line.\nNote: Even though the file_ids argument accepts (and actually expects & requires) a list as input, only a single file_id will be passed to a PreprocessingObject upon initialization. This is handled in the api module of findmycells."
  },
  {
    "objectID": "segmentation/segmentation_01_strategies.html",
    "href": "segmentation/segmentation_01_strategies.html",
    "title": "Segmentation strategies",
    "section": "",
    "text": "source\n\nDeepflash2SemanticSegmentationStrat\n\n Deepflash2SemanticSegmentationStrat ()\n\nRun semantic segmentation using deepflash2. Requires that you have already an ensemble of trained models ready to use and to provide the path to the directory where these models can be found. If you choose to process the files in your project in smaller batches (which is highly recommended, due to a huge memory load), make sure to run the segmentations “strategy-wise” in the processing configs below before launching the processing (i.e. keep the box checked).\n\nsource\n\n\nLosslessConversionOfDF2SemanticSegToInstanceSegWithCPStrat\n\n LosslessConversionOfDF2SemanticSegToInstanceSegWithCPStrat ()\n\nExtending the ProcssingStrategy base class for segmentation as processing subtype. Also adding another property that denotes the type of segmentation (i.e. instance or semantic)."
  },
  {
    "objectID": "segmentation/segmentation_00_specs.html",
    "href": "segmentation/segmentation_00_specs.html",
    "title": "Specifications of segmentation specific subclasses",
    "section": "",
    "text": "source\n\nSegmentationStrategy\n\n SegmentationStrategy ()\n\nExtending the ProcssingStrategy base class for segmentation as processing subtype. Also adding another property that denotes the type of segmentation (i.e. instance or semantic).\n\nsource\n\n\nSegmentationObject\n\n SegmentationObject ()\n\nExtending the ProcessingObject base class for segmentation as processing subtype. The clear_all_tmp_data() method allows to clear all chached results that might accumulate for instance while using deepflash2."
  },
  {
    "objectID": "readers/readers_02_rois.html",
    "href": "readers/readers_02_rois.html",
    "title": "ROI readers",
    "section": "",
    "text": "source\n\nROIReaders\n\n ROIReaders ()\n\nReturn the roi(s) as shapely.geometry.Polygon(s) in a nested dictionary with structure: {plane_id: {roi_id: Polygon}} In case plane-specific ROIs are required / requested at some point, having the additional level that enables the reference to plane_id(s) should foster the implementation. The current implementation, however, only supports the use of ROIs for all planes - the corresponding plane_id is hence: ‘all_planes’ Ultimately, this file_id specific dictionary can then be integrated into the ‘rois_as_shapely_polygons’ attribute of the database.\nNote: If multiple ROIs are used for one image, the individual ROIs must be named properly in the ROIManager-Tool in ImageJ. For instance, if images of the hippocampus are investigated & they can contain images of the DG, CA3 and CA1, the corresponding ROIs that mark the respective area have to be named consistenly for all .zip files. This makes it possible, that findmycells can handle the analysis even if not all ROIs are present for each image, e.g. for some files only DG and CA3.\n\nsource\n\n\nImageJROIReader\n\n ImageJROIReader ()\n\nReturn the roi(s) as shapely.geometry.Polygon(s) in a nested dictionary with structure: {plane_id: {roi_id: Polygon}} In case plane-specific ROIs are required / requested at some point, having the additional level that enables the reference to plane_id(s) should foster the implementation. The current implementation, however, only supports the use of ROIs for all planes - the corresponding plane_id is hence: ‘all_planes’ Ultimately, this file_id specific dictionary can then be integrated into the ‘rois_as_shapely_polygons’ attribute of the database.\nNote: If multiple ROIs are used for one image, the individual ROIs must be named properly in the ROIManager-Tool in ImageJ. For instance, if images of the hippocampus are investigated & they can contain images of the DG, CA3 and CA1, the corresponding ROIs that mark the respective area have to be named consistenly for all .zip files. This makes it possible, that findmycells can handle the analysis even if not all ROIs are present for each image, e.g. for some files only DG and CA3."
  },
  {
    "objectID": "readers/readers_01_microscopy_images.html",
    "href": "readers/readers_01_microscopy_images.html",
    "title": "microscopy image data readers",
    "section": "",
    "text": "source\n\nMicroscopyImageReaders\n\n MicroscopyImageReaders ()\n\nThe read method of MicroscopyImageReaders subclasses has to return a numpy array with the following structure: [imaging-planes, rows, columns, color-channels] For instance, an array of a RGB z-stack with 10 image planes of 1024x1024 pixels will have a shape of: [10, 1024, 1024, 3] To improve re-usability of the same functions for all different kinds of input images, this structure will be used even if there is just a single plane. For instance, the shape of the array of a grayscale 2D image with 1024 x 1024 pixels will look like this: [1, 1024, 1024, 1]\n\nsource\n\n\nCZIReader\n\n CZIReader ()\n\nThis reader enables loading of images acquired with the ZEN imaging software by Zeiss, using the czifile package. Note: the first three dimensions are entirely guessed, it could well be that they reflect different things and not “version_idx”, “tile_row_idx”, “tile_col_idx”!\n\nsource\n\n\nRegularImageFiletypeReader\n\n RegularImageFiletypeReader ()\n\nThis reader enables loading of all regular image filetypes, that scikit-image can read, using the scikit-image.io.imread function. Note: So far only single plane images are supported (yet, both single-color & multi-color channel images are supported)!\n\nsource\n\n\nFromExcelReader\n\n FromExcelReader ()\n\nThis reader is actually only a wrapper to the other MicroscopyImageReaders subclasses. It can be used if you stored the filepaths to your individual plane images in an excel sheet, for instance if you were using our “prepare my data for findmycells” functions. Please be aware that the corresponding datatype has to be loadable with any of the corresponding MicroscopyImageReaders!"
  },
  {
    "objectID": "readers/readers_00_specs.html",
    "href": "readers/readers_00_specs.html",
    "title": "Specification of default values of available data readers",
    "section": "",
    "text": "source\n\nReaderSpecsABC\n\n ReaderSpecsABC ()\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nMicroscopyReaderSpecs\n\n MicroscopyReaderSpecs ()\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nROIReaderSpecs\n\n ROIReaderSpecs ()\n\nfindmycells enables analyses of multiple ROIs in the image data. To do so, they will be matched based on their ID that will be retrieved from the ROI file. Some softwares that create these ROI-files, however, create default IDs for the individual ROIs that will interfere with this matching. For instance, in Fiji / ImageJ2, created ROIs get its centroid (?) pixel coordinates as default ID (e.g. something like “523-378”). Since such default IDs most likely won´t be consistent throughout your entire image dataset, findmycells provides you with two options to adress this: a) You can set ‘load_roi_ids_from_file’ to False (default): This will cause findmycells to ignore the IDs of the ROIs that are saved in the provided ROI file and assign them with new IDs starting at “000”. Note: Essentially, this requires you to have always the same type of ROIs present in the exact same order in all your ROI-files. It is therefore only recommended if you have just a single ROI you´d like to analyze. b) You can set ‘load_roi_ids_from_file’ to True (recommended if you have more than a single ROI): This will enforce that findmycells uses the IDs that each ROI was saved with. Therefore, it requires that you use consistent naming of the ROIs with your preferred software. For instance, if you´re using Fiji / ImageJ2, you can rename each ROI in the ROIManager (e.g. “CA3”, “vlPAG”, or “ipsilateral_SNc”). Analyses and quantifications will then be matched and pooled across all ROIs with the respective IDs (e.g. all “CA3” ROIs)."
  },
  {
    "objectID": "preprocessing/index.html",
    "href": "preprocessing/index.html",
    "title": "preprocessing",
    "section": "",
    "text": "The following submodules implement everything related to preprocessing of your image data in findmycells.\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nPreprocessing strategies\n\n\nThis module defines all available preprocessing strategies (= preprocessing options)\n\n\n\n\nSpecifications of preprocessing specific subclasses\n\n\nThis module defines the specifications of preprocessing related subclasses of ProcessingStrategy and ProcessingObject\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "processing submodules/preprocessing_01_strategies.html",
    "href": "processing submodules/preprocessing_01_strategies.html",
    "title": "Preprocessing strategies",
    "section": "",
    "text": "source\n\nCropStitchingArtefactsRGBStrat\n\n CropStitchingArtefactsRGBStrat ()\n\nWhen you acquire microscopy images that are essentially several individual images (= tiles) stitched together, you may end up with some artefacts on the borders of the image as a result from the stitching process. These pixels are usually either fully black or fully white and can therefore interfere with other processing strategies that you might want to apply to your images (for instance, if you´d like to adjust brightness and contrast). This strategy aims at identifying these pixels that were added to account for some offset between the individual tiles and eventually remove them. As these artefacts might interfere with other processing steps, it is recommended to add this (or any other cropping strategy to get rid of these artefacts) prior to other preprocessing strategies.\n\nsource\n\n\nCropToROIsBoundingBoxStrat\n\n CropToROIsBoundingBoxStrat ()\n\nYou might not be interested in analyzing the entire image, but only to quantify image features of interest in a certain region of your image (or actually also several regions). Now, chances are that it is possible to find a bounding box that contains all regions of the image that you are interested in, which is, however, smaller than the original image. Cropping your original image down to that smaller size will then significantly reduce computation time, required memory space, and also required disk space. Therefore, it is highly recommended to add this strategy to your preprocessing. You can also combine it with additional cropping strategies, like the one that tries to remove stitching artefacts.\n\nsource\n\n\nConvertTo8BitStrat\n\n ConvertTo8BitStrat ()\n\nThis strategy converts your image to an 8-bit format. Adding this strategy is at the moment mandatory, as all implemented segmentation tools (deepflash2 & cellpose) require 8-bit as input format. So you actually don´t really have a choice but adding it! :-)\n\nsource\n\n\nMaximumIntensityProjectionStrat\n\n MaximumIntensityProjectionStrat ()\n\nIf you acquired your microscopy images as z-stack, you can use this strategy to project it from a 3D image stack (commonly referred to as 2.5D) into a two dimensional single plane image. If you select this strategy, the brightest (= maximal) pixel value from the z-stack will be used in the final 2D projection. Alternatively, feel free to use the “Minimum intenstity projection” strategy, if you´d like to keep only the darkest (= minimal) value of each pixel.\n\nsource\n\n\nMinimumIntensityProjectionStrat\n\n MinimumIntensityProjectionStrat ()\n\nIf you acquired your microscopy images as z-stack, you can use this strategy to project it from a 3D image stack (commonly referred to as 2.5D) into a two dimensional single plane image. If you select this strategy, the darkest (= minimal) pixel value from the z-stack will be used in the final 2D projection. Alternatively, feel free to use the “Maximum intenstity projection” strategy, if you´d like to keep only the brightest (= maximal) value of each pixel.\n\nsource\n\n\nAdjustBrightnessAndContrastStrat\n\n AdjustBrightnessAndContrastStrat ()\n\nThis strategy allows you to automatically adjust brightness and contrast of your images. For this, please specify the percentage of pixels that you want to be saturated (default: 0.35 % - same as in ImageJ2). This strategy will then ensure that this specified percentage of pixels will be fully saturated in all of your images. If you have z-stack images, you can furthermore also specify whether you´d like to run this operation on the full z-stack (chose “globally”), or on each individual plane of the z-stack (chose “individually”). I would rather recommend using “globally” to keep a somewhat consistent meaning of pixel intensities. And, finally, if you are anyhow dealing with 2D images (either from the get-go, or since you applied a maximum or minimum intensity projection strategy prior to this one - both “globally” and “individually” will lead to the same result."
  },
  {
    "objectID": "processing submodules/index.html",
    "href": "processing submodules/index.html",
    "title": "Processing step specific submodules",
    "section": "",
    "text": "The following submodules implement everything related to the individual processing steps (i.e. “preprocessing”, “segmentation”, “postprocessing”, and “quantification” of your image data in findmycells.\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nSpecifications of preprocessing specific subclasses\n\n\nThis module defines the specifications of preprocessing related subclasses of ProcessingStrategy and ProcessingObject\n\n\n\n\nPreprocessing strategies\n\n\nThis module defines all available preprocessing strategies (= preprocessing options)\n\n\n\n\nSpecifications of segmentation specific subclasses\n\n\nThis module defines the specifications of segmentation related subclasses of ProcessingStrategy and ProcessingObject\n\n\n\n\nSegmentation strategies\n\n\nThis module defines all available segmentation strategies (= segmentation options)\n\n\n\n\nSpecifications of postprocessing specific subclasses\n\n\nThis module defines the specifications of postprocessing related subclasses of ProcessingStrategy and ProcessingObject\n\n\n\n\nPostprocessing strategies\n\n\nThis module defines all available postprocessing strategies (= postprocessing options)\n\n\n\n\nSpecifications of quantification specific subclasses\n\n\nThis module defines the specifications of quantification related subclasses of ProcessingStrategy and ProcessingObject\n\n\n\n\nQuantification strategies\n\n\nThis module defines all available quantification strategies (= quantification options)\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "processing submodules/quantification_00_specs.html",
    "href": "processing submodules/quantification_00_specs.html",
    "title": "Specifications of quantification specific subclasses",
    "section": "",
    "text": "source\n\nQuantificationStrategy\n\n QuantificationStrategy ()\n\nNote for developers: When implementing a new quantification strategy, remember to add the following line at the end of the “.run()” method, to ensure that the quantification results are added to the database:\nquantification_object = self._add_quantification_results_to_database(quantification_object = quantification_object, results = quantification_results)\n\nsource\n\n\nQuantificationObject\n\n QuantificationObject ()\n\nExtending the ProcessingObject base class for quantification as processing subtype."
  },
  {
    "objectID": "processing submodules/preprocessing_00_specs.html",
    "href": "processing submodules/preprocessing_00_specs.html",
    "title": "Specifications of preprocessing specific subclasses",
    "section": "",
    "text": "source\n\nPreprocessingStrategy\n\n PreprocessingStrategy ()\n\nExtending the ProcssingStrategy base class for preprocessing as processing subtype.\n\nsource\n\n\nPreprocessingObject\n\n PreprocessingObject ()\n\nExtending the ProcessingObject base class for preprocessing as processing subtype. Responsible for loading the microscopy image(s) and corresponding ROI(s) for each file, running the specified preprocessing strategies, updating the database, and eventually for saving the preprocessed images to disk for further processing steps down the line.\nNote: Even though the file_ids argument accepts (and actually expects & requires) a list as input, only a single file_id will be passed to a PreprocessingObject upon initialization. This is handled in the api module of findmycells."
  },
  {
    "objectID": "processing submodules/segmentation_01_strategies.html",
    "href": "processing submodules/segmentation_01_strategies.html",
    "title": "Segmentation strategies",
    "section": "",
    "text": "source\n\nDeepflash2SemanticSegmentationStrat\n\n Deepflash2SemanticSegmentationStrat ()\n\nRun semantic segmentation using deepflash2. Requires that you have already an ensemble of trained models ready to use and to provide the path to the directory where these models can be found. If you choose to process the files in your project in smaller batches (which is highly recommended, due to a huge memory load), make sure to run the segmentations “strategy-wise” in the processing configs below before launching the processing (i.e. keep the box checked).\n\nsource\n\n\nLosslessConversionOfDF2SemanticSegToInstanceSegWithCPStrat\n\n LosslessConversionOfDF2SemanticSegToInstanceSegWithCPStrat ()\n\nExtending the ProcssingStrategy base class for segmentation as processing subtype. Also adding another property that denotes the type of segmentation (i.e. instance or semantic)."
  },
  {
    "objectID": "processing submodules/segmentation_00_specs.html",
    "href": "processing submodules/segmentation_00_specs.html",
    "title": "Specifications of segmentation specific subclasses",
    "section": "",
    "text": "source\n\nSegmentationStrategy\n\n SegmentationStrategy ()\n\nExtending the ProcssingStrategy base class for segmentation as processing subtype. Also adding another property that denotes the type of segmentation (i.e. instance or semantic).\n\nsource\n\n\nSegmentationObject\n\n SegmentationObject ()\n\nExtending the ProcessingObject base class for segmentation as processing subtype. The clear_all_tmp_data() method allows to clear all chached results that might accumulate for instance while using deepflash2."
  },
  {
    "objectID": "processing submodules/postprocessing_01_strategies.html",
    "href": "processing submodules/postprocessing_01_strategies.html",
    "title": "Postprocessing strategies",
    "section": "",
    "text": "source\n\nReconstructCellsIn3DFrom2DInstanceLabelsStrat\n\n ReconstructCellsIn3DFrom2DInstanceLabelsStrat ()\n\nDescription; Include requirements Mention multi matches traceback which can be used in inspection\n\nsource\n\n\nFillHolesStrat\n\n FillHolesStrat ()\n\nSpecific conditions can lead to “holes” within the segmentations of your image features. This can make total sense, for instance if youre analyzing specifically the cells cytoplasm, and want to spare out the nucleus, or if youre analyzing ring-like features. In other cases, however, these “holes” may be artefacts and require correction. This strategy was designed for exactly this purpose: fill the “holes” in your segmented features, if they should not be there.\n\nsource\n\n\nApplyExclusionCriteriaStrat\n\n ApplyExclusionCriteriaStrat ()\n\nAnother typical postprocessing step is to filter your data by applying exclusion criteria. Please check the following list of exclusion criteria with detailed descriptions to see which criteria are currently implemented in your installed findmycells version. Importantly, if you would like to use this strategy, please make sure to run this strategy as the last postprocessing strategy, to ensure that all other processing steps have been completed. \b \u0001- Minimum feature position relative to area ROI: \u0001If you provided ROIs that denote in which area of each image you’d like to quantify the image features, you can use this criterion to specify when to exclude detected features from the quantification. These are the options you can chose from, in order of increasing distance of your feature from the area ROI: within < intersects < touches < no overlap The option you select will always be the first relative position to be included. For example, if you select “intersects”, all features that are fully within your area ROI (classified as “within”) and all features that are intersected by the area ROI border (classified as “intersects”) will be kept, while all features that only touch the area ROI border (classified as “touches”) or that lie completely outside of it (classified as “no overlap”) will be excluded from further analyses. Note: if you are analyzing an image stack, a features` position can be classified differently depending on the image plane. Findmycells will always use the nearest classification. That means, if a feature was classified in one plane as “within” but only as “intersects” or even as “no overlap” in the other planes, the entire 3D feature will be classified as “within”.\u0002\u0002 \b \u0001- Minimum feature size [px]: \u0001Every detected feature whose area is smaller than the specified pixel value will will be deleted from the segmentation masks. Note: if you are analyzing an image stack, this strategy will determine for each 3D feature the plane in which is has the largest area & then apply this exclusion criterion based on this area value.\u0002\u0002 \b \u0001- Minimum planes covered (only relevant for image stacks): \u0001Similarly to “minimum feature size”, which checks for the expansion of your image features in x-y-dimensions, you can use this exclusion criterion to also check for a minimum size of your features in the z-dimension. The number you specify here will represent the minimum number of consecutive planes each image feature needs to cover to remain in your segmentation masks. For instance, if you specify it to be 3, all features that are only present in a single or in two consecutive planes will be deleted. Note: this exclusion criterion is, obviously, only relevant for projects that analyze image stacks. If you are working only with 2D images, this value will be ignored and 1 will be used as default.\u0002\u0002"
  },
  {
    "objectID": "processing submodules/postprocessing_00_specs.html",
    "href": "processing submodules/postprocessing_00_specs.html",
    "title": "Specifications of postprocessing specific subclasses",
    "section": "",
    "text": "source\n\nPostprocessingStrategy\n\n PostprocessingStrategy ()\n\nExtending the ProcssingStrategy base class for postprocessing as processing subtype.\n\nsource\n\n\nPostprocessingObject\n\n PostprocessingObject ()\n\nExtending the ProcessingObject base class for postprocessing as processing subtype."
  },
  {
    "objectID": "processing submodules/quantification_01_strategies.html",
    "href": "processing submodules/quantification_01_strategies.html",
    "title": "Quantification strategies",
    "section": "",
    "text": "source\n\nCountFeaturesInWholeAreaROIsStrat\n\n CountFeaturesInWholeAreaROIsStrat ()\n\nStrategy description"
  },
  {
    "objectID": "data readers/readers_02_rois.html",
    "href": "data readers/readers_02_rois.html",
    "title": "ROI readers",
    "section": "",
    "text": "source\n\nROIReaders\n\n ROIReaders ()\n\nReturn the roi(s) as shapely.geometry.Polygon(s) in a nested dictionary with structure: {plane_id: {roi_id: Polygon}} In case plane-specific ROIs are required / requested at some point, having the additional level that enables the reference to plane_id(s) should foster the implementation. The current implementation, however, only supports the use of ROIs for all planes - the corresponding plane_id is hence: ‘all_planes’ Ultimately, this file_id specific dictionary can then be integrated into the ‘rois_as_shapely_polygons’ attribute of the database.\nNote: If multiple ROIs are used for one image, the individual ROIs must be named properly in the ROIManager-Tool in ImageJ. For instance, if images of the hippocampus are investigated & they can contain images of the DG, CA3 and CA1, the corresponding ROIs that mark the respective area have to be named consistenly for all .zip files. This makes it possible, that findmycells can handle the analysis even if not all ROIs are present for each image, e.g. for some files only DG and CA3.\n\nsource\n\n\nImageJROIReader\n\n ImageJROIReader ()\n\nReturn the roi(s) as shapely.geometry.Polygon(s) in a nested dictionary with structure: {plane_id: {roi_id: Polygon}} In case plane-specific ROIs are required / requested at some point, having the additional level that enables the reference to plane_id(s) should foster the implementation. The current implementation, however, only supports the use of ROIs for all planes - the corresponding plane_id is hence: ‘all_planes’ Ultimately, this file_id specific dictionary can then be integrated into the ‘rois_as_shapely_polygons’ attribute of the database.\nNote: If multiple ROIs are used for one image, the individual ROIs must be named properly in the ROIManager-Tool in ImageJ. For instance, if images of the hippocampus are investigated & they can contain images of the DG, CA3 and CA1, the corresponding ROIs that mark the respective area have to be named consistenly for all .zip files. This makes it possible, that findmycells can handle the analysis even if not all ROIs are present for each image, e.g. for some files only DG and CA3."
  },
  {
    "objectID": "data readers/readers_01_microscopy_images.html",
    "href": "data readers/readers_01_microscopy_images.html",
    "title": "microscopy image data readers",
    "section": "",
    "text": "source\n\nMicroscopyImageReaders\n\n MicroscopyImageReaders ()\n\nThe read method of MicroscopyImageReaders subclasses has to return a numpy array with the following structure: [imaging-planes, rows, columns, color-channels] For instance, an array of a RGB z-stack with 10 image planes of 1024x1024 pixels will have a shape of: [10, 1024, 1024, 3] To improve re-usability of the same functions for all different kinds of input images, this structure will be used even if there is just a single plane. For instance, the shape of the array of a grayscale 2D image with 1024 x 1024 pixels will look like this: [1, 1024, 1024, 1]\n\nsource\n\n\nCZIReader\n\n CZIReader ()\n\nThis reader enables loading of images acquired with the ZEN imaging software by Zeiss, using the czifile package. Note: the first three dimensions are entirely guessed, it could well be that they reflect different things and not “version_idx”, “tile_row_idx”, “tile_col_idx”!\n\nsource\n\n\nRegularImageFiletypeReader\n\n RegularImageFiletypeReader ()\n\nThis reader enables loading of all regular image filetypes, that scikit-image can read, using the scikit-image.io.imread function. Note: So far only single plane images are supported (yet, both single-color & multi-color channel images are supported)!\n\nsource\n\n\nFromExcelReader\n\n FromExcelReader ()\n\nThis reader is actually only a wrapper to the other MicroscopyImageReaders subclasses. It can be used if you stored the filepaths to your individual plane images in an excel sheet, for instance if you were using our “prepare my data for findmycells” functions. Please be aware that the corresponding datatype has to be loadable with any of the corresponding MicroscopyImageReaders!"
  },
  {
    "objectID": "data readers/readers_00_specs.html",
    "href": "data readers/readers_00_specs.html",
    "title": "Specification of default values of available data readers",
    "section": "",
    "text": "source\n\nReaderSpecsABC\n\n ReaderSpecsABC ()\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nMicroscopyReaderSpecs\n\n MicroscopyReaderSpecs ()\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nROIReaderSpecs\n\n ROIReaderSpecs ()\n\nfindmycells enables analyses of multiple ROIs in the image data. To do so, they will be matched based on their ID that will be retrieved from the ROI file. Some softwares that create these ROI-files, however, create default IDs for the individual ROIs that will interfere with this matching. For instance, in Fiji / ImageJ2, created ROIs get its centroid (?) pixel coordinates as default ID (e.g. something like “523-378”). Since such default IDs most likely won´t be consistent throughout your entire image dataset, findmycells provides you with two options to adress this: a) You can set ‘load_roi_ids_from_file’ to False (default): This will cause findmycells to ignore the IDs of the ROIs that are saved in the provided ROI file and assign them with new IDs starting at “000”. Note: Essentially, this requires you to have always the same type of ROIs present in the exact same order in all your ROI-files. It is therefore only recommended if you have just a single ROI you´d like to analyze. b) You can set ‘load_roi_ids_from_file’ to True (recommended if you have more than a single ROI): This will enforce that findmycells uses the IDs that each ROI was saved with. Therefore, it requires that you use consistent naming of the ROIs with your preferred software. For instance, if you´re using Fiji / ImageJ2, you can rename each ROI in the ROIManager (e.g. “CA3”, “vlPAG”, or “ipsilateral_SNc”). Analyses and quantifications will then be matched and pooled across all ROIs with the respective IDs (e.g. all “CA3” ROIs)."
  },
  {
    "objectID": "API documentation/configs.html",
    "href": "API documentation/configs.html",
    "title": "configs",
    "section": "",
    "text": "Configurations\nThere are several layers that require & allow configuration of findmycells. However, only the top most level (ProjectConfigs) is implemented here. All lower level configs (e.g. configs for each processing type like “preprocessing” or “quantification”, or even lower level configs like for each individual processing step represented by ProcessingStrategy subclasses), will be defined by each of these classes using the DefaultConfigs - which is implemented here. For an example of how the DefaultConfigs shall be used, please have a look at the general implementation of ProcessingObject and ProcessingStrategy in the core module, and then check out the “specs.py” file of the corresponding processing sub-module!\n\nsource\n\nProjectConfigs\n\n ProjectConfigs (root_dir:pathlib.PosixPath)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nDefaultConfigs\n\n DefaultConfigs (default_values:Dict[str,Any],\n                 valid_types:Dict[str,List[type]],\n                 valid_value_ranges:Optional[Dict[str,Tuple]]=None,\n                 valid_value_options:Optional[Dict[str,Tuple]]=None)\n\nThis class has to be specified as an attribute in several classes throughout findmycells and allows / ensures that each novel class defines its own set of default config values. Moreover, the ‘valid_types’ dictionary also defines which types of values are allowed.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndefault_values\ntyping.Dict[str, typing.Any]\n\nKeys are identifier of config options, values the corresponding default value\n\n\nvalid_types\ntyping.Dict[str, typing.List[type]]\n\nKeys must match with keys of “default_values”, values are lists of allowed types\n\n\nvalid_value_ranges\ntyping.Optional[typing.Dict[str, typing.Tuple]]\nNone\nRequired for every config option that allows floats or integers. Keys must match with keys of “default_values”. Expected format: (start_idx, end_idx) or (start_idx, end_idx, step_size)\n\n\nvalid_value_options\ntyping.Optional[typing.Dict[str, typing.Tuple]]\nNone\nKeys must match with keys of “default_values”. Expected format: (‘option_a’, ‘option_b’, …)\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\n\nGUIConfigs\n\n GUIConfigs (widget_names:Dict[str,str], descriptions:Dict[str,str],\n             tooltips:Optional[Dict[str,str]]=None)\n\nNote for developers: The docstrings of each processing strategy will also be used to display the description of each strategy in both the GUI and in the online hosted documentation. To improve the layout of these displayed HTML elements, we introduced some custom “string commands”. Their use is described in detail in the docstring of the “_convert_docstring_to_html()” method of this class."
  },
  {
    "objectID": "API documentation/core.html",
    "href": "API documentation/core.html",
    "title": "core",
    "section": "",
    "text": "Handling data processing\nThe following two classes, ProcessingObject and ProcessingStrategy, provide the blueprints for all processing strategies and objects that are used throughout the findmycells package. As you can see in the corresponding processing step modules (i.e. “preprocess”, “segment”, or “quantify”), these abstract base classes provide the basic structure of the more specific objects and strategies in each of these modules (e.g. QuantificationObject and QuantificationStrategy within the “quantify” module inherit from ProcessingObject and ProcessingStrategy, respectively). While this makes these two classes highly relevant for any developer, regular users of findmycells won´t be interacting with them, even if they want to use the API instead of the GUI.\n\nsource\n\nProcessingObject\n\n ProcessingObject ()\n\nAbstract base class (inherits from ABC) that defines the general structure of ProcessingObjects in findmycells. A ProcessingObject combines all information needed for the corresponding processing step, i.e. what files are supposed to be processed & how. It also interfaces to the database of the project, such that it can automatically update the database with the latest progress.\nSubclasses that inherit from ProcessingObject need to implement the following two abstract methods:\n\nsource\n\n\nProcessingObject.processing_type\n\n ProcessingObject.processing_type ()\n\nAbstract method that requires its subclasses to define the processing_type as a property of the class. Thus, this will be specified in each individual processing module (e.g. the “preprocess” or “quantify” modules). It will be used in the database to keep track of the processing progress of the project. Has to be a string.\n\nsource\n\n\nProcessingObject._add_processing_specific_infos_to_updates\n\n ProcessingObject._add_processing_specific_infos_to_updates (updates:Dict)\n\nAbstract method that that requires its subclasses to define what updates need to be passed to the database, in addition to those that are already covered by the corresponding ProcessingStrategies or the “self.update_database()” method. If there are no more information to add, simply return the input ‘updates’ dictionary without any alterations.\nReturns a dictionary with all updates that need to be passed to the database.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nupdates\ntyping.Dict\nA dictionary with updates that need to be passed to the database\n\n\nReturns\ntyping.Dict\nA dictionary with all updates that need to be passed to the database\n\n\n\nIn addition, ProcessingObject defines two core functions that will be called on all its subclasses, which are:\n\nsource\n\n\nProcessingObject.run_all_strategies\n\n ProcessingObject.run_all_strategies (strategies:List,\n                                      strategy_configs:List[Dict])\n\nRuns all ProcessingStrategies that were passed upon initialization (i.e. self.strategies). For this, the corresponding ProcessingStrategy objects will be initialized and their “.run()” method will be called, while passing “self” as “processing_object”. Finally, it updates the database and deletes the ProcessingStrategy object to clear it from memory.\n\nsource\n\n\nProcessingObject.update_database\n\n ProcessingObject.update_database (mark_as_completed:bool=True)\n\nFor each microscopy file that had to be processed (self.file_ids), the database will be updated with the respective processing progress information. Interfaces back to the abstract method “self.add_processing_specific_infos_to_updates()” that enables the corresponding subclasses to add more specific details before triggering the update method of the database.\n\nsource\n\n\nProcessingStrategy\n\n ProcessingStrategy ()\n\nAbstract base class that defines the general structure of ProcessingStrategies in findmycells. A ProcessingStrategy combines all functions that are required for one particular processing step, e.g. ConvertTo8Bit is a ProcessingStrategy in the “preprocess” module and converts the corresponding images into 8-bit.\n\n\n\nHandling data reading\nFurthermore, the following two classes DataLoader and DataReader will be re-used throughout the findmycells package to load data into your findmycells project.\n\nsource\n\nDataReader\n\n DataReader ()\n\nAbstract base class that defines the general structure of DataReader subclasses. Essentially, it demands the corresponding subclasses to define the “readable_filetype_extensions” attribut, as well as the “set_optional_configs()” and the “read()” methods.\n\nsource\n\n\nDataLoader\n\n DataLoader ()\n\nInitialize self. See help(type(self)) for accurate signature."
  },
  {
    "objectID": "API documentation/processing submodules/preprocessing_01_strategies.html",
    "href": "API documentation/processing submodules/preprocessing_01_strategies.html",
    "title": "preprocessing strategies",
    "section": "",
    "text": "source\n\nCropStitchingArtefactsRGBStrat\n\n CropStitchingArtefactsRGBStrat ()\n\nWhen you acquire microscopy images that are essentially several individual images (= tiles) stitched together, you may end up with some artefacts on the borders of the image as a result from the stitching process. These pixels are usually either fully black or fully white and can therefore interfere with other processing strategies that you might want to apply to your images (for instance, if you´d like to adjust brightness and contrast). This strategy aims at identifying these pixels that were added to account for some offset between the individual tiles and eventually remove them. As these artefacts might interfere with other processing steps, it is recommended to add this (or any other cropping strategy to get rid of these artefacts) prior to other preprocessing strategies.\n\nsource\n\n\nCropToROIsBoundingBoxStrat\n\n CropToROIsBoundingBoxStrat ()\n\nYou might not be interested in analyzing the entire image, but only to quantify image features of interest in a certain region of your image (or actually also several regions). Now, chances are that it is possible to find a bounding box that contains all regions of the image that you are interested in, which is, however, smaller than the original image. Cropping your original image down to that smaller size will then significantly reduce computation time, required memory space, and also required disk space. Therefore, it is highly recommended to add this strategy to your preprocessing. You can also combine it with additional cropping strategies, like the one that tries to remove stitching artefacts.\n\nsource\n\n\nConvertTo8BitStrat\n\n ConvertTo8BitStrat ()\n\nThis strategy converts your image to an 8-bit format. Adding this strategy is at the moment mandatory, as all implemented segmentation tools (deepflash2 & cellpose) require 8-bit as input format. So you actually don´t really have a choice but adding it! :-)\n\nsource\n\n\nMaximumIntensityProjectionStrat\n\n MaximumIntensityProjectionStrat ()\n\nIf you acquired your microscopy images as z-stack, you can use this strategy to project it from a 3D image stack (commonly referred to as 2.5D) into a two dimensional single plane image. If you select this strategy, the brightest (= maximal) pixel value from the z-stack will be used in the final 2D projection. Alternatively, feel free to use the “Minimum intenstity projection” strategy, if you´d like to keep only the darkest (= minimal) value of each pixel.\n\nsource\n\n\nMinimumIntensityProjectionStrat\n\n MinimumIntensityProjectionStrat ()\n\nIf you acquired your microscopy images as z-stack, you can use this strategy to project it from a 3D image stack (commonly referred to as 2.5D) into a two dimensional single plane image. If you select this strategy, the darkest (= minimal) pixel value from the z-stack will be used in the final 2D projection. Alternatively, feel free to use the “Maximum intenstity projection” strategy, if you´d like to keep only the brightest (= maximal) value of each pixel.\n\nsource\n\n\nAdjustBrightnessAndContrastStrat\n\n AdjustBrightnessAndContrastStrat ()\n\nThis strategy allows you to automatically adjust brightness and contrast of your images. For this, please specify the percentage of pixels that you want to be saturated (default: 0.35 % - same as in ImageJ2). This strategy will then ensure that this specified percentage of pixels will be fully saturated in all of your images. If you have z-stack images, you can furthermore also specify whether you´d like to run this operation on the full z-stack (chose “globally”), or on each individual plane of the z-stack (chose “individually”). I would rather recommend using “globally” to keep a somewhat consistent meaning of pixel intensities. And, finally, if you are anyhow dealing with 2D images (either from the get-go, or since you applied a maximum or minimum intensity projection strategy prior to this one - both “globally” and “individually” will lead to the same result."
  },
  {
    "objectID": "API documentation/processing submodules/index.html",
    "href": "API documentation/processing submodules/index.html",
    "title": "Processing step specific submodules",
    "section": "",
    "text": "The following submodules implement everything related to the individual processing steps (i.e. “preprocessing”, “segmentation”, “postprocessing”, and “quantification” of your image data in findmycells.\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\npreprocessing related subclasses\n\n\nThis module implements the preprocessing-related subclasses of ProcessingStrategy and ProcessingObject\n\n\n\n\npreprocessing strategies\n\n\nThis module defines all available preprocessing strategies (= preprocessing options)\n\n\n\n\nsegmentation related subclasses\n\n\nThis module implements the segmentation-related subclasses of ProcessingStrategy and ProcessingObject\n\n\n\n\nsegmentation strategies\n\n\nThis module defines all available segmentation strategies (= segmentation options)\n\n\n\n\npostprocessing related subclasses\n\n\nThis module implements the postprocessing-related subclasses of ProcessingStrategy and ProcessingObject\n\n\n\n\npostprocessing strategies\n\n\nThis module defines all available postprocessing strategies (= postprocessing options)\n\n\n\n\nquantification related subclasses\n\n\nThis module implements the quantification-related subclasses of ProcessingStrategy and ProcessingObject\n\n\n\n\nquantification strategies\n\n\nThis module defines all available quantification strategies (= quantification options)\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "API documentation/processing submodules/quantification_00_specs.html",
    "href": "API documentation/processing submodules/quantification_00_specs.html",
    "title": "quantification related subclasses",
    "section": "",
    "text": "source\n\nQuantificationStrategy\n\n QuantificationStrategy ()\n\nNote for developers: When implementing a new quantification strategy, remember to add the following line at the end of the “.run()” method, to ensure that the quantification results are added to the database:\nquantification_object = self._add_quantification_results_to_database(quantification_object = quantification_object, results = quantification_results)\n\nsource\n\n\nQuantificationObject\n\n QuantificationObject ()\n\nExtending the ProcessingObject base class for quantification as processing subtype."
  },
  {
    "objectID": "API documentation/processing submodules/preprocessing_00_specs.html",
    "href": "API documentation/processing submodules/preprocessing_00_specs.html",
    "title": "preprocessing related subclasses",
    "section": "",
    "text": "source\n\nPreprocessingStrategy\n\n PreprocessingStrategy ()\n\nExtending the ProcssingStrategy base class for preprocessing as processing subtype.\n\nsource\n\n\nPreprocessingObject\n\n PreprocessingObject ()\n\nExtending the ProcessingObject base class for preprocessing as processing subtype. Responsible for loading the microscopy image(s) and corresponding ROI(s) for each file, running the specified preprocessing strategies, updating the database, and eventually for saving the preprocessed images to disk for further processing steps down the line.\nNote: Even though the file_ids argument accepts (and actually expects & requires) a list as input, only a single file_id will be passed to a PreprocessingObject upon initialization. This is handled in the api module of findmycells."
  },
  {
    "objectID": "API documentation/processing submodules/segmentation_01_strategies.html",
    "href": "API documentation/processing submodules/segmentation_01_strategies.html",
    "title": "segmentation strategies",
    "section": "",
    "text": "source\n\nDeepflash2SemanticSegmentationStrat\n\n Deepflash2SemanticSegmentationStrat ()\n\nRun semantic segmentation using deepflash2. Requires that you have already an ensemble of trained models ready to use and to provide the path to the directory where these models can be found. If you choose to process the files in your project in smaller batches (which is highly recommended, due to a huge memory load), make sure to run the segmentations “strategy-wise” in the processing configs below before launching the processing (i.e. keep the box checked).\n\nsource\n\n\nLosslessConversionOfDF2SemanticSegToInstanceSegWithCPStrat\n\n LosslessConversionOfDF2SemanticSegToInstanceSegWithCPStrat ()\n\nExtending the ProcssingStrategy base class for segmentation as processing subtype. Also adding another property that denotes the type of segmentation (i.e. instance or semantic)."
  },
  {
    "objectID": "API documentation/processing submodules/segmentation_00_specs.html",
    "href": "API documentation/processing submodules/segmentation_00_specs.html",
    "title": "segmentation related subclasses",
    "section": "",
    "text": "source\n\nSegmentationStrategy\n\n SegmentationStrategy ()\n\nExtending the ProcssingStrategy base class for segmentation as processing subtype. Also adding another property that denotes the type of segmentation (i.e. instance or semantic).\n\nsource\n\n\nSegmentationObject\n\n SegmentationObject ()\n\nExtending the ProcessingObject base class for segmentation as processing subtype. The clear_all_tmp_data() method allows to clear all chached results that might accumulate for instance while using deepflash2."
  },
  {
    "objectID": "API documentation/processing submodules/postprocessing_01_strategies.html",
    "href": "API documentation/processing submodules/postprocessing_01_strategies.html",
    "title": "postprocessing strategies",
    "section": "",
    "text": "source\n\nReconstructCellsIn3DFrom2DInstanceLabelsStrat\n\n ReconstructCellsIn3DFrom2DInstanceLabelsStrat ()\n\nDescription; Include requirements Mention multi matches traceback which can be used in inspection\n\nsource\n\n\nFillHolesStrat\n\n FillHolesStrat ()\n\nSpecific conditions can lead to “holes” within the segmentations of your image features. This can make total sense, for instance if youre analyzing specifically the cells cytoplasm, and want to spare out the nucleus, or if youre analyzing ring-like features. In other cases, however, these “holes” may be artefacts and require correction. This strategy was designed for exactly this purpose: fill the “holes” in your segmented features, if they should not be there.\n\nsource\n\n\nApplyExclusionCriteriaStrat\n\n ApplyExclusionCriteriaStrat ()\n\nAnother typical postprocessing step is to filter your data by applying exclusion criteria. Please check the following list of exclusion criteria with detailed descriptions to see which criteria are currently implemented in your installed findmycells version. Importantly, if you would like to use this strategy, please make sure to run this strategy as the last postprocessing strategy, to ensure that all other processing steps have been completed. \b \u0001- Minimum feature position relative to area ROI: \u0001If you provided ROIs that denote in which area of each image you’d like to quantify the image features, you can use this criterion to specify when to exclude detected features from the quantification. These are the options you can chose from, in order of increasing distance of your feature from the area ROI: within < intersects < touches < no overlap The option you select will always be the first relative position to be included. For example, if you select “intersects”, all features that are fully within your area ROI (classified as “within”) and all features that are intersected by the area ROI border (classified as “intersects”) will be kept, while all features that only touch the area ROI border (classified as “touches”) or that lie completely outside of it (classified as “no overlap”) will be excluded from further analyses. Note: if you are analyzing an image stack, a features` position can be classified differently depending on the image plane. Findmycells will always use the nearest classification. That means, if a feature was classified in one plane as “within” but only as “intersects” or even as “no overlap” in the other planes, the entire 3D feature will be classified as “within”.\u0002\u0002 \b \u0001- Minimum feature size [px]: \u0001Every detected feature whose area is smaller than the specified pixel value will will be deleted from the segmentation masks. Note: if you are analyzing an image stack, this strategy will determine for each 3D feature the plane in which is has the largest area & then apply this exclusion criterion based on this area value.\u0002\u0002 \b \u0001- Minimum planes covered (only relevant for image stacks): \u0001Similarly to “minimum feature size”, which checks for the expansion of your image features in x-y-dimensions, you can use this exclusion criterion to also check for a minimum size of your features in the z-dimension. The number you specify here will represent the minimum number of consecutive planes each image feature needs to cover to remain in your segmentation masks. For instance, if you specify it to be 3, all features that are only present in a single or in two consecutive planes will be deleted. Note: this exclusion criterion is, obviously, only relevant for projects that analyze image stacks. If you are working only with 2D images, this value will be ignored and 1 will be used as default.\u0002\u0002"
  },
  {
    "objectID": "API documentation/processing submodules/postprocessing_00_specs.html",
    "href": "API documentation/processing submodules/postprocessing_00_specs.html",
    "title": "postprocessing related subclasses",
    "section": "",
    "text": "source\n\nPostprocessingStrategy\n\n PostprocessingStrategy ()\n\nExtending the ProcssingStrategy base class for postprocessing as processing subtype.\n\nsource\n\n\nPostprocessingObject\n\n PostprocessingObject ()\n\nExtending the ProcessingObject base class for postprocessing as processing subtype."
  },
  {
    "objectID": "API documentation/processing submodules/quantification_01_strategies.html",
    "href": "API documentation/processing submodules/quantification_01_strategies.html",
    "title": "quantification strategies",
    "section": "",
    "text": "source\n\nCountFeaturesInWholeAreaROIsStrat\n\n CountFeaturesInWholeAreaROIsStrat ()\n\nStrategy description"
  },
  {
    "objectID": "API documentation/data readers/readers_02_rois.html",
    "href": "API documentation/data readers/readers_02_rois.html",
    "title": "ROI readers",
    "section": "",
    "text": "source\n\nROIReaders\n\n ROIReaders ()\n\nReturn the roi(s) as shapely.geometry.Polygon(s) in a nested dictionary with structure: {plane_id: {roi_id: Polygon}} In case plane-specific ROIs are required / requested at some point, having the additional level that enables the reference to plane_id(s) should foster the implementation. The current implementation, however, only supports the use of ROIs for all planes - the corresponding plane_id is hence: ‘all_planes’ Ultimately, this file_id specific dictionary can then be integrated into the ‘rois_as_shapely_polygons’ attribute of the database.\nNote: If multiple ROIs are used for one image, the individual ROIs must be named properly in the ROIManager-Tool in ImageJ. For instance, if images of the hippocampus are investigated & they can contain images of the DG, CA3 and CA1, the corresponding ROIs that mark the respective area have to be named consistenly for all .zip files. This makes it possible, that findmycells can handle the analysis even if not all ROIs are present for each image, e.g. for some files only DG and CA3.\n\nsource\n\n\nImageJROIReader\n\n ImageJROIReader ()\n\nReturn the roi(s) as shapely.geometry.Polygon(s) in a nested dictionary with structure: {plane_id: {roi_id: Polygon}} In case plane-specific ROIs are required / requested at some point, having the additional level that enables the reference to plane_id(s) should foster the implementation. The current implementation, however, only supports the use of ROIs for all planes - the corresponding plane_id is hence: ‘all_planes’ Ultimately, this file_id specific dictionary can then be integrated into the ‘rois_as_shapely_polygons’ attribute of the database.\nNote: If multiple ROIs are used for one image, the individual ROIs must be named properly in the ROIManager-Tool in ImageJ. For instance, if images of the hippocampus are investigated & they can contain images of the DG, CA3 and CA1, the corresponding ROIs that mark the respective area have to be named consistenly for all .zip files. This makes it possible, that findmycells can handle the analysis even if not all ROIs are present for each image, e.g. for some files only DG and CA3."
  },
  {
    "objectID": "API documentation/data readers/readers_01_microscopy_images.html",
    "href": "API documentation/data readers/readers_01_microscopy_images.html",
    "title": "microscopy image data readers",
    "section": "",
    "text": "source\n\nMicroscopyImageReaders\n\n MicroscopyImageReaders ()\n\nThe read method of MicroscopyImageReaders subclasses has to return a numpy array with the following structure: [imaging-planes, rows, columns, color-channels] For instance, an array of a RGB z-stack with 10 image planes of 1024x1024 pixels will have a shape of: [10, 1024, 1024, 3] To improve re-usability of the same functions for all different kinds of input images, this structure will be used even if there is just a single plane. For instance, the shape of the array of a grayscale 2D image with 1024 x 1024 pixels will look like this: [1, 1024, 1024, 1]\n\nsource\n\n\nCZIReader\n\n CZIReader ()\n\nThis reader enables loading of images acquired with the ZEN imaging software by Zeiss, using the czifile package. Note: the first three dimensions are entirely guessed, it could well be that they reflect different things and not “version_idx”, “tile_row_idx”, “tile_col_idx”!\n\nsource\n\n\nRegularImageFiletypeReader\n\n RegularImageFiletypeReader ()\n\nThis reader enables loading of all regular image filetypes, that scikit-image can read, using the scikit-image.io.imread function. Note: So far only single plane images are supported (yet, both single-color & multi-color channel images are supported)!\n\nsource\n\n\nFromExcelReader\n\n FromExcelReader ()\n\nThis reader is actually only a wrapper to the other MicroscopyImageReaders subclasses. It can be used if you stored the filepaths to your individual plane images in an excel sheet, for instance if you were using our “prepare my data for findmycells” functions. Please be aware that the corresponding datatype has to be loadable with any of the corresponding MicroscopyImageReaders!"
  },
  {
    "objectID": "API documentation/data readers/readers_00_specs.html",
    "href": "API documentation/data readers/readers_00_specs.html",
    "title": "Specification of default values of available data readers",
    "section": "",
    "text": "source\n\nReaderSpecsABC\n\n ReaderSpecsABC ()\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nMicroscopyReaderSpecs\n\n MicroscopyReaderSpecs ()\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nROIReaderSpecs\n\n ROIReaderSpecs ()\n\nfindmycells enables analyses of multiple ROIs in the image data. To do so, they will be matched based on their ID that will be retrieved from the ROI file. Some softwares that create these ROI-files, however, create default IDs for the individual ROIs that will interfere with this matching. For instance, in Fiji / ImageJ2, created ROIs get its centroid (?) pixel coordinates as default ID (e.g. something like “523-378”). Since such default IDs most likely won´t be consistent throughout your entire image dataset, findmycells provides you with two options to adress this: a) You can set ‘load_roi_ids_from_file’ to False (default): This will cause findmycells to ignore the IDs of the ROIs that are saved in the provided ROI file and assign them with new IDs starting at “000”. Note: Essentially, this requires you to have always the same type of ROIs present in the exact same order in all your ROI-files. It is therefore only recommended if you have just a single ROI you´d like to analyze. b) You can set ‘load_roi_ids_from_file’ to True (recommended if you have more than a single ROI): This will enforce that findmycells uses the IDs that each ROI was saved with. Therefore, it requires that you use consistent naming of the ROIs with your preferred software. For instance, if you´re using Fiji / ImageJ2, you can rename each ROI in the ROIManager (e.g. “CA3”, “vlPAG”, or “ipsilateral_SNc”). Analyses and quantifications will then be matched and pooled across all ROIs with the respective IDs (e.g. all “CA3” ROIs)."
  },
  {
    "objectID": "API documentation/interfaces.html",
    "href": "API documentation/interfaces.html",
    "title": "interfaces",
    "section": "",
    "text": "Application programming interface (API)\nThe following class defines the API of findmycells, which represents the intended way of how users interact with and use findmycells, if they are not using the graphical user interface (GUI; defined below).\n\nsource\n\nAPI\n\n API (project_root_dir:pathlib.PosixPath)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\nGraphical user interface\nThe following classes are used to create the graphical user interface of findmycells. Please note that classes will be listed here in an inverted hirarchy, such that you can find the main GUI class at the very end, and classes that handle much more specific details at the beginning.\n\nclass StrategyConfigurator:\n    \n    \"\"\"\n    This class implements the interface that let´s the user choose and \n    configurate the processing strategies. It will be placed inside of\n    an accordion that is implemented in the `ProcessingStepPage`.\n    It gets a list of all available processing strategies from the parent\n    `ProcessingStepPage` and, thus, eventually from the `API` that checks\n    for all available processing strategies in the corresponding processing\n    submodule (e.g. \"findmycells.preprocessing.strategies\"). Upon initializing\n    it´s dropdown widget, which let´s the user browser through the different\n    available strategies, it also initializes an object of each strategy.\n    This object can then be used to run it´s associated method \n    \".initialize_gui_configs_and_widget()\" to build the specified widget, \n    using its `GUIConfigs` instance. Essentially, this contains a\n    description of what the processing strategy does and, if applicable,\n    widgets to specify all parameters that can be configurated for this \n    strategy. Finally, a \"confirm & export\" and a \"remove\" button allow\n    the user to load or delete the current to or from the findmycells\n    project, respectively.\n    \"\"\"\n    \n    def __init__(self,\n                 available_strategy_classes: List,\n                 parent_accordion: w.Accordion,\n                 target_for_configs_export: List) -> None:\n        self.available_strategy_classes = available_strategy_classes\n        self.parent_accordion = parent_accordion\n        self.target_for_configs_export = target_for_configs_export\n        self.widget = self._initialize_widget()\n        self._link_widgets_with_eventhandlers()\n\n        \n    def _initialize_widget(self) -> WidgetType:\n        info_text = w.HTML(value = ('Please select one of the available processing methods from the dropdown menu below. '\n                                    'Feel free to click through all listed methods, as each of them will display a '\n                                    'short description of what exactly to expect and may also prompt you with some '\n                                    'customization options. To select a method with all selected customization options, '\n                                    'click on the \"confirm selection & export configurations\". Using the \"remove method\" '\n                                    'button allows you to remove previously loaded methods again.'))\n        self.dropdown = self._initialize_dropdown()\n        self.confirm_and_export_button = w.Button(description = 'confirm selection & export configurations', layout = {'width': '30%'})\n        self.remove_button = w.Button(description = 'remove method', layout = {'width': '20%'}, disabled = True)\n        self.displayed_strat_widget = w.VBox([self.dropdown.value.widget], layout = {'width': '95%'})\n        widget = w.VBox([info_text,\n                         GUI_SPACER,\n                         w.HBox([self.dropdown, self.confirm_and_export_button, self.remove_button]),\n                         GUI_SPACER,\n                         self.displayed_strat_widget])\n        return widget\n        \n        \n    def _link_widgets_with_eventhandlers(self) -> None:\n        self.confirm_and_export_button.on_click(self._confirm_and_export_button_clicked)\n        self.remove_button.on_click(self._remove_button_clicked)\n        self.dropdown.observe(self._dropdown_option_changed, names = 'value')\n        \n    \n    def _initialize_dropdown(self) -> WidgetType:\n        dropdown_option_tuples = []\n        for strategy_class in self.available_strategy_classes:\n            strategy_obj = strategy_class()\n            strategy_obj.initialize_gui_configs_and_widget()\n            dropdown_option_tuples.append((strategy_obj.dropdown_option_value_for_gui, strategy_obj))\n        return w.Dropdown(options = dropdown_option_tuples, layout = {'width': '50%'}) \n        \n        \n    def _get_own_position_idx_in_parent_accordion(self) -> int:\n        return self.parent_accordion.children.index(self.widget)\n        \n        \n    def _confirm_and_export_button_clicked(self, b) -> None:\n        self._export_configs()\n        self._change_disable_settings_of_customizable_widgets(disable_customizable_widgets = True)\n        self._add_new_strategy_configurator_to_parent_accordion()\n        self._change_own_accordion_tab_title(title = self.dropdown.value.dropdown_option_value_for_gui)\n        self.parent_accordion.selected_index = None\n        \n        \n    def _add_new_strategy_configurator_to_parent_accordion(self) -> None:\n        new_strategy_configurator = StrategyConfigurator(available_strategy_classes = self.available_strategy_classes,\n                                                         parent_accordion = self.parent_accordion,\n                                                         target_for_configs_export = self.target_for_configs_export)\n        self.parent_accordion.children = self.parent_accordion.children + (new_strategy_configurator.widget, )\n        position_idx = len(self.parent_accordion.children) - 1\n        self.parent_accordion.set_title(position_idx, 'Expand me to add a processing method')\n                                                         \n                                                         \n    def _change_own_accordion_tab_title(self, title: str) -> None:\n        position_idx = self._get_own_position_idx_in_parent_accordion()\n        self.parent_accordion.set_title(position_idx, title)\n\n        \n    def _export_configs(self) -> None:\n        selected_strategy_obj = self.dropdown.value\n        current_configs = selected_strategy_obj.gui_configs.export_current_config_values()\n        position_idx = self._get_own_position_idx_in_parent_accordion()\n        self.target_for_configs_export.insert(position_idx, (selected_strategy_obj.__class__, current_configs))      \n        \n        \n    def _change_disable_settings_of_customizable_widgets(self, disable_customizable_widgets: bool) -> None:\n        self.remove_button.disabled = not disable_customizable_widgets\n        self.dropdown.disabled = disable_customizable_widgets\n        self.confirm_and_export_button.disabled = disable_customizable_widgets\n        for widget in self.displayed_strat_widget.children[0].children:\n            if hasattr(widget, 'disabled'):\n                widget.disabled = disable_customizable_widgets\n            elif type(widget) == w.HBox:\n                if hasattr(widget.children[0], 'disabled'):\n                    widget.children[0].disabled = disable_customizable_widgets\n        \n        \n    def _remove_button_clicked(self, b) -> None:\n        self._remove_configs()\n        if len(self.parent_accordion.children) == 1:\n            self._change_disable_settings_of_customizable_widgets(disable_customizable_widgets = False)\n            self._change_own_accordion_tab_title(title = 'Expand me to add a processing method')\n        else:\n            currently_present_accordion_tabs = len(self.parent_accordion.children)\n            currently_confirmed_strategies = len(self.target_for_configs_export)\n            tabs_available_for_selection = currently_present_accordion_tabs - currently_confirmed_strategies\n            if tabs_available_for_selection > 1:\n                self._remove_own_tab_from_parent_accordion()\n            else:\n                self._change_disable_settings_of_customizable_widgets(disable_customizable_widgets = False)\n                self._change_own_accordion_tab_title(title = 'Expand me to add a processing method')\n                \n                \n    def _remove_own_tab_from_parent_accordion(self) -> None:\n        tmp_children = list(self.parent_accordion.children)\n        tmp_titles = []\n        for idx in range(len(tmp_children)):\n            tmp_titles.append(self.parent_accordion.get_title(idx))\n        position_idx = self._get_own_position_idx_in_parent_accordion()\n        tmp_children.pop(position_idx)\n        tmp_titles.pop(position_idx)\n        self.parent_accordion.children = tuple(tmp_children)\n        for idx, title in enumerate(tmp_titles):\n            self.parent_accordion.set_title(idx, title)\n            \n            \n    def _remove_configs(self) -> None:\n        position_idx = self._get_own_position_idx_in_parent_accordion()\n        self.target_for_configs_export.pop(position_idx)\n                \n                \n    def _dropdown_option_changed(self, change) -> None:\n        new_selection = change.new\n        self.displayed_strat_widget.children = (new_selection.widget, )\n\n\nsource\n\nPageButtonBundle\n\n PageButtonBundle (bundle_id:str,\n                   page_screen:traitlets.traitlets.MetaHasTraits,\n                   all_navigator_buttons:List, api:__main__.API)\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nSettingsPage\n\n SettingsPage (bundle_id:str,\n               page_screen:traitlets.traitlets.MetaHasTraits,\n               all_navigator_buttons:List, api:__main__.API)\n\nSubclass of PageButtonBundle that implements the GUI interface that allows the user to specify all settings relevant to the findmycells project. It also enables saving & loading of the project status, and to browse through the file history that is automatically created by findmycells.\n\nsource\n\n\nProcessingStepPage\n\n ProcessingStepPage (bundle_id:str,\n                     page_screen:traitlets.traitlets.MetaHasTraits,\n                     all_navigator_buttons:List, api:__main__.API)\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nInspectionPage\n\n InspectionPage (bundle_id:str,\n                 page_screen:traitlets.traitlets.MetaHasTraits,\n                 all_navigator_buttons:List, api:__main__.API)\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nGUI\n\n GUI ()\n\nInitialize self. See help(type(self)) for accurate signature."
  },
  {
    "objectID": "API documentation/utils.html",
    "href": "API documentation/utils.html",
    "title": "utility functions",
    "section": "",
    "text": "source\n\nlist_dir_no_hidden\n\n list_dir_no_hidden (path:pathlib.PosixPath,\n                     only_dirs:Optional[bool]=False,\n                     only_files:Optional[bool]=False)\n\n\nsource\n\n\nload_zstack_as_array_from_single_planes\n\n load_zstack_as_array_from_single_planes (path:pathlib.PosixPath,\n                                          file_id:str,\n                                          minx:Optional[int]=None,\n                                          maxx:Optional[int]=None,\n                                          miny:Optional[int]=None,\n                                          maxy:Optional[int]=None)\n\n\nsource\n\n\nunpad_x_y_dims_in_3d_array\n\n unpad_x_y_dims_in_3d_array (padded_3d_array:numpy.ndarray, pad_width:int)\n\n\nsource\n\n\nget_polygon_from_instance_segmentation\n\n get_polygon_from_instance_segmentation (single_plane:numpy.ndarray,\n                                         label_id:int)"
  },
  {
    "objectID": "API documentation/inspection_00_methods.html",
    "href": "API documentation/inspection_00_methods.html",
    "title": "inspection",
    "section": "",
    "text": "Note: This submodule does not use the abstract base classes ProcessingObject and ProcessingStrategy. The reason for this is to make specifying the settings and configurations for these inspection methods more interactive for the user - especially when accessed via the GUI. Unfortunately, this sacrifices a bit of overall code consistency. However, since inspection also does not really represent a processing step, this trade-off in favor of usability seemed reasonable. To make make the distinction ever more apparent, the classes that handle the different inspections will be referred to as “methods” instead of “strategies” in the class names.\n\nsource\n\nInspectionMethod\n\n InspectionMethod ()\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nInspectStackIn3D\n\n InspectStackIn3D ()\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nInspectSinglePlane\n\n InspectSinglePlane ()\n\nHelper class that provides a standard way to create an ABC using inheritance."
  },
  {
    "objectID": "API documentation/database.html",
    "href": "API documentation/database.html",
    "title": "database",
    "section": "",
    "text": "source\n\nDatabase\n\n Database (project_configs:findmycells.configs.ProjectConfigs)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nFileHistory\n\n FileHistory (file_id:str, source_image_filepath:pathlib.PosixPath)\n\nInitialize self. See help(type(self)) for accurate signature."
  },
  {
    "objectID": "API documentation/preprocessing_01_strategies.html",
    "href": "API documentation/preprocessing_01_strategies.html",
    "title": "preprocessing options",
    "section": "",
    "text": "source\n\nCropStitchingArtefactsRGBStrat\n\n CropStitchingArtefactsRGBStrat ()\n\nWhen you acquire microscopy images that are essentially several individual images (= tiles) stitched together, you may end up with some artefacts on the borders of the image as a result from the stitching process. These pixels are usually either fully black or fully white and can therefore interfere with other processing strategies that you might want to apply to your images (for instance, if you´d like to adjust brightness and contrast). This strategy aims at identifying these pixels that were added to account for some offset between the individual tiles and eventually remove them. As these artefacts might interfere with other processing steps, it is recommended to add this (or any other cropping strategy to get rid of these artefacts) prior to other preprocessing strategies.\n\nsource\n\n\nCropToROIsBoundingBoxStrat\n\n CropToROIsBoundingBoxStrat ()\n\nYou might not be interested in analyzing the entire image, but only to quantify image features of interest in a certain region of your image (or actually also several regions). Now, chances are that it is possible to find a bounding box that contains all regions of the image that you are interested in, which is, however, smaller than the original image. Cropping your original image down to that smaller size will then significantly reduce computation time, required memory space, and also required disk space. Therefore, it is highly recommended to add this strategy to your preprocessing. You can also combine it with additional cropping strategies, like the one that tries to remove stitching artefacts.\n\nsource\n\n\nConvertTo8BitStrat\n\n ConvertTo8BitStrat ()\n\nThis strategy converts your image to an 8-bit format. Adding this strategy is at the moment mandatory, as all implemented segmentation tools (deepflash2 & cellpose) require 8-bit as input format. So you actually don´t really have a choice but adding it! :-)\n\nsource\n\n\nMaximumIntensityProjectionStrat\n\n MaximumIntensityProjectionStrat ()\n\nIf you acquired your microscopy images as z-stack, you can use this strategy to project it from a 3D image stack (commonly referred to as 2.5D) into a two dimensional single plane image. If you select this strategy, the brightest (= maximal) pixel value from the z-stack will be used in the final 2D projection. Alternatively, feel free to use the “Minimum intenstity projection” strategy, if you´d like to keep only the darkest (= minimal) value of each pixel.\n\nsource\n\n\nMinimumIntensityProjectionStrat\n\n MinimumIntensityProjectionStrat ()\n\nIf you acquired your microscopy images as z-stack, you can use this strategy to project it from a 3D image stack (commonly referred to as 2.5D) into a two dimensional single plane image. If you select this strategy, the darkest (= minimal) pixel value from the z-stack will be used in the final 2D projection. Alternatively, feel free to use the “Maximum intenstity projection” strategy, if you´d like to keep only the brightest (= maximal) value of each pixel.\n\nsource\n\n\nAdjustBrightnessAndContrastStrat\n\n AdjustBrightnessAndContrastStrat ()\n\nThis strategy allows you to automatically adjust brightness and contrast of your images. For this, please specify the percentage of pixels that you want to be saturated (default: 0.35 % - same as in ImageJ2). This strategy will then ensure that this specified percentage of pixels will be fully saturated in all of your images. If you have z-stack images, you can furthermore also specify whether you´d like to run this operation on the full z-stack (chose “globally”), or on each individual plane of the z-stack (chose “individually”). I would rather recommend using “globally” to keep a somewhat consistent meaning of pixel intensities. And, finally, if you are anyhow dealing with 2D images (either from the get-go, or since you applied a maximum or minimum intensity projection strategy prior to this one - both “globally” and “individually” will lead to the same result."
  },
  {
    "objectID": "API documentation/index.html",
    "href": "API documentation/index.html",
    "title": "API documentation",
    "section": "",
    "text": "The following table lists all submodules of findmycells in alphabetical order. Please note that the displayed list is only for overview purposes and does neither represent the correct arrangement of the submodules, nor (neccessarily) the exact name of the submodule. These information, however, can be found right at the top of each of the individual submodule pages that are linked via the following table.\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nProcessing step specific submodules\n\n\n\n\n\n\n\nconfigs\n\n\nDefines several classes that handle the different configuration levels and options\n\n\n\n\npreprocessing related subclasses\n\n\nThis module implements the preprocessing-related subclasses of ProcessingStrategy and ProcessingObject\n\n\n\n\ncore\n\n\nDefines central classes that are re-used throughout the findmycells package\n\n\n\n\npreprocessing strategies\n\n\nThis module defines all available preprocessing strategies (= preprocessing options)\n\n\n\n\ndatabase\n\n\nDefines a database and file history tracker that stores all relevant information of your findmycells project\n\n\n\n\nsegmentation related subclasses\n\n\nThis module implements the segmentation-related subclasses of ProcessingStrategy and ProcessingObject\n\n\n\n\ninspection\n\n\nDefines all available methods that you can use to interactively inspect the final segmentation results\n\n\n\n\nsegmentation strategies\n\n\nThis module defines all available segmentation strategies (= segmentation options)\n\n\n\n\ninterfaces\n\n\nDefines the top-level API and the GUI of findmycells\n\n\n\n\npostprocessing related subclasses\n\n\nThis module implements the postprocessing-related subclasses of ProcessingStrategy and ProcessingObject\n\n\n\n\npostprocessing strategies\n\n\nThis module defines all available postprocessing strategies (= postprocessing options)\n\n\n\n\npostprocessing subclasses\n\n\nExtends the classes defined in core for the postprocessing-specific requirements\n\n\n\n\npostprocessing options\n\n\nDefines all options you can use for postprocessing of your segmentation data\n\n\n\n\nquantification related subclasses\n\n\nThis module implements the quantification-related subclasses of ProcessingStrategy and ProcessingObject\n\n\n\n\npreprocessing subclasses\n\n\nExtends the classes defined in core for the preprocessing-specific requirements\n\n\n\n\nquantification strategies\n\n\nThis module defines all available quantification strategies (= quantification options)\n\n\n\n\npreprocessing options\n\n\nDefines all options you can use for preprocessing of your image data\n\n\n\n\nquantification subclasses\n\n\nExtends the classes defined in core for the quantification-specific requirements\n\n\n\n\nquantification strategies\n\n\nDefines all options you can use for quantification of your postprocessed segmentation data\n\n\n\n\nsegmentation subclasses\n\n\nExtends the classes defined in core for the segmentation-specific requirements\n\n\n\n\nsegmentation strategies\n\n\nDefines all options you can use for segmentation of your preprocessed image data\n\n\n\n\nutility functions\n\n\nDefines several general purpose functions that are used throughout findmycells\n\n\n\n\nROI readers\n\n\nThis module contains all code responsible for reading region of interests (ROI) files:\n\n\n\n\nSpecification of default values of available data readers\n\n\nThis module specifies the default values of the available data readers, their descriptions, and their widgets:\n\n\n\n\nmicroscopy image data readers\n\n\nThis module contains all code responsible for reading microscopy image files:\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "API documentation/quantification_00_specs.html",
    "href": "API documentation/quantification_00_specs.html",
    "title": "quantification subclasses",
    "section": "",
    "text": "source\n\nQuantificationStrategy\n\n QuantificationStrategy ()\n\nNote for developers: When implementing a new quantification strategy, remember to add the following line at the end of the “.run()” method, to ensure that the quantification results are added to the database:\nquantification_object = self._add_quantification_results_to_database(quantification_object = quantification_object, results = quantification_results)\n\nsource\n\n\nQuantificationObject\n\n QuantificationObject ()\n\nExtending the ProcessingObject base class for quantification as processing subtype."
  },
  {
    "objectID": "API documentation/preprocessing_00_specs.html",
    "href": "API documentation/preprocessing_00_specs.html",
    "title": "preprocessing subclasses",
    "section": "",
    "text": "source\n\nPreprocessingStrategy\n\n PreprocessingStrategy ()\n\nExtending the ProcssingStrategy base class for preprocessing as processing subtype.\n\nsource\n\n\nPreprocessingObject\n\n PreprocessingObject ()\n\nExtending the ProcessingObject base class for preprocessing as processing subtype. Responsible for loading the microscopy image(s) and corresponding ROI(s) for each file, running the specified preprocessing strategies, updating the database, and eventually for saving the preprocessed images to disk for further processing steps down the line.\nNote: Even though the file_ids argument accepts (and actually expects & requires) a list as input, only a single file_id will be passed to a PreprocessingObject upon initialization. This is handled in the api module of findmycells."
  },
  {
    "objectID": "API documentation/segmentation_01_strategies.html",
    "href": "API documentation/segmentation_01_strategies.html",
    "title": "segmentation strategies",
    "section": "",
    "text": "source\n\nDeepflash2SemanticSegmentationStrat\n\n Deepflash2SemanticSegmentationStrat ()\n\nRun semantic segmentation using deepflash2. Requires that you have already an ensemble of trained models ready to use and to provide the path to the directory where these models can be found. If you choose to process the files in your project in smaller batches (which is highly recommended, due to a huge memory load), make sure to run the segmentations “strategy-wise” in the processing configs below before launching the processing (i.e. keep the box checked).\n\nsource\n\n\nLosslessConversionOfDF2SemanticSegToInstanceSegWithCPStrat\n\n LosslessConversionOfDF2SemanticSegToInstanceSegWithCPStrat ()\n\nExtending the ProcssingStrategy base class for segmentation as processing subtype. Also adding another property that denotes the type of segmentation (i.e. instance or semantic)."
  },
  {
    "objectID": "API documentation/segmentation_00_specs.html",
    "href": "API documentation/segmentation_00_specs.html",
    "title": "segmentation subclasses",
    "section": "",
    "text": "source\n\nSegmentationStrategy\n\n SegmentationStrategy ()\n\nExtending the ProcssingStrategy base class for segmentation as processing subtype. Also adding another property that denotes the type of segmentation (i.e. instance or semantic).\n\nsource\n\n\nSegmentationObject\n\n SegmentationObject ()\n\nExtending the ProcessingObject base class for segmentation as processing subtype. The clear_all_tmp_data() method allows to clear all chached results that might accumulate for instance while using deepflash2."
  },
  {
    "objectID": "API documentation/postprocessing_01_strategies.html",
    "href": "API documentation/postprocessing_01_strategies.html",
    "title": "postprocessing options",
    "section": "",
    "text": "source\n\nReconstructCellsIn3DFrom2DInstanceLabelsStrat\n\n ReconstructCellsIn3DFrom2DInstanceLabelsStrat ()\n\nDescription; Include requirements Mention multi matches traceback which can be used in inspection\n\nsource\n\n\nFillHolesStrat\n\n FillHolesStrat ()\n\nSpecific conditions can lead to “holes” within the segmentations of your image features. This can make total sense, for instance if youre analyzing specifically the cells cytoplasm, and want to spare out the nucleus, or if youre analyzing ring-like features. In other cases, however, these “holes” may be artefacts and require correction. This strategy was designed for exactly this purpose: fill the “holes” in your segmented features, if they should not be there.\n\nsource\n\n\nApplyExclusionCriteriaStrat\n\n ApplyExclusionCriteriaStrat ()\n\nAnother typical postprocessing step is to filter your data by applying exclusion criteria. Please check the following list of exclusion criteria with detailed descriptions to see which criteria are currently implemented in your installed findmycells version. Importantly, if you would like to use this strategy, please make sure to run this strategy as the last postprocessing strategy, to ensure that all other processing steps have been completed. \b \u0001- Minimum feature position relative to area ROI: \u0001If you provided ROIs that denote in which area of each image you’d like to quantify the image features, you can use this criterion to specify when to exclude detected features from the quantification. These are the options you can chose from, in order of increasing distance of your feature from the area ROI: within < intersects < touches < no overlap The option you select will always be the first relative position to be included. For example, if you select “intersects”, all features that are fully within your area ROI (classified as “within”) and all features that are intersected by the area ROI border (classified as “intersects”) will be kept, while all features that only touch the area ROI border (classified as “touches”) or that lie completely outside of it (classified as “no overlap”) will be excluded from further analyses. Note: if you are analyzing an image stack, a features` position can be classified differently depending on the image plane. Findmycells will always use the nearest classification. That means, if a feature was classified in one plane as “within” but only as “intersects” or even as “no overlap” in the other planes, the entire 3D feature will be classified as “within”.\u0002\u0002 \b \u0001- Minimum feature size [px]: \u0001Every detected feature whose area is smaller than the specified pixel value will will be deleted from the segmentation masks. Note: if you are analyzing an image stack, this strategy will determine for each 3D feature the plane in which is has the largest area & then apply this exclusion criterion based on this area value.\u0002\u0002 \b \u0001- Minimum planes covered (only relevant for image stacks): \u0001Similarly to “minimum feature size”, which checks for the expansion of your image features in x-y-dimensions, you can use this exclusion criterion to also check for a minimum size of your features in the z-dimension. The number you specify here will represent the minimum number of consecutive planes each image feature needs to cover to remain in your segmentation masks. For instance, if you specify it to be 3, all features that are only present in a single or in two consecutive planes will be deleted. Note: this exclusion criterion is, obviously, only relevant for projects that analyze image stacks. If you are working only with 2D images, this value will be ignored and 1 will be used as default.\u0002\u0002"
  },
  {
    "objectID": "API documentation/postprocessing_00_specs.html",
    "href": "API documentation/postprocessing_00_specs.html",
    "title": "postprocessing subclasses",
    "section": "",
    "text": "source\n\nPostprocessingStrategy\n\n PostprocessingStrategy ()\n\nExtending the ProcssingStrategy base class for postprocessing as processing subtype.\n\nsource\n\n\nPostprocessingObject\n\n PostprocessingObject ()\n\nExtending the ProcessingObject base class for postprocessing as processing subtype."
  },
  {
    "objectID": "API documentation/quantification_01_strategies.html",
    "href": "API documentation/quantification_01_strategies.html",
    "title": "quantification strategies",
    "section": "",
    "text": "source\n\nCountFeaturesInWholeAreaROIsStrat\n\n CountFeaturesInWholeAreaROIsStrat ()\n\nStrategy description"
  },
  {
    "objectID": "api/configs.html",
    "href": "api/configs.html",
    "title": "configs",
    "section": "",
    "text": "Configurations\nThere are several layers that require & allow configuration of findmycells. However, only the top most level (ProjectConfigs) is implemented here. All lower level configs (e.g. configs for each processing type like “preprocessing” or “quantification”, or even lower level configs like for each individual processing step represented by ProcessingStrategy subclasses), will be defined by each of these classes using the DefaultConfigs - which is implemented here. For an example of how the DefaultConfigs shall be used, please have a look at the general implementation of ProcessingObject and ProcessingStrategy in the core module, and then check out the “specs.py” file of the corresponding processing sub-module!\n\nsource\n\nProjectConfigs\n\n ProjectConfigs (root_dir:pathlib.PosixPath)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nDefaultConfigs\n\n DefaultConfigs (default_values:Dict[str,Any],\n                 valid_types:Dict[str,List[type]],\n                 valid_value_ranges:Optional[Dict[str,Tuple]]=None,\n                 valid_value_options:Optional[Dict[str,Tuple]]=None)\n\nThis class has to be specified as an attribute in several classes throughout findmycells and allows / ensures that each novel class defines its own set of default config values. Moreover, the ‘valid_types’ dictionary also defines which types of values are allowed.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndefault_values\ntyping.Dict[str, typing.Any]\n\nKeys are identifier of config options, values the corresponding default value\n\n\nvalid_types\ntyping.Dict[str, typing.List[type]]\n\nKeys must match with keys of “default_values”, values are lists of allowed types\n\n\nvalid_value_ranges\ntyping.Optional[typing.Dict[str, typing.Tuple]]\nNone\nRequired for every config option that allows floats or integers. Keys must match with keys of “default_values”. Expected format: (start_idx, end_idx) or (start_idx, end_idx, step_size)\n\n\nvalid_value_options\ntyping.Optional[typing.Dict[str, typing.Tuple]]\nNone\nKeys must match with keys of “default_values”. Expected format: (‘option_a’, ‘option_b’, …)\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\n\nGUIConfigs\n\n GUIConfigs (widget_names:Dict[str,str], descriptions:Dict[str,str],\n             tooltips:Optional[Dict[str,str]]=None)\n\nNote for developers: The docstrings of each processing strategy will also be used to display the description of each strategy in both the GUI and in the online hosted documentation. To improve the layout of these displayed HTML elements, we introduced some custom “string commands”. Their use is described in detail in the docstring of the “_convert_docstring_to_html()” method of this class."
  },
  {
    "objectID": "api/core.html",
    "href": "api/core.html",
    "title": "core",
    "section": "",
    "text": "Handling data processing\nThe following two classes, ProcessingObject and ProcessingStrategy, provide the blueprints for all processing strategies and objects that are used throughout the findmycells package. As you can see in the corresponding processing step modules (i.e. “preprocess”, “segment”, or “quantify”), these abstract base classes provide the basic structure of the more specific objects and strategies in each of these modules (e.g. QuantificationObject and QuantificationStrategy within the “quantify” module inherit from ProcessingObject and ProcessingStrategy, respectively). While this makes these two classes highly relevant for any developer, regular users of findmycells won´t be interacting with them, even if they want to use the API instead of the GUI.\n\nsource\n\nProcessingObject\n\n ProcessingObject ()\n\nAbstract base class (inherits from ABC) that defines the general structure of ProcessingObjects in findmycells. A ProcessingObject combines all information needed for the corresponding processing step, i.e. what files are supposed to be processed & how. It also interfaces to the database of the project, such that it can automatically update the database with the latest progress.\nSubclasses that inherit from ProcessingObject need to implement the following two abstract methods:\n\nsource\n\n\nProcessingObject.processing_type\n\n ProcessingObject.processing_type ()\n\nAbstract method that requires its subclasses to define the processing_type as a property of the class. Thus, this will be specified in each individual processing module (e.g. the “preprocess” or “quantify” modules). It will be used in the database to keep track of the processing progress of the project. Has to be a string.\n\nsource\n\n\nProcessingObject._add_processing_specific_infos_to_updates\n\n ProcessingObject._add_processing_specific_infos_to_updates (updates:Dict)\n\nAbstract method that that requires its subclasses to define what updates need to be passed to the database, in addition to those that are already covered by the corresponding ProcessingStrategies or the “self.update_database()” method. If there are no more information to add, simply return the input ‘updates’ dictionary without any alterations.\nReturns a dictionary with all updates that need to be passed to the database.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nupdates\ntyping.Dict\nA dictionary with updates that need to be passed to the database\n\n\nReturns\ntyping.Dict\nA dictionary with all updates that need to be passed to the database\n\n\n\nIn addition, ProcessingObject defines two core functions that will be called on all its subclasses, which are:\n\nsource\n\n\nProcessingObject.run_all_strategies\n\n ProcessingObject.run_all_strategies (strategies:List,\n                                      strategy_configs:List[Dict])\n\nRuns all ProcessingStrategies that were passed upon initialization (i.e. self.strategies). For this, the corresponding ProcessingStrategy objects will be initialized and their “.run()” method will be called, while passing “self” as “processing_object”. Finally, it updates the database and deletes the ProcessingStrategy object to clear it from memory.\n\nsource\n\n\nProcessingObject.update_database\n\n ProcessingObject.update_database (mark_as_completed:bool=True)\n\nFor each microscopy file that had to be processed (self.file_ids), the database will be updated with the respective processing progress information. Interfaces back to the abstract method “self.add_processing_specific_infos_to_updates()” that enables the corresponding subclasses to add more specific details before triggering the update method of the database.\n\nsource\n\n\nProcessingStrategy\n\n ProcessingStrategy ()\n\nAbstract base class that defines the general structure of ProcessingStrategies in findmycells. A ProcessingStrategy combines all functions that are required for one particular processing step, e.g. ConvertTo8Bit is a ProcessingStrategy in the “preprocess” module and converts the corresponding images into 8-bit.\n\n\n\nHandling data reading\nFurthermore, the following two classes DataLoader and DataReader will be re-used throughout the findmycells package to load data into your findmycells project.\n\nsource\n\nDataReader\n\n DataReader ()\n\nAbstract base class that defines the general structure of DataReader subclasses. Essentially, it demands the corresponding subclasses to define the “readable_filetype_extensions” attribut, as well as the “set_optional_configs()” and the “read()” methods.\n\nsource\n\n\nDataLoader\n\n DataLoader ()\n\nInitialize self. See help(type(self)) for accurate signature."
  },
  {
    "objectID": "api/readers_02_rois.html",
    "href": "api/readers_02_rois.html",
    "title": "readers for ROI-files",
    "section": "",
    "text": "source\n\nROIReaders\n\n ROIReaders ()\n\nReturn the roi(s) as shapely.geometry.Polygon(s) in a nested dictionary with structure: {plane_id: {roi_id: Polygon}} In case plane-specific ROIs are required / requested at some point, having the additional level that enables the reference to plane_id(s) should foster the implementation. The current implementation, however, only supports the use of ROIs for all planes - the corresponding plane_id is hence: ‘all_planes’ Ultimately, this file_id specific dictionary can then be integrated into the ‘rois_as_shapely_polygons’ attribute of the database.\nNote: If multiple ROIs are used for one image, the individual ROIs must be named properly in the ROIManager-Tool in ImageJ. For instance, if images of the hippocampus are investigated & they can contain images of the DG, CA3 and CA1, the corresponding ROIs that mark the respective area have to be named consistenly for all .zip files. This makes it possible, that findmycells can handle the analysis even if not all ROIs are present for each image, e.g. for some files only DG and CA3.\n\nsource\n\n\nImageJROIReader\n\n ImageJROIReader ()\n\nReturn the roi(s) as shapely.geometry.Polygon(s) in a nested dictionary with structure: {plane_id: {roi_id: Polygon}} In case plane-specific ROIs are required / requested at some point, having the additional level that enables the reference to plane_id(s) should foster the implementation. The current implementation, however, only supports the use of ROIs for all planes - the corresponding plane_id is hence: ‘all_planes’ Ultimately, this file_id specific dictionary can then be integrated into the ‘rois_as_shapely_polygons’ attribute of the database.\nNote: If multiple ROIs are used for one image, the individual ROIs must be named properly in the ROIManager-Tool in ImageJ. For instance, if images of the hippocampus are investigated & they can contain images of the DG, CA3 and CA1, the corresponding ROIs that mark the respective area have to be named consistenly for all .zip files. This makes it possible, that findmycells can handle the analysis even if not all ROIs are present for each image, e.g. for some files only DG and CA3."
  },
  {
    "objectID": "api/preprocessing_01_strategies.html",
    "href": "api/preprocessing_01_strategies.html",
    "title": "preprocessing options",
    "section": "",
    "text": "source\n\nCropStitchingArtefactsRGBStrat\n\n CropStitchingArtefactsRGBStrat ()\n\nWhen you acquire microscopy images that are essentially several individual images (= tiles) stitched together, you may end up with some artefacts on the borders of the image as a result from the stitching process. These pixels are usually either fully black or fully white and can therefore interfere with other processing strategies that you might want to apply to your images (for instance, if you´d like to adjust brightness and contrast). This strategy aims at identifying these pixels that were added to account for some offset between the individual tiles and eventually remove them. As these artefacts might interfere with other processing steps, it is recommended to add this (or any other cropping strategy to get rid of these artefacts) prior to other preprocessing strategies.\n\nsource\n\n\nCropToROIsBoundingBoxStrat\n\n CropToROIsBoundingBoxStrat ()\n\nYou might not be interested in analyzing the entire image, but only to quantify image features of interest in a certain region of your image (or actually also several regions). Now, chances are that it is possible to find a bounding box that contains all regions of the image that you are interested in, which is, however, smaller than the original image. Cropping your original image down to that smaller size will then significantly reduce computation time, required memory space, and also required disk space. Therefore, it is highly recommended to add this strategy to your preprocessing. You can also combine it with additional cropping strategies, like the one that tries to remove stitching artefacts.\n\nsource\n\n\nConvertTo8BitStrat\n\n ConvertTo8BitStrat ()\n\nThis strategy converts your image to an 8-bit format. Adding this strategy is at the moment mandatory, as all implemented segmentation tools (deepflash2 & cellpose) require 8-bit as input format. So you actually don´t really have a choice but adding it! :-)\n\nsource\n\n\nMaximumIntensityProjectionStrat\n\n MaximumIntensityProjectionStrat ()\n\nIf you acquired your microscopy images as z-stack, you can use this strategy to project it from a 3D image stack (commonly referred to as 2.5D) into a two dimensional single plane image. If you select this strategy, the brightest (= maximal) pixel value from the z-stack will be used in the final 2D projection. Alternatively, feel free to use the “Minimum intenstity projection” strategy, if you´d like to keep only the darkest (= minimal) value of each pixel.\n\nsource\n\n\nMinimumIntensityProjectionStrat\n\n MinimumIntensityProjectionStrat ()\n\nIf you acquired your microscopy images as z-stack, you can use this strategy to project it from a 3D image stack (commonly referred to as 2.5D) into a two dimensional single plane image. If you select this strategy, the darkest (= minimal) pixel value from the z-stack will be used in the final 2D projection. Alternatively, feel free to use the “Maximum intenstity projection” strategy, if you´d like to keep only the brightest (= maximal) value of each pixel.\n\nsource\n\n\nAdjustBrightnessAndContrastStrat\n\n AdjustBrightnessAndContrastStrat ()\n\nThis strategy allows you to automatically adjust brightness and contrast of your images. For this, please specify the percentage of pixels that you want to be saturated (default: 0.35 % - same as in ImageJ2). This strategy will then ensure that this specified percentage of pixels will be fully saturated in all of your images. If you have z-stack images, you can furthermore also specify whether you´d like to run this operation on the full z-stack (chose “globally”), or on each individual plane of the z-stack (chose “individually”). I would rather recommend using “globally” to keep a somewhat consistent meaning of pixel intensities. And, finally, if you are anyhow dealing with 2D images (either from the get-go, or since you applied a maximum or minimum intensity projection strategy prior to this one - both “globally” and “individually” will lead to the same result."
  },
  {
    "objectID": "api/readers_01_microscopy_images.html",
    "href": "api/readers_01_microscopy_images.html",
    "title": "readers for microscopy images",
    "section": "",
    "text": "source\n\nMicroscopyImageReaders\n\n MicroscopyImageReaders ()\n\nThe read method of MicroscopyImageReaders subclasses has to return a numpy array with the following structure: [imaging-planes, rows, columns, color-channels] For instance, an array of a RGB z-stack with 10 image planes of 1024x1024 pixels will have a shape of: [10, 1024, 1024, 3] To improve re-usability of the same functions for all different kinds of input images, this structure will be used even if there is just a single plane. For instance, the shape of the array of a grayscale 2D image with 1024 x 1024 pixels will look like this: [1, 1024, 1024, 1]\n\nsource\n\n\nCZIReader\n\n CZIReader ()\n\nThis reader enables loading of images acquired with the ZEN imaging software by Zeiss, using the czifile package. Note: the first three dimensions are entirely guessed, it could well be that they reflect different things and not “version_idx”, “tile_row_idx”, “tile_col_idx”!\n\nsource\n\n\nRegularImageFiletypeReader\n\n RegularImageFiletypeReader ()\n\nThis reader enables loading of all regular image filetypes, that scikit-image can read, using the scikit-image.io.imread function. Note: So far only single plane images are supported (yet, both single-color & multi-color channel images are supported)!\n\nsource\n\n\nFromExcelReader\n\n FromExcelReader ()\n\nThis reader is actually only a wrapper to the other MicroscopyImageReaders subclasses. It can be used if you stored the filepaths to your individual plane images in an excel sheet, for instance if you were using our “prepare my data for findmycells” functions. Please be aware that the corresponding datatype has to be loadable with any of the corresponding MicroscopyImageReaders!"
  },
  {
    "objectID": "api/readers_00_specs.html",
    "href": "api/readers_00_specs.html",
    "title": "reader specifications",
    "section": "",
    "text": "source\n\nReaderSpecsABC\n\n ReaderSpecsABC ()\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nMicroscopyReaderSpecs\n\n MicroscopyReaderSpecs ()\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nROIReaderSpecs\n\n ROIReaderSpecs ()\n\nfindmycells enables analyses of multiple ROIs in the image data. To do so, they will be matched based on their ID that will be retrieved from the ROI file. Some softwares that create these ROI-files, however, create default IDs for the individual ROIs that will interfere with this matching. For instance, in Fiji / ImageJ2, created ROIs get its centroid (?) pixel coordinates as default ID (e.g. something like “523-378”). Since such default IDs most likely won´t be consistent throughout your entire image dataset, findmycells provides you with two options to adress this: a) You can set ‘load_roi_ids_from_file’ to False (default): This will cause findmycells to ignore the IDs of the ROIs that are saved in the provided ROI file and assign them with new IDs starting at “000”. Note: Essentially, this requires you to have always the same type of ROIs present in the exact same order in all your ROI-files. It is therefore only recommended if you have just a single ROI you´d like to analyze. b) You can set ‘load_roi_ids_from_file’ to True (recommended if you have more than a single ROI): This will enforce that findmycells uses the IDs that each ROI was saved with. Therefore, it requires that you use consistent naming of the ROIs with your preferred software. For instance, if you´re using Fiji / ImageJ2, you can rename each ROI in the ROIManager (e.g. “CA3”, “vlPAG”, or “ipsilateral_SNc”). Analyses and quantifications will then be matched and pooled across all ROIs with the respective IDs (e.g. all “CA3” ROIs)."
  },
  {
    "objectID": "api/index.html",
    "href": "api/index.html",
    "title": "documentation overview",
    "section": "",
    "text": "The following table lists all submodules of findmycells in alphabetical order. Please note that the displayed table only serves as an overview of all submodules and does neither represent the correct arrangement of the submodules, nor (neccessarily) the exact name of the submodule. These information, however, can be found in parentheses at the end of each description.\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nconfigs\n\n\nDefines several classes that handle the different configuration levels and options (findmycells.configs)\n\n\n\n\ncore\n\n\nDefines central classes that are re-used throughout the findmycells package (findmycells.core)\n\n\n\n\ndatabase\n\n\nDefines a database and file history tracker that stores all relevant information of your findmycells project (findmycells.database)\n\n\n\n\ninspection\n\n\nDefines all available methods that you can use to interactively inspect the final (i.e. postprocessed and quantified) segmentation results (findmycells.inspection.methods)\n\n\n\n\ninterfaces\n\n\nDefines the top-level API and the GUI of findmycells (findmycells.interfaces)\n\n\n\n\npostprocessing subclasses\n\n\nExtends the classes defined in core for the postprocessing-specific requirements (findmycells.postprocessing.specs)\n\n\n\n\npostprocessing options\n\n\nDefines all options you can use for postprocessing of your segmentation data (findmycells.postprocessing.strategies)\n\n\n\n\npreprocessing subclasses\n\n\nExtends the classes defined in core for the preprocessing-specific requirements (findmycells.preprocessing.specs)\n\n\n\n\npreprocessing options\n\n\nDefines all options you can use for preprocessing of your image data (findmycells.preprocessing.strategies)\n\n\n\n\nquantification subclasses\n\n\nExtends the classes defined in core for the quantification-specific requirements (findmycells.quantification.specs)\n\n\n\n\nquantification strategies\n\n\nDefines all options you can use for quantification of your postprocessed segmentation data (findmycells.quantification.strategies)\n\n\n\n\nreader specifications\n\n\nDefines the generic classes to handle import of data (images & ROIs) to findmycells that will by extended by specific reader submodules (findmycells.readers.specs)\n\n\n\n\nreaders for microscopy images\n\n\nExtends the generic reader classes for specific image data types (findmycells.readers.microscopy_images)\n\n\n\n\nreaders for ROI-files\n\n\nExtends the generic reader classes for specific ROI data types (findmycells.readers.rois)\n\n\n\n\nsegmentation subclasses\n\n\nExtends the classes defined in core for the segmentation-specific requirements (findmycells.segmentation.specs)\n\n\n\n\nsegmentation strategies\n\n\nDefines all options you can use for segmentation of your preprocessed image data (findmycells.segmentation.strategies)\n\n\n\n\nutility functions\n\n\nDefines several general purpose functions that are used throughout findmycells (findmycells.utils)\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "api/quantification_00_specs.html",
    "href": "api/quantification_00_specs.html",
    "title": "quantification subclasses",
    "section": "",
    "text": "source\n\nQuantificationStrategy\n\n QuantificationStrategy ()\n\nNote for developers: When implementing a new quantification strategy, remember to add the following line at the end of the “.run()” method, to ensure that the quantification results are added to the database:\nquantification_object = self._add_quantification_results_to_database(quantification_object = quantification_object, results = quantification_results)\n\nsource\n\n\nQuantificationObject\n\n QuantificationObject ()\n\nExtending the ProcessingObject base class for quantification as processing subtype."
  },
  {
    "objectID": "api/preprocessing_00_specs.html",
    "href": "api/preprocessing_00_specs.html",
    "title": "preprocessing subclasses",
    "section": "",
    "text": "source\n\nPreprocessingStrategy\n\n PreprocessingStrategy ()\n\nExtending the ProcssingStrategy base class for preprocessing as processing subtype.\n\nsource\n\n\nPreprocessingObject\n\n PreprocessingObject ()\n\nExtending the ProcessingObject base class for preprocessing as processing subtype. Responsible for loading the microscopy image(s) and corresponding ROI(s) for each file, running the specified preprocessing strategies, updating the database, and eventually for saving the preprocessed images to disk for further processing steps down the line.\nNote: Even though the file_ids argument accepts (and actually expects & requires) a list as input, only a single file_id will be passed to a PreprocessingObject upon initialization. This is handled in the api module of findmycells."
  },
  {
    "objectID": "api/segmentation_01_strategies.html",
    "href": "api/segmentation_01_strategies.html",
    "title": "segmentation strategies",
    "section": "",
    "text": "source\n\nDeepflash2SemanticSegmentationStrat\n\n Deepflash2SemanticSegmentationStrat ()\n\nRun semantic segmentation using deepflash2. Requires that you have already an ensemble of trained models ready to use and to provide the path to the directory where these models can be found. If you choose to process the files in your project in smaller batches (which is highly recommended, due to a huge memory load), make sure to run the segmentations “strategy-wise” in the processing configs below before launching the processing (i.e. keep the box checked).\n\nsource\n\n\nLosslessConversionOfDF2SemanticSegToInstanceSegWithCPStrat\n\n LosslessConversionOfDF2SemanticSegToInstanceSegWithCPStrat ()\n\nExtending the ProcssingStrategy base class for segmentation as processing subtype. Also adding another property that denotes the type of segmentation (i.e. instance or semantic)."
  },
  {
    "objectID": "api/segmentation_00_specs.html",
    "href": "api/segmentation_00_specs.html",
    "title": "segmentation subclasses",
    "section": "",
    "text": "source\n\nSegmentationStrategy\n\n SegmentationStrategy ()\n\nExtending the ProcssingStrategy base class for segmentation as processing subtype. Also adding another property that denotes the type of segmentation (i.e. instance or semantic).\n\nsource\n\n\nSegmentationObject\n\n SegmentationObject ()\n\nExtending the ProcessingObject base class for segmentation as processing subtype. The clear_all_tmp_data() method allows to clear all chached results that might accumulate for instance while using deepflash2."
  },
  {
    "objectID": "api/postprocessing_01_strategies.html",
    "href": "api/postprocessing_01_strategies.html",
    "title": "postprocessing options",
    "section": "",
    "text": "source\n\nReconstructCellsIn3DFrom2DInstanceLabelsStrat\n\n ReconstructCellsIn3DFrom2DInstanceLabelsStrat ()\n\nDescription; Include requirements Mention multi matches traceback which can be used in inspection\n\nsource\n\n\nFillHolesStrat\n\n FillHolesStrat ()\n\nSpecific conditions can lead to “holes” within the segmentations of your image features. This can make total sense, for instance if youre analyzing specifically the cells cytoplasm, and want to spare out the nucleus, or if youre analyzing ring-like features. In other cases, however, these “holes” may be artefacts and require correction. This strategy was designed for exactly this purpose: fill the “holes” in your segmented features, if they should not be there.\n\nsource\n\n\nApplyExclusionCriteriaStrat\n\n ApplyExclusionCriteriaStrat ()\n\nAnother typical postprocessing step is to filter your data by applying exclusion criteria. Please check the following list of exclusion criteria with detailed descriptions to see which criteria are currently implemented in your installed findmycells version. Importantly, if you would like to use this strategy, please make sure to run this strategy as the last postprocessing strategy, to ensure that all other processing steps have been completed. \b \u0001- Minimum feature position relative to area ROI: \u0001If you provided ROIs that denote in which area of each image you’d like to quantify the image features, you can use this criterion to specify when to exclude detected features from the quantification. These are the options you can chose from, in order of increasing distance of your feature from the area ROI: within < intersects < touches < no overlap The option you select will always be the first relative position to be included. For example, if you select “intersects”, all features that are fully within your area ROI (classified as “within”) and all features that are intersected by the area ROI border (classified as “intersects”) will be kept, while all features that only touch the area ROI border (classified as “touches”) or that lie completely outside of it (classified as “no overlap”) will be excluded from further analyses. Note: if you are analyzing an image stack, a features` position can be classified differently depending on the image plane. Findmycells will always use the nearest classification. That means, if a feature was classified in one plane as “within” but only as “intersects” or even as “no overlap” in the other planes, the entire 3D feature will be classified as “within”.\u0002\u0002 \b \u0001- Minimum feature size [px]: \u0001Every detected feature whose area is smaller than the specified pixel value will will be deleted from the segmentation masks. Note: if you are analyzing an image stack, this strategy will determine for each 3D feature the plane in which is has the largest area & then apply this exclusion criterion based on this area value.\u0002\u0002 \b \u0001- Minimum planes covered (only relevant for image stacks): \u0001Similarly to “minimum feature size”, which checks for the expansion of your image features in x-y-dimensions, you can use this exclusion criterion to also check for a minimum size of your features in the z-dimension. The number you specify here will represent the minimum number of consecutive planes each image feature needs to cover to remain in your segmentation masks. For instance, if you specify it to be 3, all features that are only present in a single or in two consecutive planes will be deleted. Note: this exclusion criterion is, obviously, only relevant for projects that analyze image stacks. If you are working only with 2D images, this value will be ignored and 1 will be used as default.\u0002\u0002"
  },
  {
    "objectID": "api/interfaces.html",
    "href": "api/interfaces.html",
    "title": "interfaces",
    "section": "",
    "text": "Application programming interface (API)\nThe following class defines the API of findmycells, which represents the intended way of how users interact with and use findmycells, if they are not using the graphical user interface (GUI; defined below).\n\nsource\n\nAPI\n\n API (project_root_dir:pathlib.PosixPath)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\nGraphical user interface\nThe following classes are used to create the graphical user interface of findmycells. Please note that classes will be listed here in an inverted hirarchy, such that you can find the main GUI class at the very end, and classes that handle much more specific details at the beginning.\n\nclass StrategyConfigurator:\n    \n    \"\"\"\n    This class implements the interface that let´s the user choose and \n    configurate the processing strategies. It will be placed inside of\n    an accordion that is implemented in the `ProcessingStepPage`.\n    It gets a list of all available processing strategies from the parent\n    `ProcessingStepPage` and, thus, eventually from the `API` that checks\n    for all available processing strategies in the corresponding processing\n    submodule (e.g. \"findmycells.preprocessing.strategies\"). Upon initializing\n    it´s dropdown widget, which let´s the user browser through the different\n    available strategies, it also initializes an object of each strategy.\n    This object can then be used to run it´s associated method \n    \".initialize_gui_configs_and_widget()\" to build the specified widget, \n    using its `GUIConfigs` instance. Essentially, this contains a\n    description of what the processing strategy does and, if applicable,\n    widgets to specify all parameters that can be configurated for this \n    strategy. Finally, a \"confirm & export\" and a \"remove\" button allow\n    the user to load or delete the current to or from the findmycells\n    project, respectively.\n    \"\"\"\n    \n    def __init__(self,\n                 available_strategy_classes: List,\n                 parent_accordion: w.Accordion,\n                 target_for_configs_export: List) -> None:\n        self.available_strategy_classes = available_strategy_classes\n        self.parent_accordion = parent_accordion\n        self.target_for_configs_export = target_for_configs_export\n        self.widget = self._initialize_widget()\n        self._link_widgets_with_eventhandlers()\n\n        \n    def _initialize_widget(self) -> WidgetType:\n        info_text = w.HTML(value = ('Please select one of the available processing methods from the dropdown menu below. '\n                                    'Feel free to click through all listed methods, as each of them will display a '\n                                    'short description of what exactly to expect and may also prompt you with some '\n                                    'customization options. To select a method with all selected customization options, '\n                                    'click on the \"confirm selection & export configurations\". Using the \"remove method\" '\n                                    'button allows you to remove previously loaded methods again.'))\n        self.dropdown = self._initialize_dropdown()\n        self.confirm_and_export_button = w.Button(description = 'confirm selection & export configurations', layout = {'width': '30%'})\n        self.remove_button = w.Button(description = 'remove method', layout = {'width': '20%'}, disabled = True)\n        self.displayed_strat_widget = w.VBox([self.dropdown.value.widget], layout = {'width': '95%'})\n        widget = w.VBox([info_text,\n                         GUI_SPACER,\n                         w.HBox([self.dropdown, self.confirm_and_export_button, self.remove_button]),\n                         GUI_SPACER,\n                         self.displayed_strat_widget])\n        return widget\n        \n        \n    def _link_widgets_with_eventhandlers(self) -> None:\n        self.confirm_and_export_button.on_click(self._confirm_and_export_button_clicked)\n        self.remove_button.on_click(self._remove_button_clicked)\n        self.dropdown.observe(self._dropdown_option_changed, names = 'value')\n        \n    \n    def _initialize_dropdown(self) -> WidgetType:\n        dropdown_option_tuples = []\n        for strategy_class in self.available_strategy_classes:\n            strategy_obj = strategy_class()\n            strategy_obj.initialize_gui_configs_and_widget()\n            dropdown_option_tuples.append((strategy_obj.dropdown_option_value_for_gui, strategy_obj))\n        return w.Dropdown(options = dropdown_option_tuples, layout = {'width': '50%'}) \n        \n        \n    def _get_own_position_idx_in_parent_accordion(self) -> int:\n        return self.parent_accordion.children.index(self.widget)\n        \n        \n    def _confirm_and_export_button_clicked(self, b) -> None:\n        self._export_configs()\n        self._change_disable_settings_of_customizable_widgets(disable_customizable_widgets = True)\n        self._add_new_strategy_configurator_to_parent_accordion()\n        self._change_own_accordion_tab_title(title = self.dropdown.value.dropdown_option_value_for_gui)\n        self.parent_accordion.selected_index = None\n        \n        \n    def _add_new_strategy_configurator_to_parent_accordion(self) -> None:\n        new_strategy_configurator = StrategyConfigurator(available_strategy_classes = self.available_strategy_classes,\n                                                         parent_accordion = self.parent_accordion,\n                                                         target_for_configs_export = self.target_for_configs_export)\n        self.parent_accordion.children = self.parent_accordion.children + (new_strategy_configurator.widget, )\n        position_idx = len(self.parent_accordion.children) - 1\n        self.parent_accordion.set_title(position_idx, 'Expand me to add a processing method')\n                                                         \n                                                         \n    def _change_own_accordion_tab_title(self, title: str) -> None:\n        position_idx = self._get_own_position_idx_in_parent_accordion()\n        self.parent_accordion.set_title(position_idx, title)\n\n        \n    def _export_configs(self) -> None:\n        selected_strategy_obj = self.dropdown.value\n        current_configs = selected_strategy_obj.gui_configs.export_current_config_values()\n        position_idx = self._get_own_position_idx_in_parent_accordion()\n        self.target_for_configs_export.insert(position_idx, (selected_strategy_obj.__class__, current_configs))      \n        \n        \n    def _change_disable_settings_of_customizable_widgets(self, disable_customizable_widgets: bool) -> None:\n        self.remove_button.disabled = not disable_customizable_widgets\n        self.dropdown.disabled = disable_customizable_widgets\n        self.confirm_and_export_button.disabled = disable_customizable_widgets\n        for widget in self.displayed_strat_widget.children[0].children:\n            if hasattr(widget, 'disabled'):\n                widget.disabled = disable_customizable_widgets\n            elif type(widget) == w.HBox:\n                if hasattr(widget.children[0], 'disabled'):\n                    widget.children[0].disabled = disable_customizable_widgets\n        \n        \n    def _remove_button_clicked(self, b) -> None:\n        self._remove_configs()\n        if len(self.parent_accordion.children) == 1:\n            self._change_disable_settings_of_customizable_widgets(disable_customizable_widgets = False)\n            self._change_own_accordion_tab_title(title = 'Expand me to add a processing method')\n        else:\n            currently_present_accordion_tabs = len(self.parent_accordion.children)\n            currently_confirmed_strategies = len(self.target_for_configs_export)\n            tabs_available_for_selection = currently_present_accordion_tabs - currently_confirmed_strategies\n            if tabs_available_for_selection > 1:\n                self._remove_own_tab_from_parent_accordion()\n            else:\n                self._change_disable_settings_of_customizable_widgets(disable_customizable_widgets = False)\n                self._change_own_accordion_tab_title(title = 'Expand me to add a processing method')\n                \n                \n    def _remove_own_tab_from_parent_accordion(self) -> None:\n        tmp_children = list(self.parent_accordion.children)\n        tmp_titles = []\n        for idx in range(len(tmp_children)):\n            tmp_titles.append(self.parent_accordion.get_title(idx))\n        position_idx = self._get_own_position_idx_in_parent_accordion()\n        tmp_children.pop(position_idx)\n        tmp_titles.pop(position_idx)\n        self.parent_accordion.children = tuple(tmp_children)\n        for idx, title in enumerate(tmp_titles):\n            self.parent_accordion.set_title(idx, title)\n            \n            \n    def _remove_configs(self) -> None:\n        position_idx = self._get_own_position_idx_in_parent_accordion()\n        self.target_for_configs_export.pop(position_idx)\n                \n                \n    def _dropdown_option_changed(self, change) -> None:\n        new_selection = change.new\n        self.displayed_strat_widget.children = (new_selection.widget, )\n\n\nsource\n\nPageButtonBundle\n\n PageButtonBundle (bundle_id:str,\n                   page_screen:traitlets.traitlets.MetaHasTraits,\n                   all_navigator_buttons:List, api:__main__.API)\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nSettingsPage\n\n SettingsPage (bundle_id:str,\n               page_screen:traitlets.traitlets.MetaHasTraits,\n               all_navigator_buttons:List, api:__main__.API)\n\nSubclass of PageButtonBundle that implements the GUI interface that allows the user to specify all settings relevant to the findmycells project. It also enables saving & loading of the project status, and to browse through the file history that is automatically created by findmycells.\n\nsource\n\n\nProcessingStepPage\n\n ProcessingStepPage (bundle_id:str,\n                     page_screen:traitlets.traitlets.MetaHasTraits,\n                     all_navigator_buttons:List, api:__main__.API)\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nInspectionPage\n\n InspectionPage (bundle_id:str,\n                 page_screen:traitlets.traitlets.MetaHasTraits,\n                 all_navigator_buttons:List, api:__main__.API)\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nGUI\n\n GUI ()\n\nInitialize self. See help(type(self)) for accurate signature."
  },
  {
    "objectID": "api/utils.html",
    "href": "api/utils.html",
    "title": "utility functions",
    "section": "",
    "text": "source\n\nlist_dir_no_hidden\n\n list_dir_no_hidden (path:pathlib.PosixPath,\n                     only_dirs:Optional[bool]=False,\n                     only_files:Optional[bool]=False)\n\n\nsource\n\n\nload_zstack_as_array_from_single_planes\n\n load_zstack_as_array_from_single_planes (path:pathlib.PosixPath,\n                                          file_id:str,\n                                          minx:Optional[int]=None,\n                                          maxx:Optional[int]=None,\n                                          miny:Optional[int]=None,\n                                          maxy:Optional[int]=None)\n\n\nsource\n\n\nunpad_x_y_dims_in_3d_array\n\n unpad_x_y_dims_in_3d_array (padded_3d_array:numpy.ndarray, pad_width:int)\n\n\nsource\n\n\nget_polygon_from_instance_segmentation\n\n get_polygon_from_instance_segmentation (single_plane:numpy.ndarray,\n                                         label_id:int)"
  },
  {
    "objectID": "api/inspection_00_methods.html",
    "href": "api/inspection_00_methods.html",
    "title": "inspection",
    "section": "",
    "text": "Note: This submodule does not use the abstract base classes ProcessingObject and ProcessingStrategy. The reason for this is to make specifying the settings and configurations for these inspection methods more interactive for the user - especially when accessed via the GUI. Unfortunately, this sacrifices a bit of overall code consistency. However, since inspection also does not really represent a processing step, this trade-off in favor of usability seemed reasonable. To make make the distinction ever more apparent, the classes that handle the different inspections will be referred to as “methods” instead of “strategies” in the class names.\n\nsource\n\nInspectionMethod\n\n InspectionMethod ()\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nInspectStackIn3D\n\n InspectStackIn3D ()\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\nsource\n\n\nInspectSinglePlane\n\n InspectSinglePlane ()\n\nHelper class that provides a standard way to create an ABC using inheritance."
  },
  {
    "objectID": "api/postprocessing_00_specs.html",
    "href": "api/postprocessing_00_specs.html",
    "title": "postprocessing subclasses",
    "section": "",
    "text": "source\n\nPostprocessingStrategy\n\n PostprocessingStrategy ()\n\nExtending the ProcssingStrategy base class for postprocessing as processing subtype.\n\nsource\n\n\nPostprocessingObject\n\n PostprocessingObject ()\n\nExtending the ProcessingObject base class for postprocessing as processing subtype."
  },
  {
    "objectID": "api/database.html",
    "href": "api/database.html",
    "title": "database",
    "section": "",
    "text": "source\n\nDatabase\n\n Database (project_configs:findmycells.configs.ProjectConfigs)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nFileHistory\n\n FileHistory (file_id:str, source_image_filepath:pathlib.PosixPath)\n\nInitialize self. See help(type(self)) for accurate signature."
  },
  {
    "objectID": "api/quantification_01_strategies.html",
    "href": "api/quantification_01_strategies.html",
    "title": "quantification strategies",
    "section": "",
    "text": "source\n\nCountFeaturesInWholeAreaROIsStrat\n\n CountFeaturesInWholeAreaROIsStrat ()\n\nStrategy description"
  }
]