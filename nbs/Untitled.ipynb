{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ecb979-530b-4794-89eb-01db280e73fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path, PosixPath\n",
    "from typing import Optional, Dict, Any, List\n",
    "import pandas as pd\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdc1e5f-e37d-474c-a7e2-f7923f433789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_dir_no_hidden(path: Path, only_dirs: Optional[bool]=False, only_files: Optional[bool]=False) -> List:\n",
    "    if only_dirs == True:\n",
    "        detected_paths = [elem for elem in path.iterdir() if (elem.is_dir() == True) & (elem.name.startswith('.') == False)]\n",
    "    elif only_files == True:\n",
    "        detected_paths = [elem for elem in path.iterdir() if (elem.is_dir() == False) & (elem.name.startswith('.') == False)]\n",
    "    else:\n",
    "        detected_paths = [elem for elem in path.iterdir() if elem.name.startswith('.') == False]\n",
    "    return detected_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee62612-7fb3-43ee-bba8-a78c06d9bd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectConfigs:\n",
    "    \n",
    "    def __init__(self, root_dir: Path, project_configs_filepath: Optional[Path]=None) -> None:\n",
    "        assert type(root_dir) == PosixPath, '\"root_dir\" must be pathlib.Path referring to an existing directory.'\n",
    "        assert root_dir.is_dir(), '\"root_dir\" must be pathlib.Path referring to an existing directory.'\n",
    "        self.root_dir = root_dir\n",
    "        if type(project_configs_filepath) == PosixPath:\n",
    "            self.attempt_loading_from_configs_filepath(project_configs_filepath = project_configs_filepath)\n",
    "            \n",
    "    \n",
    "    def _load_available_processing_modules(self) -> None:\n",
    "        \"\"\"\n",
    "        load all processing modules (and their specs submodules)\n",
    "        that are available in the installed fmc version as attr to this object, \n",
    "        to make it easier to access them and the default values.\n",
    "        \"\"\"\n",
    "        pass\n",
    "            \n",
    "            \n",
    "    def add_processing_step_configs(self, processing_step_id: str, configs: Dict[str, Any]) -> None:\n",
    "        \"\"\"\n",
    "        1. Checks whether 'processing_step_id' is valid - i.e. if it matches a module name of findmycells\n",
    "            - seems the easiest approach that would also keep it flexible for extensions\n",
    "            - alternatively, a module could be passed here, such that defaults can be loaded from there right away \n",
    "              (which should also be possible from the str?)\n",
    "        2. Set passed configs (confirm that itÂ´s a dictionary and has only strings as keys) as attribute to this object\n",
    "            - loading of default values needed here? From \"specs\" submodule in each processing module?\n",
    "        \"\"\"\n",
    "        self._assert_valid_processing_step_id(processing_step_id)\n",
    "        configs = self._assert_valid_configs_input_and_fill_with_defaults_where_needed(processing_step_id, configs)\n",
    "        setattr(self, processing_step_id, configs)\n",
    "        # maybe we could add a warning here, if there were already some configs existing and they have been replaced now\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _assert_valid_processing_step_id(self, processing_step_id: str) -> None:\n",
    "        \"\"\"\n",
    "        Asserts whether 'processing_step_id' is valid, i.e. whether it matches an\n",
    "        existing processing module in findmycells that contains a \"specs.py\" file.\n",
    "        \n",
    "        Needs to be implemented once basic refactored structure of fmc was established & exported via nbdev\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def _assert_valid_configs_input_and_fill_with_defaults_where_needed(self, processing_step_id: str, configs: Dict[str, Any]) -> None:\n",
    "        \"\"\"\n",
    "        Asserts that all keys of the configs dictionary are:\n",
    "        - of type string\n",
    "        - are keys defined by the respective specs\n",
    "        - their value types match the valid value types\n",
    "        \n",
    "        If keys are missing, will load the corresponding defaults as defined in the specs\n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    \n",
    "    def load_from_disk(self, project_configs_filepath: Path) -> None:\n",
    "        \"\"\"\n",
    "        Reconstitute configs object from this file (which is probably a pickle dictionary)\n",
    "        \"\"\"\n",
    "    \n",
    "    \n",
    "    def save_to_disk(self, filename: Optional[str]=None, out_dir: Optional[Path]=None) -> None:\n",
    "        \"\"\"\n",
    "        Saves current object as pickle file to disk. If filename & out_dir are provided, \n",
    "        and of correct types, will save it there, otherwise defaults are something like\n",
    "        \"findmycells_project_configs_\" + date and time in project root dir.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cc8803-51d7-4d8e-bf95-34d55eadc57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectDatabase:\n",
    "    \n",
    "    def __init__(self, project_configs: ProjectConfigs) -> None:\n",
    "        self.project_configs = project_configs\n",
    "        self._initialize_project_in_root_dir()\n",
    "        self._create_file_infos_as_attr()\n",
    "        self._create_file_histories_as_attr()\n",
    "        \n",
    "        \n",
    "    def _initialize_project_in_root_dir(self) -> None:\n",
    "        self._initialize_all_top_level_subdirectories()\n",
    "        self._initialize_segmentation_tool_subdirectories()\n",
    "        self._initialize_microscopy_images_subdirectory_tree()\n",
    "    \n",
    "          \n",
    "    def _initialize_all_top_level_subdirectories(self) -> None:\n",
    "        self._find_or_create_subdir(target_name = 'microscopy_images', keywords = ['microscopy', 'Microscopy'])\n",
    "        self._find_or_create_subdir(target_name = 'rois_to_analyze', keywords = ['rois', 'ROIs', 'ROIS', 'Rois'])\n",
    "        self._find_or_create_subdir(target_name = 'preprocessed_images', keywords = ['preprocessed', 'Preprocessed', 'pre-processed'])\n",
    "        self._find_or_create_subdir(target_name = 'segmentation_tool', keywords = ['tool', 'Tool'])\n",
    "        self._find_or_create_subdir(target_name = 'semantic_segmentations', keywords = ['semantic', 'Semantic'])\n",
    "        self._find_or_create_subdir(target_name = 'instance_segmentations', keywords = ['instance', 'Instance'])\n",
    "        self._find_or_create_subdir(target_name = 'postprocessed_images', keywords = ['postprocessed', 'Postprocessed', 'post-processed'])\n",
    "        self._find_or_create_subdir(target_name = 'quantified_segmentations', keywords = ['quantified', 'Quantified', 'quantification', 'Quantification'])\n",
    "        self._find_or_create_subdir(target_name = 'results', keywords = ['results', 'Results'])\n",
    "        self._find_or_create_subdir(target_name = 'inspection', keywords = ['inspect', 'Inspect'])\n",
    "        \n",
    "        \n",
    "    def _find_or_create_subdir(self, target_name: str, keywords: List[str], parent_dir: Optional[Path]=None) -> None:\n",
    "        if parent_dir == None:\n",
    "            parent_dir = self.project_configs.root_dir\n",
    "        subdir_found = False\n",
    "        for path in parent_dir.iterdir():\n",
    "            if path.is_dir():\n",
    "                for key in keywords:\n",
    "                    if key in path.name:\n",
    "                        subdir_found = True\n",
    "                        subdir_path = path\n",
    "                        break\n",
    "        if subdir_found == False:\n",
    "            subdir_path = parent_dir.joinpath(target_name)\n",
    "            subdir_path.mkdir()\n",
    "        print(subdir_path)\n",
    "        print(subdir_found)\n",
    "        setattr(self, f'{target_name}_dir', subdir_path.name)\n",
    "                                               \n",
    "    \n",
    "    def _initialize_segmentation_tool_subdirectories(self) -> None:    \n",
    "        self._find_or_create_subdir(target_name = 'trained_models',\n",
    "                                    keywords = ['models'],\n",
    "                                    parent_dir = self.project_configs.root_dir.joinpath(self.segmentation_tool_dir))\n",
    "        self._find_or_create_subdir(target_name = 'segmentation_tool_temp_dir',\n",
    "                                    keywords = ['tmp', 'temp'],\n",
    "                                    parent_dir = self.project_configs.root_dir.joinpath(self.segmentation_tool_dir))\n",
    "        \n",
    "        \n",
    "    def _initialize_microscopy_images_subdirectory_tree(self) -> None:\n",
    "        if len(list_dir_no_hidden(path = self.project_configs.root_dir.joinpath(self.microscopy_images_dir), only_dirs = True)) > 0:\n",
    "            self._assert_valid_microscopy_image_subdir_tree_structure()\n",
    "        else:\n",
    "            self._create_representative_microscopy_image_subdir_tree()\n",
    "            \n",
    "            \n",
    "    def _assert_valid_microscopy_image_subdir_tree_structure(self) -> None:\n",
    "        microscopy_images_dir_path = self.project_configs.root_dir.joinpath(self.microscopy_images_dir)\n",
    "        for main_group_id_subdir_path in list_dir_no_hidden(path = microscopy_images_dir_path, only_dirs = True):\n",
    "            tmp_subgroup_subdir_paths = list_dir_no_hidden(path = main_group_id_subdir_path, only_dirs = True)\n",
    "            assert len(tmp_subgroup_subdir_paths) > 0, f'Invalid microscopy images subdir structure! Expected at least one subdirectory in {main_group_id_subdir_path}.'\n",
    "            for subgroup_id_subdir_path in tmp_subgroup_subdir_paths:\n",
    "                tmp_subject_subdir_paths = list_dir_no_hidden(path = subgroup_id_subdir_path, only_dirs = True)\n",
    "                assert len(tmp_subject_subdir_paths) > 0, f'Invalid microscopy images subdir structure! Expected at least one subdirectory in {subgroup_id_subdir_path}.'\n",
    "                for subject_id_subdir_path in tmp_subject_subdir_paths:\n",
    "                    tmp_hemisphere_subdir_paths = list_dir_no_hidden(path = subject_id_subdir_path, only_dirs = True)\n",
    "                    assert len(tmp_subject_subdir_paths) > 0, f'Invalid microscopy images subdir structure! Expected at least one subdirectory in {subject_id_subdir_path}.'\n",
    "                    for hemisphere_id_subdir_path in tmp_hemisphere_subdir_paths:\n",
    "                        valid_hemisphere_id = hemisphere_id_subdir_path.name in ['ipsilateral', 'ipsi', 'Ipsilateral', 'Ipsi',\n",
    "                                                                                  'contralateral', 'contra', 'Contralateral', 'Contra',\n",
    "                                                                                  'any', 'Any', 'undefiened', 'Undefiened', 'unidentified', 'Unidentified']\n",
    "                        assert valid_hemisphere_id == True, f'\"{hemisphere_id_subdir_path.name}\" ({hemisphere_id_subdir_path}) is not a valid hemisphere id!'\n",
    "                        #any_file_present = len(list_dir_no_hidden(path = hemisphere_id_subdir_path, only_files = True)) > 0\n",
    "                        #assert any_file_present == True, f'Invalid microscopy images subdir structure! Expected at least one file in {hemisphere_id_subdir_path}.'\n",
    "                           \n",
    "                            \n",
    "    def _create_representative_microscopy_image_subdir_tree(self) -> None:\n",
    "        for representative_main_group_id in ['wildtype', 'transgenic']:\n",
    "            for representative_subgroup_id in ['week_1', 'week_4']:\n",
    "                if representative_main_group_id == 'wildtype':\n",
    "                    subject_ids = ['mouse_1', 'mouse_2', 'mouse_3']\n",
    "                else:\n",
    "                    subject_ids = ['mouse_4', 'mouse_5', 'mouse_6']\n",
    "                for representative_subject_id in subject_ids:\n",
    "                    for representative_hemisphere_id in ['contralateral', 'ipsilateral']:\n",
    "                        self._make_subdir_tree(main_group_id = representative_main_group_id,\n",
    "                                               subgroup_id = representative_subgroup_id,\n",
    "                                               subject_id = representative_subject_id,\n",
    "                                               hemisphere_id = representative_hemisphere_id)\n",
    "                            \n",
    "                            \n",
    "    def _make_subdir_tree(self, main_group_id: str, subgroup_id: str, subject_id: str, hemisphere_id: str) -> None:\n",
    "        microscopy_images_dir = self.project_configs.root_dir.joinpath(self.microscopy_images_dir)\n",
    "        microscopy_images_dir.joinpath(main_group_id).mkdir(exist_ok = True)\n",
    "        microscopy_images_dir.joinpath(main_group_id, subgroup_id).mkdir(exist_ok = True)\n",
    "        microscopy_images_dir.joinpath(main_group_id, subgroup_id, subject_id).mkdir(exist_ok = True)\n",
    "        microscopy_images_dir.joinpath(main_group_id, subgroup_id, subject_id, hemisphere_id).mkdir(exist_ok = True)\n",
    "                                               \n",
    "                                               \n",
    "\n",
    "    def _create_file_infos_as_attr(self) -> None:\n",
    "        file_infos = {'file_id': [],\n",
    "                      'original_filename': [],\n",
    "                      'main_group_id': [],\n",
    "                      'subgroup_id': [],\n",
    "                      'subject_id': [],\n",
    "                      'hemisphere_id': [],\n",
    "                      'microscopy_filepath': [],\n",
    "                      'microscopy_filetype': [],\n",
    "                      'rois_present': [],\n",
    "                      'rois_filepath': [],\n",
    "                      'rois_filetype': [],\n",
    "                      'datetime_added': [],\n",
    "                      'datetime_removed': []}\n",
    "        setattr(self, 'file_infos', file_infos)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _create_file_histories_as_attr(self) -> None:\n",
    "        setattr(self, 'file_histories', {})\n",
    "        \n",
    "        \n",
    "    def compute_file_infos(self, skip_checking: bool=False) -> None:\n",
    "        self._add_new_files_to_database(skip_checking = skip_checking)\n",
    "        self._identify_removed_files() # ToDo: not implemented yet\n",
    "        \n",
    "        \n",
    "    def _add_new_files_to_database(self, skip_checking: bool) -> None:\n",
    "        microscopy_images_dir_path = self.project_configs.root_dir.joinpath(self.microscopy_images_dir)\n",
    "        for main_group_id_subdir_path in list_dir_no_hidden(path = microscopy_images_dir_path, only_dirs = True):\n",
    "            for subgroup_id_subdir_path in list_dir_no_hidden(path = rois_to_analyze_dir_path, only_dirs = True):\n",
    "                for subject_id_subdir_path in list_dir_no_hidden(path = subgroup_id_subdir_path, only_dirs = True):\n",
    "                    for hemisphere_id_subdir_path in list_dir_no_hidden(path = subject_id_subdir_path, only_dirs = True):\n",
    "                        for filepath in list_dir_no_hidden(path = hemisphere_id_subdir_path, only_files = True):\n",
    "                            if skip_checking == True:\n",
    "                                new_file_found = True\n",
    "                            else:\n",
    "                                new_file_found = self._is_this_a_new_file(filepath = filepath)\n",
    "                            if new_file_found == True:\n",
    "                                file_id = self._get_next_available_file_id()\n",
    "                                self._append_details_to_file_infos(file_id = file_id, filepath = filepath)\n",
    "                                self._add_new_file_history_tracker(file_id = file_id, source_image_filepath = filepath)\n",
    "        \n",
    "    \n",
    "    def _is_this_a_new_file(self, filepath: Path) -> bool:\n",
    "        hemisphere_subdir_path = filepath.parent\n",
    "        subject_subdir_path = hemisphere_subdir_path.parent\n",
    "        subgroup_subdir_path = subject_subdir_path.parent\n",
    "        main_group_id = subgroup_subdir_path.parent.name\n",
    "        original_filename = filepath.name[:filepath.name.find('.')]\n",
    "        file_infos_as_df = pd.DataFrame(data = self.file_infos)\n",
    "        matching_entries = file_infos_as_df.loc[(file_infos_as_df['main_group_id'] == main_group_id) &\n",
    "                                                (file_infos_as_df['subgroup_id'] == subgroup_subdir_path.name) &\n",
    "                                                (file_infos_as_df['subject_id'] == subject_subdir_path.name) &\n",
    "                                                (file_infos_as_df['hemisphere_id'] == hemisphere_subdir_path.name) &\n",
    "                                                (file_infos_as_df['original_filename'] == original_filename)].shape[0]\n",
    "        if matching_entries == 0:\n",
    "            is_new_file = True\n",
    "        elif matching_entries == 1:\n",
    "            is_new_file = False\n",
    "        else:\n",
    "            raise ValueError(f'Found multiple entries in file_infos for {filepath}.')\n",
    "        return is_new_file\n",
    "        \n",
    "        \n",
    "    def _get_next_available_file_id(self) -> int:\n",
    "        if len(self.file_infos['file_id']) > 0:\n",
    "            file_id = max([int(file_id_str) for file_id_str in self.file_infos['file_id']]) + 1\n",
    "        else:\n",
    "            file_id = 0\n",
    "        return file_id\n",
    "                                               \n",
    "    \n",
    "    \n",
    "    def _append_details_to_file_infos(self, file_id: int, filepath: Path) -> None:\n",
    "        hemisphere_subdir_path = filepath.parent\n",
    "        subject_subdir_path = hemisphere_subdir_path.parent\n",
    "        subgroup_subdir_path = subject_subdir_path.parent\n",
    "        main_group_subdir_path = subgroup_subdir_path.parent\n",
    "        self.file_infos['file_id'].append(str(file_id).zfill(4))\n",
    "        original_filename = filepath.name[:filepath.name.find('.')]\n",
    "        self.file_infos['original_filename'].append(original_filename)\n",
    "        self.file_infos['main_group_id'].append(main_group_subdir_path.name)\n",
    "        self.file_infos['subgroup_id'].append(subgroup_subdir_path.name)\n",
    "        self.file_infos['subject_id'].append(subject_subdir_path.name)\n",
    "        self.file_infos['hemisphere_id'].append(hemisphere_subdir_path.name)\n",
    "        self.file_infos['microscopy_filepath'].append(filepath)\n",
    "        self.file_infos['microscopy_filetype'].append(filepath.name[filepath.find('.'):])\n",
    "        corresponding_dir_in_rois_to_analyze_dir = self.project_configs.root_dir.joinpath(self.rois_to_analyze_dir,\n",
    "                                                                                          main_group_subdir_path.name,\n",
    "                                                                                          subgroup_subdir_path.name,\n",
    "                                                                                          subject_subdir_path.name,\n",
    "                                                                                          hemisphere_subdir_path.name)\n",
    "        matching_roi_filepaths = []\n",
    "        for roi_filepath in list_dir_no_hidden(path = corresponding_dir_in_rois_to_analyze_dir, only_files = True):\n",
    "            if roi_filepath.name[:roi_filepath.name.find('.')] == original_filename:\n",
    "                matching_roi_filepaths.append(matching_roi_filepaths)\n",
    "        if len(matching_roi_filepaths) == 0:\n",
    "            self.file_infos['rois_present'].append(False)\n",
    "            self.file_infos['rois_filepath'].append('not_available')\n",
    "            self.file_infos['rois_filetype'].append('not_available')\n",
    "        elif len(matching_roi_filepaths) == 1:\n",
    "            self.file_infos['rois_present'].append(True)\n",
    "            self.file_infos['rois_filepath'].append(matching_roi_filepaths[0])\n",
    "            self.file_infos['rois_filetype'].append(matching_roi_filepaths[0].name[matching_roi_filepaths[0].name.find('.'):])\n",
    "        else:\n",
    "            raise ValueError('It seems like you provided more than a single ROI file in '\n",
    "                             f'{corresponding_dir_in_rois_to_analyze_dir} that matches the microscopy '\n",
    "                             f'image filename: {original_filename}. If you want to quantify image features '\n",
    "                             'within multiple ROIs per image, please use RoiSets created with ImageJ as '\n",
    "                             'described here: [Documentation link not provided yet - please raise an issue on '\n",
    "                             'https://github.com/Defense-Circuits-Lab/findmycells - thank you!')\n",
    "\n",
    "        \n",
    "    def _add_new_file_history_tracker(self, file_id: int, source_image_filepath: Path) -> None:\n",
    "        self.file_histories[file_id] = FileHistory(file_id = file_id, source_image_filepath = source_image_filepath)\n",
    "                                               \n",
    "        \n",
    "        \n",
    "    def _identify_removed_files(self) -> None:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def get_file_infos(self, identifier: str) -> Dict:\n",
    "        \"\"\"\n",
    "        supports use of either original_filename, file_id, or microscopy_filepath as input parameter identifier \n",
    "        \"\"\"\n",
    "        if identifier in self.file_infos['file_id']:\n",
    "            index = self.file_infos['file_id'].index(identifier)\n",
    "        elif identifier in self.file_infos['original_filename']:\n",
    "            index = self.file_infos['original_filename'].index(identifier)\n",
    "        elif identifier in self.file_infos['microscopy_filepath']:\n",
    "            index = self.file_infos['microscopy_filepath'].index(identifier)\n",
    "        else:\n",
    "            raise ValueError(f'{identifier} is not a valid input!')\n",
    "        file_infos = {}    \n",
    "        for key, list_of_values in self.file_infos.items():\n",
    "            if len(list_of_values) > 0:\n",
    "                file_infos[key] = list_of_values[index]\n",
    "        return file_infos\n",
    "    \n",
    "    \n",
    "    # ToDo should be re-named to something like \"change file info entries\" or similar\n",
    "    def update_file_infos(self, file_id: str, updates: Dict, preferred_empty_value: Union[bool, str, None]=None) -> None: \n",
    "        index = self.file_infos['file_id'].index(file_id)\n",
    "        for key, value in updates.items():\n",
    "            if key not in self.file_infos.keys():\n",
    "                self.add_new_key_to_file_infos(key, preferred_empty_value = preferred_empty_value)\n",
    "            self.file_infos[key][index] = value\n",
    "            \n",
    "            \n",
    "    def get_file_ids_to_process(self, input_file_ids: Optional[List], process_tracker_key: str, overwrite: bool) -> List:\n",
    "        if input_file_ids == None:\n",
    "            input_file_ids = self.file_infos['file_id']\n",
    "        if process_tracker_key not in self.file_infos.keys():\n",
    "            self.add_new_key_to_file_infos(process_tracker_key)\n",
    "        if overwrite == True:\n",
    "            output_file_ids = input_file_ids\n",
    "        else:\n",
    "            process_tracker_status = []\n",
    "            for file_id in input_file_ids:\n",
    "                index = self.file_infos['file_id'].index(file_id)\n",
    "                process_tracker_status.append(self.file_infos[process_tracker_key][index])\n",
    "            output_file_ids = [elem[0] for elem in zip(input_file_ids, process_tracker_status) if elem[1] == False or elem[1] == None]\n",
    "        return output_file_ids.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e713707-2894-4f4f-b9d1-0d36f1b7dbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileHistory:\n",
    "    \n",
    "    \n",
    "    def __init__(self, file_id: int, source_image_filepath: Path) -> None:\n",
    "        self.file_id = file_id\n",
    "        self.source_image_filepath = source_image_filepath\n",
    "        self.datetime_added = datetime.datetime.now()\n",
    "        self._initialize_tracked_history()\n",
    "        self._initilaize_tracked_settings()\n",
    "        \n",
    "        \n",
    "    def _initialize_tracked_history(self) -> None:\n",
    "        empty_history = {'processing_step_id': [],\n",
    "                         'processing_strategy': [],\n",
    "                         'step_finished_at': []}\n",
    "        empty_history_df = pd.DataFrame(data = empty_history)\n",
    "        setattr(self, 'tracked_history', empty_history_df)\n",
    "        \n",
    "        \n",
    "    def _initialize_tracked_settings(self) -> None:\n",
    "        setattr(self, 'tracked_settings', {})\n",
    "        \n",
    "        \n",
    "    def track_processing_step(self, processing_step_id: str, processing_strategy_name: str, strategy_specific_settings: Dict) -> None:\n",
    "        tracked_details = {'processing_step_id': [processing_step_id],\n",
    "                           'processing_strategy': [processing_strategy_name],\n",
    "                           'step_finished_at': [datetime.datetime.now()]}\n",
    "        tracked_details_df = pd.DataFrame(data = tracked_details)\n",
    "        self.tracked_history = pd.concat([self.tracked_history, tracked_details_df], ignore_index = True)\n",
    "        self.tracked_settings[self.tracked_history.index[-1]] = strategy_specific_settings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
