{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# database\n",
    "\n",
    "> The database holds all the relevant metadata information related to the *findmycells* project and is used to keep track of the progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Dict, Optional, Union\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#from .utils import listdir_nohidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# ToDo: improve how project directory is constructed & how filepaths are fetched\n",
    "MAIN_SUBDIR_ATTRIBUTES = {'preprocessed_images_dir': {'foldername': '02_preprocessed_images', 'key_substring': 'preprocessed'},\n",
    "                          'segmentation_tool_dir': {'foldername': '03a_segmentation_tool', 'key_substring': 'tool'},\n",
    "                          'semantic_segmentations_dir': {'foldername': '03b_semantic_segmentations', 'key_substring': 'semantic'},\n",
    "                          'instance_segmentations_dir': {'foldername': '03c_instance_segmentations', 'key_substring': 'instance'},\n",
    "                          'quantified_segmentations_dir': {'foldername': '04_quantified_segmentations', 'key_substring': 'quantified'},\n",
    "                          'results_dir': {'foldername': '05_results', 'key_substring': 'results'},\n",
    "                          'inspection_dir': {'foldername': '06_inspection', 'key_substring': 'inspection'}}\n",
    "\n",
    "SEGMENTATION_TOOL_SUBDIR_ATTRIBUTES = {'trained_models_dir': {'foldername': 'trained_models', 'key_substring': 'models'},\n",
    "                                       'segmentation_tool_temp_dir': {'foldername': 'temp', 'key_substring': 'temp'}}\n",
    "                                \n",
    "INSPECTION_SUBDIR_ATTRIBUTES = {'inspected_area_plots_dir': {'foldername': 'inspected_area_plots', 'key_substring': 'inspected_area'},\n",
    "                                'inspection_final_label_planes_dir': {'foldername': 'planes_with_final_label_ids', 'key_substring': 'final_label_ids'},\n",
    "                                'inspection_planes_for_quantification': {'foldername': 'planes_for_quantification', 'key_substring': 'for_quantification'}}\n",
    "\n",
    "RENAMING_DICT = {'file_id': 'File ID', \n",
    "                 'original_file_id': 'Original File ID',               \n",
    "                 'group_id': 'Group ID', \n",
    "                 'subject_id': 'Subject ID', \n",
    "                 'microscopy_filepath': 'Microscopy Filepath', \n",
    "                 'microscopy_filetype': 'Microscopy Filetype',\n",
    "                 'rois_present': 'Rois Present', \n",
    "                 'rois_filepath': 'Rois Filepath',\n",
    "                 'rois_filetype': 'Rois Filetype',\n",
    "                 'preprocessing_completed': 'Preprocessing Completed',\n",
    "                 'RGB': 'RGB',\n",
    "                 'total_image_planes': 'Total Image Planes',\n",
    "                 'cropping_method': 'Cropping Method',\n",
    "                 'cropping_row_indices': 'Cropping Row Indices',\n",
    "                 'cropping_column_indices': 'Cropping Column Indices',\n",
    "                 'quantification_completed': 'Quantification Completed'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# ToDo - return list of Path objects\n",
    "def listdir_nohidden(path: Path) -> List:\n",
    "    return [f for f in os.listdir(path) if f.startswith('.') == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# ToDo - split in subclasses?\n",
    "\n",
    "class Database():\n",
    "    '''\n",
    "    The database object is intended to collect and hold all information about\n",
    "    the image analysis project at hand. Depending on the type of analysis that \n",
    "    shall be performed, the Database needs to be flexible and adopt to the \n",
    "    respective needs. For instance, there might be more than just two groups \n",
    "    that are investigated, or just a single group but with multiple images per \n",
    "    subject, and so on.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, user_input_via_gui: dict) -> None:\n",
    "        self.extract_user_input(user_input_via_gui)\n",
    "        self.construct_main_subdirectories()\n",
    "        if hasattr(self, 'only_duplication') == False:\n",
    "            self.create_file_infos()\n",
    "        elif self.only_duplication == False:\n",
    "            self.create_file_infos()\n",
    "        else:\n",
    "            self.load_all()\n",
    "\n",
    "        \n",
    "    \n",
    "    def extract_user_input(self, user_input: dict) -> None:\n",
    "        for key, value in user_input.items():\n",
    "            if hasattr(self, key) == False:\n",
    "                setattr(self, key, value)\n",
    "\n",
    "\n",
    "    def construct_main_subdirectories(self) -> None:\n",
    "        subdirectories = listdir_nohidden(self.project_root_dir)\n",
    "        # Mandatory: directories with microscopy images and the rois of the areas that shall be quantified has to be created by the user\n",
    "        self.microscopy_image_dir = self.project_root_dir.joinpath([elem for elem in subdirectories if 'microscopy' in elem][0])\n",
    "        self.rois_to_analyze_dir = self.project_root_dir.joinpath([elem for elem in subdirectories if 'rois' in elem][0])\n",
    "        # Remaining directories that are currently not required to exist when the database object is created:\n",
    "        for attribute_str, subdir_dict in [('project_root_dir', MAIN_SUBDIR_ATTRIBUTES), \n",
    "                                           ('segmentation_tool_dir', SEGMENTATION_TOOL_SUBDIR_ATTRIBUTES),\n",
    "                                           ('inspection_dir', INSPECTION_SUBDIR_ATTRIBUTES)]:\n",
    "            root_path = getattr(self, attribute_str)\n",
    "            self.check_and_create_remaining_directories(root_dir = root_path, subdirectory_attributes = subdir_dict)\n",
    "    \n",
    "    \n",
    "    def check_and_create_remaining_directories(self, root_dir: Path, subdirectory_attributes: Dict) -> None:\n",
    "        existing_subdirectories = listdir_nohidden(root_dir)\n",
    "        for attribute_key in subdirectory_attributes.keys():\n",
    "            elements_matching_key_substring = [elem for elem in existing_subdirectories if subdirectory_attributes[attribute_key]['key_substring'] in elem]\n",
    "            if len(elements_matching_key_substring) > 0:\n",
    "                for matching_element in elements_matching_key_substring:\n",
    "                    if (root_dir.joinpath(matching_element).is_dir()) & (hasattr(self, attribute_key) == False):\n",
    "                        setattr(self, attribute_key, root_dir.joinpath(matching_element))\n",
    "            if hasattr(self, attribute_key) == False:\n",
    "                subdirectory_path = root_dir.joinpath(subdirectory_attributes[attribute_key]['foldername'])\n",
    "                subdirectory_path.mkdir()\n",
    "                setattr(self, attribute_key, subdirectory_path)                       \n",
    "    \n",
    "    \n",
    "    def create_file_infos(self) -> None:\n",
    "        # Initial information will be retrieved from the microscopy_image_dir\n",
    "        self.file_infos = {'file_id': list(),\n",
    "                           'original_file_id': list(),\n",
    "                           'group_id': list(),\n",
    "                           'subject_id': list(),\n",
    "                           'microscopy_filepath': list(),\n",
    "                           'microscopy_filetype': list(),\n",
    "                           'rois_present': list(),\n",
    "                           'rois_filepath': list(),\n",
    "                           'rois_filetype': list()}\n",
    "        file_id = 0\n",
    "        for group in listdir_nohidden(self.microscopy_image_dir):\n",
    "            for subject in listdir_nohidden(self.microscopy_image_dir.joinpath(group)):\n",
    "                for filename in listdir_nohidden(self.microscopy_image_dir.joinpath(group, subject)):\n",
    "                    self.file_infos['file_id'].append(str(file_id).zfill(4))\n",
    "                    original_file_id = filename[:filename.find('.')]\n",
    "                    self.file_infos['original_file_id'].append(original_file_id)\n",
    "                    self.file_infos['group_id'].append(group)\n",
    "                    self.file_infos['subject_id'].append(subject)\n",
    "                    self.file_infos['microscopy_filepath'].append(self.microscopy_image_dir.joinpath(group, subject, filename))\n",
    "                    self.file_infos['microscopy_filetype'].append(filename[filename.find('.'):])\n",
    "                    \n",
    "                    matching_roi_filenames = [elem for elem in listdir_nohidden(self.rois_to_analyze_dir.joinpath(group,subject)) if elem.startswith(original_file_id)]\n",
    "                    if len(matching_roi_filenames) == 0:\n",
    "                        self.file_infos['rois_present'].append(False)\n",
    "                        self.file_infos['rois_filepath'].append('not_available')\n",
    "                        self.file_infos['rois_filetype'].append('not_available')                      \n",
    "                    elif len(matching_roi_filenames) == 1:\n",
    "                        roi_filename = matching_roi_filenames[0]\n",
    "                        self.file_infos['rois_present'].append(True)\n",
    "                        self.file_infos['rois_filepath'].append(self.rois_to_analyze_dir.joinpath(group, subject, roi_filename))\n",
    "                        self.file_infos['rois_filetype'].append(roi_filename[roi_filename.find('.'):])\n",
    "                    else:\n",
    "                        message_line_0 = 'It seems like you provided more than a single ROI file in:\\n'\n",
    "                        message_line_1 = f'{self.rois_to_analyze_dir.joinpath(group,subject)}\\n'\n",
    "                        message_line_2 = 'If you want to quantify image features within multiple ROIs per image, please use RoiSets created with ImageJ as described here:\\n'\n",
    "                        message_line_3 = 'Documentation not live yet - please contact: segebarth_d@ukw.de for more information.'\n",
    "                        error_message = message_line_0 + message_line_1 + message_line_2 + message_line_3\n",
    "                        raise ValueError(error_message)\n",
    "                    \n",
    "                    file_id += 1\n",
    "                \n",
    "                    \n",
    "    def get_file_infos(self, identifier: str) -> Dict:\n",
    "        # supports use of either original_file_id, file_id, or microscopy_filepath as input parameter identifier       \n",
    "        if identifier in self.file_infos['file_id']:\n",
    "            index = self.file_infos['file_id'].index(identifier)\n",
    "        elif identifier in self.file_infos['original_file_id']:\n",
    "            index = self.file_infos['original_file_id'].index(identifier)\n",
    "        elif identifier in self.file_infos['microscopy_filepath']:\n",
    "            index = self.file_infos['microscopy_filepath'].index(identifier)\n",
    "        else:\n",
    "            raise NameError(f'{identifier} is not a valid input!')\n",
    "        \n",
    "        file_infos = dict()    \n",
    "        for key in self.file_infos.keys():\n",
    "            if len(self.file_infos[key]) > 0:\n",
    "                file_infos[key] = self.file_infos[key][index]\n",
    "         \n",
    "        return file_infos\n",
    "    \n",
    "    \n",
    "    def add_new_key_to_file_infos(self, key: str, values: Optional[List]=None, preferred_empty_value: Union[bool, str, None]=None) -> None:\n",
    "        \"\"\"\n",
    "        Allows us to add a new key-value-pair to the file_infos dict\n",
    "        If values is not passed, a list full of 'preferred_empty_value' that matches the length of file_ids will be created\n",
    "        If values is passed, it has to be a list of the length of file_id\n",
    "        \"\"\"\n",
    "        if key in self.file_infos.keys():\n",
    "            raise ValueError(\"The key you are trying to add is already in file_infos.\")\n",
    "        else:\n",
    "            length = len(self.file_infos['file_id'])\n",
    "            if values == None:\n",
    "                values = [preferred_empty_value] * length\n",
    "                self.file_infos[key] = values\n",
    "            elif type(values) != list:\n",
    "                raise TypeError(\"'values' has to be 'None' or a list that matches the length of file_infos['file_ids']\")\n",
    "            else:\n",
    "                if len(values) == length:\n",
    "                    self.file_infos[key] = values                \n",
    "                else:\n",
    "                    raise ValueError(\"The list of values that you provided does not match the length of file_infos['file_ids']!\")\n",
    "            \n",
    "\n",
    "    def update_file_infos(self, file_id: str, updates: Dict, preferred_empty_value: Union[bool, str, None]=None) -> None: \n",
    "        index = self.file_infos['file_id'].index(file_id)\n",
    "        for key, value in updates.items():\n",
    "            if key not in self.file_infos.keys():\n",
    "                self.add_new_key_to_file_infos(key, preferred_empty_value = preferred_empty_value)\n",
    "            self.file_infos[key][index] = value\n",
    "\n",
    "    \n",
    "    def get_file_ids_to_process(self, input_file_ids: Optional[List], process_tracker_key: str, overwrite: bool) -> List:\n",
    "        if input_file_ids == None:\n",
    "            input_file_ids = self.file_infos['file_id']\n",
    "        if process_tracker_key not in self.file_infos.keys():\n",
    "            self.add_new_key_to_file_infos(process_tracker_key)\n",
    "        if overwrite:\n",
    "            output_file_ids = input_file_ids\n",
    "        else:\n",
    "            process_tracker_status = list()\n",
    "            for file_id in input_file_ids:\n",
    "                index = self.file_infos['file_id'].index(file_id)\n",
    "                process_tracker_status.append(self.file_infos[process_tracker_key][index])\n",
    "            output_file_ids = [elem[0] for elem in zip(input_file_ids, process_tracker_status) if elem[1] == False or elem[1] == None]\n",
    "        return output_file_ids.copy()\n",
    "\n",
    "\n",
    "    def get_batches_of_file_ids(self, input_file_ids: Optional[List], batch_size: int) -> List[List[int]]:\n",
    "        if input_file_ids == None:\n",
    "            input_file_ids = self.file_infos['file_id']        \n",
    "        if len(input_file_ids) % batch_size == 0:\n",
    "            total_batches = int(len(input_file_ids) / batch_size)\n",
    "        else:\n",
    "            total_batches = int(len(input_file_ids) / batch_size) + 1\n",
    "        file_ids_per_batch = list()\n",
    "        for batch in range(total_batches):\n",
    "            if len(input_file_ids) >= batch_size:\n",
    "                sampled_file_ids = random.sample(input_file_ids, batch_size)\n",
    "            else:\n",
    "                sampled_file_ids = input_file_ids.copy()\n",
    "            file_ids_per_batch.append(sampled_file_ids)\n",
    "            for file_id in sampled_file_ids:\n",
    "                input_file_ids.remove(file_id)\n",
    "        return file_ids_per_batch\n",
    "    \n",
    "    \n",
    "    def import_rois_dict(self, file_id: str, rois_dict: Dict) -> None:\n",
    "        if hasattr(self, 'area_rois_for_quantification') == False:\n",
    "            self.area_rois_for_quantification = dict()\n",
    "        self.area_rois_for_quantification[file_id] = rois_dict\n",
    "        \n",
    "\n",
    "    def remove_file_id_from_project(self, file_id: str) -> None:\n",
    "        index = self.file_infos['file_id'].index(file_id)\n",
    "        original_file_id = self.file_infos['original_file_id'][index]\n",
    "        # Move all source files, i.e. microscopy image file and roi file(s):\n",
    "        subdirectories = listdir_nohidden(self.project_root_dir)\n",
    "        self.check_and_create_remaining_directories(root_dir = self.project_root_dir,\n",
    "                                                    subdirectory_attributes = {'removed_files_dir': {'foldername': '08_removed_files', 'key_substring': 'removed_files'}})\n",
    "        for source_data_type in ['microscopy', 'rois']:\n",
    "            source_filepath = self.file_infos[f'{source_data_type}_filepath'][index]\n",
    "            if type(source_filepath) == list:\n",
    "                for filepath in source_filepath:\n",
    "                    shutil.move(filepath.as_posix(), self.removed_files_dir.as_posix())\n",
    "            else:\n",
    "                shutil.move(source_filepath.as_posix(), self.removed_files_dir.as_posix())\n",
    "        # Delete all files that were already generated from findmycells:\n",
    "        for directory in [self.preprocessed_images_dir, \n",
    "                          self.semantic_segmentations_dir, \n",
    "                          self.instance_segmentations_dir, \n",
    "                          self.inspected_area_plots_dir,\n",
    "                          self.inspection_final_label_planes_dir,\n",
    "                          self.inspection_planes_for_quantification]:\n",
    "            filenames = listdir_nohidden(directory)\n",
    "            for filename in filenames:\n",
    "                if filename.startswith(file_id):\n",
    "                    os.remove(directory.joinpath(filename).as_posix())\n",
    "        # Remove from file_infos:\n",
    "        for key in self.file_infos.keys():\n",
    "            self.file_infos[key].pop(index)\n",
    "        # Remove from area_rois_for_quantification:\n",
    "        if file_id in self.area_rois_for_quantification.keys():\n",
    "            self.area_rois_for_quantification.pop(file_id)\n",
    "    \n",
    "    \n",
    "    def save_all(self) -> None:\n",
    "        self.save_csv()\n",
    "        self.save_file_infos()\n",
    "        self.save_project_configs()\n",
    "    \n",
    "    \n",
    "    def save_csv(self) -> None:\n",
    "        df = pd.DataFrame(self.file_infos)\n",
    "        current_columns = list(df.columns)\n",
    "        new_columns = list()\n",
    "        for column_name in current_columns:\n",
    "            if column_name in RENAMING_DICT.keys():\n",
    "                new_columns.append(RENAMING_DICT[column_name])\n",
    "            else: \n",
    "                #print(f\"Warning: {column_name} not yet specified in renaming dictionary\")\n",
    "                new_columns.append(column_name)\n",
    "        df.columns=new_columns\n",
    "        df.to_csv(self.results_dir.joinpath(f'{datetime.now().strftime(\"%Y_%m_%d\")}_findmycells_overview_for_user.csv').as_posix())\n",
    "    \n",
    "    \n",
    "    def save_file_infos(self) -> None:\n",
    "        filepath = self.results_dir.joinpath(f'{datetime.now().strftime(\"%Y_%m_%d\")}_findmycells_project_summary.p').as_posix()\n",
    "        with open(filepath, 'wb') as io:\n",
    "            pickle.dump(self.file_infos, io)\n",
    "            \n",
    "        \n",
    "    def save_project_configs(self) -> None:\n",
    "        project_configs = self.__dict__.copy()\n",
    "        if 'file_infos' in project_configs.keys():\n",
    "            project_configs.pop('file_infos')\n",
    "        if 'only_duplication' in project_configs.keys():\n",
    "            project_configs.pop('only_duplication')  \n",
    "            \n",
    "        filepath = self.results_dir.joinpath(f'{datetime.now().strftime(\"%Y_%m_%d\")}_findmycells_project_configs.p').as_posix()       \n",
    "        with open(filepath, 'wb') as io:\n",
    "            pickle.dump(project_configs, io)\n",
    "    \n",
    "    \n",
    "    def load_all(self) -> None:\n",
    "        result_files = [fname for fname in listdir_nohidden(self.results_dir) if fname.endswith('.p')]\n",
    "        result_files.sort(reverse = True)\n",
    "        if len(result_files) < 2:\n",
    "            raise FileNotFoundError(f\"Couldn´t find the required files in {self.results_dir.as_posix()}\")\n",
    "        \n",
    "        else:\n",
    "            project_summary_filename = [fname for fname in result_files if fname.endswith('project_summary.p')][0]\n",
    "            with open(self.results_dir.joinpath(project_summary_filename).as_posix(), 'rb') as io:\n",
    "                self.file_infos = pickle.load(io)\n",
    "\n",
    "            project_configs_filename = [fname for fname in result_files if fname.endswith('project_configs.p')][0]\n",
    "            with open(self.results_dir.joinpath(project_configs_filename).as_posix(), 'rb') as io:\n",
    "                project_configs = pickle.load(io)\n",
    "            \n",
    "            for key, value in project_configs.items():\n",
    "                if hasattr(self, key) == False:\n",
    "                    setattr(self, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
