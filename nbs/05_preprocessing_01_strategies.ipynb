{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1819fa9d-b390-4250-9c60-1e779f4aeb23",
   "metadata": {},
   "source": [
    "# Preprocessing strategies\n",
    "\n",
    "> This module defines all available preprocessing strategies (= preprocessing options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64252aad-c910-4c4b-bad9-df78816a74a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp preprocessing/strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b30d9b5-d70d-4894-b05a-8465b88db3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from typing import List, Dict, Tuple\n",
    "from shapely.geometry import Polygon\n",
    "import numpy as np\n",
    "from skimage import exposure\n",
    "\n",
    "\n",
    "from findmycells.preprocessing.specs import PreprocessingObject, PreprocessingStrategy\n",
    "from findmycells.database import Database\n",
    "from findmycells.configs import DefaultConfigs, GUIConfigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c02d588-1495-4f60-8cd9-91f068db60c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ca9b14-cec7-4ce5-9f9c-f3d30691130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class CropStitchingArtefactsRGBStrat(PreprocessingStrategy):\n",
    "    \n",
    "    #ToDo:\n",
    "    # - Option to specify whether artefact pixel color is black or white\n",
    "    # - if white: make sure to identify bit type of the image (whether white == 255, 4095, ..)\n",
    "    # - check whether it also works if it´s only a single channel image\n",
    "    \n",
    "    \"\"\"\n",
    "    When you acquire microscopy images that are essentially several individual \n",
    "    images (= tiles) stitched together, you may end up with some artefacts on the\n",
    "    borders of the image as a result from the stitching process. These pixels are\n",
    "    usually either fully black or fully white and can therefore interfere with \n",
    "    other processing strategies that you might want to apply to your images (for \n",
    "    instance, if you´d like to adjust brightness and contrast). This strategy aims\n",
    "    at identifying these pixels that were added to account for some offset between\n",
    "    the individual tiles and eventually remove them. As these artefacts might \n",
    "    interfere with other processing steps, it is recommended to add this (or any other\n",
    "    cropping strategy to get rid of these artefacts) prior to other preprocessing \n",
    "    strategies. \n",
    "    \"\"\"\n",
    "    \n",
    "    @property\n",
    "    def dropdown_option_value_for_gui(self):\n",
    "        return 'Crop stitching artefacts (RGB image version)'\n",
    "    \n",
    "    @property\n",
    "    def default_configs(self):\n",
    "        default_values = {}\n",
    "        valid_types = {}\n",
    "        default_configs = DefaultConfigs(default_values = default_values, valid_types = valid_types)\n",
    "        return default_configs\n",
    "        \n",
    "    @property\n",
    "    def widget_names(self):\n",
    "        return {}\n",
    "\n",
    "    @property\n",
    "    def descriptions(self):\n",
    "        return {}\n",
    "    \n",
    "    @property\n",
    "    def tooltips(self):\n",
    "        return {}\n",
    "    \n",
    "    def run(self, processing_object: PreprocessingObject, strategy_configs: Dict) -> PreprocessingObject:\n",
    "        self.cropping_indices = self._determine_cropping_indices_for_entire_zstack(preprocessing_object = processing_object)\n",
    "        processing_object.preprocessed_image = processing_object.crop_rgb_zstack(zstack = processing_object.preprocessed_image,\n",
    "                                                                                 cropping_indices = self.cropping_indices)\n",
    "        processing_object.preprocessed_rois = processing_object.adjust_rois(rois_dict = processing_object.preprocessed_rois,\n",
    "                                                                            lower_row_cropping_idx = self.cropping_indices['lower_row_cropping_idx'],\n",
    "                                                                            lower_col_cropping_idx = self.cropping_indices['lower_col_cropping_idx'])\n",
    "        return processing_object\n",
    "\n",
    "\n",
    "    def _add_strategy_specific_infos_to_updates(self, updates: Dict) -> Dict:\n",
    "        updates[f'cropping_row_indices'] = (self.cropping_indices['lower_row_cropping_idx'], \n",
    "                                            self.cropping_indices['upper_row_cropping_idx'])\n",
    "        updates[f'cropping_column_indices'] = (self.cropping_indices['lower_col_cropping_idx'], \n",
    "                                               self.cropping_indices['upper_col_cropping_idx']) \n",
    "        return updates\n",
    "\n",
    "\n",
    "    def _determine_cropping_indices_for_entire_zstack(self, preprocessing_object: PreprocessingObject) -> Dict:\n",
    "        for plane_index in range(preprocessing_object.preprocessed_image.shape[0]):\n",
    "            rgb_image_plane = preprocessing_object.preprocessed_image[plane_index]\n",
    "            rows_with_black_px, columns_with_black_px = np.where(np.all(rgb_image_plane == 0, axis = -1))\n",
    "            lower_row_idx, upper_row_idx = self._get_cropping_indices(rows_with_black_px)\n",
    "            lower_col_idx, upper_col_idx = self._get_cropping_indices(columns_with_black_px)  \n",
    "            if plane_index == 0:\n",
    "                min_lower_row_cropping_idx, max_upper_row_cropping_idx = lower_row_idx, upper_row_idx\n",
    "                min_lower_col_cropping_idx, max_upper_col_cropping_idx = lower_col_idx, upper_col_idx\n",
    "            else:\n",
    "                if lower_row_idx > min_lower_row_cropping_idx:\n",
    "                    min_lower_row_cropping_idx = lower_row_idx\n",
    "                if upper_row_idx < max_upper_row_cropping_idx:\n",
    "                    max_upper_row_cropping_idx = upper_row_idx\n",
    "                if lower_col_idx > min_lower_col_cropping_idx:\n",
    "                    min_lower_col_cropping_idx = lower_col_idx\n",
    "                if upper_col_idx < max_upper_col_cropping_idx:\n",
    "                    max_upper_col_cropping_idx = upper_col_idx  \n",
    "        cropping_indices = {'lower_row_cropping_idx': min_lower_row_cropping_idx,\n",
    "                            'upper_row_cropping_idx': max_upper_row_cropping_idx,\n",
    "                            'lower_col_cropping_idx': min_lower_col_cropping_idx,\n",
    "                            'upper_col_cropping_idx': max_upper_col_cropping_idx}\n",
    "        return cropping_indices\n",
    "    \n",
    "    \n",
    "    def _get_cropping_indices(self, a, min_black_px_stretch: int=100) -> Tuple[int, int]:\n",
    "        unique, counts = np.unique(a, return_counts=True)\n",
    "        indices_with_black_pixels = unique[np.where(counts >= min_black_px_stretch)]\n",
    "        if indices_with_black_pixels.shape[0] > 0: \n",
    "            if np.where(np.diff(indices_with_black_pixels) > 1)[0].shape[0] > 0:\n",
    "                lower_cropping_index = indices_with_black_pixels[np.where(np.diff(indices_with_black_pixels) > 1)[0]][0] + 1\n",
    "                upper_cropping_index = indices_with_black_pixels[np.where(np.diff(indices_with_black_pixels) > 1)[0] + 1][0]\n",
    "            else:\n",
    "                if indices_with_black_pixels[0] == 0:\n",
    "                    lower_cropping_index = indices_with_black_pixels[-1]\n",
    "                    upper_cropping_index = a.shape[0] - 1\n",
    "                else:\n",
    "                    lower_cropping_index = 0\n",
    "                    upper_cropping_index = indices_with_black_pixels[0]\n",
    "        else:\n",
    "            lower_cropping_index = 0\n",
    "            upper_cropping_index = a.shape[0] - 1\n",
    "        return lower_cropping_index, upper_cropping_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4962248-c76c-40c0-a74c-5e3d37d85cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class CropToROIsBoundingBoxStrat(PreprocessingStrategy):\n",
    "    \n",
    "    \"\"\"\n",
    "    You might not be interested in analyzing the entire image, but only to quantify\n",
    "    image features of interest in a certain region of your image (or actually also\n",
    "    several regions). Now, chances are that it is possible to find a bounding box that\n",
    "    contains all regions of the image that you are interested in, which is, however,\n",
    "    smaller than the original image. Cropping your original image down to that smaller \n",
    "    size will then significantly reduce computation time, required memory space, and also\n",
    "    required disk space. Therefore, it is highly recommended to add this strategy to your\n",
    "    preprocessing. You can also combine it with additional cropping strategies, like the\n",
    "    one that tries to remove stitching artefacts.\n",
    "    \"\"\"\n",
    "    \n",
    "    @property\n",
    "    def dropdown_option_value_for_gui(self):\n",
    "        return 'Crop image to bounding box enclosing all ROIs'\n",
    "    \n",
    "    @property\n",
    "    def default_configs(self):\n",
    "        default_values = {'pad_size': 100}\n",
    "        valid_types = {'pad_size': [int]}\n",
    "        valid_ranges = {'pad_size': (0, 500, 1)}\n",
    "        default_configs = DefaultConfigs(default_values = default_values, valid_types = valid_types, valid_value_ranges = valid_ranges)\n",
    "        return default_configs\n",
    "        \n",
    "    @property\n",
    "    def widget_names(self):\n",
    "        return {'pad_size': 'IntSlider'}\n",
    "\n",
    "    @property\n",
    "    def descriptions(self):\n",
    "        return {'pad_size': 'Pad size [pixel]:'}\n",
    "    \n",
    "    @property\n",
    "    def tooltips(self):\n",
    "        return {}\n",
    "    \n",
    "    \n",
    "    def run(self, processing_object: PreprocessingObject, strategy_configs: Dict) -> PreprocessingObject:\n",
    "        self.cropping_indices = self._determine_bounding_box(preprocessing_object = processing_object,\n",
    "                                                             pad_size = strategy_configs['pad_size'])\n",
    "        processing_object.preprocessed_image = processing_object.crop_rgb_zstack(zstack = processing_object.preprocessed_image,\n",
    "                                                                                 cropping_indices = self.cropping_indices)\n",
    "        processing_object.preprocessed_rois = processing_object.adjust_rois(rois_dict = processing_object.preprocessed_rois,\n",
    "                                                                            lower_row_cropping_idx = self.cropping_indices['lower_row_cropping_idx'],\n",
    "                                                                            lower_col_cropping_idx = self.cropping_indices['lower_col_cropping_idx'])\n",
    "        return processing_object\n",
    "                                                  \n",
    "    \n",
    "    def _determine_bounding_box(self, preprocessing_object: PreprocessingObject, pad_size: int) -> Dict:\n",
    "        rois_dict = preprocessing_object.preprocessed_rois.copy()\n",
    "        max_row_idx = preprocessing_object.preprocessed_image.shape[1]\n",
    "        max_col_idx = preprocessing_object.preprocessed_image.shape[2]\n",
    "        min_lower_row_cropping_idx, min_lower_col_cropping_idx, max_upper_row_cropping_idx, max_upper_col_cropping_idx = None, None, None, None\n",
    "        for plane_id in rois_dict.keys():\n",
    "            for roi_id in rois_dict[plane_id].keys():\n",
    "                lower_row_idx, lower_col_idx, upper_row_idx, upper_col_idx =  rois_dict[plane_id][roi_id].bounds\n",
    "                if min_lower_row_cropping_idx == None:\n",
    "                    min_lower_row_cropping_idx, max_upper_row_cropping_idx = lower_row_idx, upper_row_idx\n",
    "                    min_lower_col_cropping_idx, max_upper_col_cropping_idx = lower_col_idx, upper_col_idx\n",
    "                else:\n",
    "                    if lower_row_idx < min_lower_row_cropping_idx:\n",
    "                        min_lower_row_cropping_idx = lower_row_idx\n",
    "                    if upper_row_idx > max_upper_row_cropping_idx:\n",
    "                        max_upper_row_cropping_idx = upper_row_idx\n",
    "                    if lower_col_idx < min_lower_col_cropping_idx:\n",
    "                        min_lower_col_cropping_idx = lower_col_idx\n",
    "                    if upper_col_idx > max_upper_col_cropping_idx:\n",
    "                        max_upper_col_cropping_idx = upper_col_idx\n",
    "        if min_lower_row_cropping_idx - pad_size <= 0:\n",
    "            min_lower_row_cropping_idx = 0\n",
    "        else:\n",
    "            min_lower_row_cropping_idx -= pad_size\n",
    "        if min_lower_col_cropping_idx - pad_size <= 0:\n",
    "            min_lower_col_cropping_idx = 0\n",
    "        else:\n",
    "            min_lower_col_cropping_idx -= pad_size\n",
    "        \n",
    "        if max_upper_row_cropping_idx + pad_size >= max_row_idx:\n",
    "            max_upper_row_cropping_idx = max_row_idx\n",
    "        else:\n",
    "            max_upper_row_cropping_idx += pad_size\n",
    "        if max_upper_col_cropping_idx + pad_size >= max_col_idx:\n",
    "            max_upper_col_cropping_idx = max_col_idx\n",
    "        else:\n",
    "            max_upper_col_cropping_idx += pad_size        \n",
    "    \n",
    "        cropping_indices = {'lower_row_cropping_idx': int(min_lower_row_cropping_idx),\n",
    "                            'upper_row_cropping_idx': int(max_upper_row_cropping_idx),\n",
    "                            'lower_col_cropping_idx': int(min_lower_col_cropping_idx),\n",
    "                            'upper_col_cropping_idx': int(max_upper_col_cropping_idx)}\n",
    "        return cropping_indices\n",
    "\n",
    "    \n",
    "    def _add_strategy_specific_infos_to_updates(self, updates: Dict) -> Dict:\n",
    "        updates[f'cropping_row_indices'] = (self.cropping_indices['lower_row_cropping_idx'], \n",
    "                                            self.cropping_indices['upper_row_cropping_idx'])\n",
    "        updates[f'cropping_column_indices_step'] = (self.cropping_indices['lower_col_cropping_idx'], \n",
    "                                                    self.cropping_indices['upper_col_cropping_idx']) \n",
    "        return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba98c42-71e4-4f9f-a9d3-7c09cf0a6c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class ConvertTo8BitStrat(PreprocessingStrategy):\n",
    "    \n",
    "    \"\"\"\n",
    "    This strategy converts your image to an 8-bit format. Adding this strategy is\n",
    "    at the moment mandatory, as all implemented segmentation tools (deepflash2 & cellpose)\n",
    "    require 8-bit as input format. So you actually don´t really have a choice but adding it! :-)\n",
    "    \"\"\"\n",
    "    \n",
    "    @property\n",
    "    def dropdown_option_value_for_gui(self):\n",
    "        return 'Convert into 8-bit format'\n",
    "    \n",
    "    @property\n",
    "    def default_configs(self):\n",
    "        default_values = {}\n",
    "        valid_types = {}\n",
    "        default_configs = DefaultConfigs(default_values = default_values, valid_types = valid_types)\n",
    "        return default_configs\n",
    "        \n",
    "    @property\n",
    "    def widget_names(self):\n",
    "        return {}\n",
    "\n",
    "    @property\n",
    "    def descriptions(self):\n",
    "        return {}\n",
    "    \n",
    "    @property\n",
    "    def tooltips(self):\n",
    "        return {}\n",
    "    \n",
    "    \n",
    "    def run(self, processing_object: PreprocessingObject, strategy_configs: Dict) -> PreprocessingObject:\n",
    "        processing_object.preprocessed_image = self._convert_to_8bit(zstack = processing_object.preprocessed_image)\n",
    "        return processing_object\n",
    "    \n",
    "    \n",
    "    def _convert_to_8bit(self, zstack: np.ndarray) -> np.ndarray:\n",
    "        max_value = zstack.max()\n",
    "        if max_value <= 255:\n",
    "            pass\n",
    "        elif max_value <= 4095:\n",
    "            for plane_index in range(zstack.shape[0]):\n",
    "                zstack[plane_index] = (zstack[plane_index] / 4095 * 255).round(0)\n",
    "        elif max_value <= 65535:\n",
    "            for plane_index in range(zstack.shape[0]):\n",
    "                zstack[plane_index] = (zstack[plane_index] / 65535 * 255).round(0)\n",
    "        if zstack.dtype.name != 'uint8':\n",
    "            zstack = zstack.astype('uint8')\n",
    "        return zstack\n",
    "    \n",
    "\n",
    "    def _add_strategy_specific_infos_to_updates(self, updates: Dict) -> Dict:\n",
    "        return updates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fb6668-de8e-48ca-81b2-c376917a12e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class MaximumIntensityProjectionStrat(PreprocessingStrategy):\n",
    "\n",
    "    \"\"\"\n",
    "    If you acquired your microscopy images as z-stack, you can use this strategy to\n",
    "    project it from a 3D image stack (commonly referred to as 2.5D) into a two\n",
    "    dimensional single plane image. If you select this strategy, the brightest (= maximal)\n",
    "    pixel value from the z-stack will be used in the final 2D projection. Alternatively,\n",
    "    feel free to use the \"Minimum intenstity projection\" strategy, if you´d like to \n",
    "    keep only the darkest (= minimal) value of each pixel.\n",
    "    \"\"\"\n",
    "    \n",
    "    @property\n",
    "    def dropdown_option_value_for_gui(self):\n",
    "        return 'Maximum intensity projection'\n",
    "    \n",
    "    @property\n",
    "    def default_configs(self):\n",
    "        default_values = {}\n",
    "        valid_types = {}\n",
    "        default_configs = DefaultConfigs(default_values = default_values, valid_types = valid_types)\n",
    "        return default_configs\n",
    "        \n",
    "    @property\n",
    "    def widget_names(self):\n",
    "        return {}\n",
    "\n",
    "    @property\n",
    "    def descriptions(self):\n",
    "        return {}\n",
    "    \n",
    "    @property\n",
    "    def tooltips(self):\n",
    "        return {}\n",
    "    \n",
    "    \n",
    "    def run(self, processing_object: PreprocessingObject, strategy_configs: Dict) -> PreprocessingObject:\n",
    "        processing_object.preprocessed_image = self._run_maximum_projection_on_zstack(zstack = processing_object.preprocessed_image)\n",
    "        processing_object.preprocessed_rois = self._remove_all_single_plane_rois(rois_dict = processing_object.preprocessed_rois)\n",
    "        return processing_object\n",
    "    \n",
    "    \n",
    "    def _run_maximum_projection_on_zstack(self, zstack: np.ndarray) -> np.ndarray:\n",
    "        max_projection = np.max(zstack, axis=0)\n",
    "        return max_projection[np.newaxis, :]\n",
    "    \n",
    "    \n",
    "    def _remove_all_single_plane_rois(self, rois_dict: Dict[str, Dict[str, Polygon]]) -> Dict[str, Dict[str, Polygon]]:\n",
    "        if 'all_planes' not in rois_dict.keys():\n",
    "            raise ValueError('For findmycells to be able to perform a MaximumIntensityProjection as preprocessing step, '\n",
    "                             'all ROIs that specify the areas for quantification must apply to all planes of the microscopy image stack.')\n",
    "        for key in rois_dict.keys():\n",
    "            if key != 'all_planes':\n",
    "                rois_dict.pop(key)\n",
    "        return rois_dict\n",
    "    \n",
    "    \n",
    "    def _add_strategy_specific_infos_to_updates(self, updates: Dict) -> Dict:\n",
    "        return updates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef5dcd0-741e-4729-8700-f99efe96863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class MinimumIntensityProjectionStrat(PreprocessingStrategy):\n",
    "    \n",
    "    \"\"\"\n",
    "    If you acquired your microscopy images as z-stack, you can use this strategy to\n",
    "    project it from a 3D image stack (commonly referred to as 2.5D) into a two\n",
    "    dimensional single plane image. If you select this strategy, the darkest (= minimal)\n",
    "    pixel value from the z-stack will be used in the final 2D projection. Alternatively,\n",
    "    feel free to use the \"Maximum intenstity projection\" strategy, if you´d like to \n",
    "    keep only the brightest (= maximal) value of each pixel.\n",
    "    \"\"\"\n",
    "    \n",
    "    @property\n",
    "    def dropdown_option_value_for_gui(self):\n",
    "        return 'Minimum intensity projection'\n",
    "    \n",
    "    @property\n",
    "    def default_configs(self):\n",
    "        default_values = {}\n",
    "        valid_types = {}\n",
    "        default_configs = DefaultConfigs(default_values = default_values, valid_types = valid_types)\n",
    "        return default_configs\n",
    "        \n",
    "    @property\n",
    "    def widget_names(self):\n",
    "        return {}\n",
    "\n",
    "    @property\n",
    "    def descriptions(self):\n",
    "        return {}\n",
    "    \n",
    "    @property\n",
    "    def tooltips(self):\n",
    "        return {}\n",
    "    \n",
    "\n",
    "    def run(self, processing_object: PreprocessingObject, strategy_configs: Dict) -> PreprocessingObject:\n",
    "        processing_object.preprocessed_image = self._run_minimum_projection_on_zstack(zstack = processing_object.preprocessed_image)\n",
    "        processing_object.preprocessed_rois = self._remove_all_single_plane_rois(rois_dict = processing_object.preprocessed_rois)\n",
    "        return processing_object\n",
    "    \n",
    "    \n",
    "    def _run_minimum_projection_on_zstack(self, zstack: np.ndarray) -> np.ndarray:\n",
    "        min_projection = np.min(zstack, axis=0)\n",
    "        return min_projection[np.newaxis, :]\n",
    "    \n",
    "    \n",
    "    def _remove_all_single_plane_rois(self, rois_dict: Dict[str, Dict[str, Polygon]]) -> Dict[str, Dict[str, Polygon]]:\n",
    "        if 'all_planes' not in rois_dict.keys():\n",
    "            raise ValueError('For findmycells to be able to perform a MaximumIntensityProjection as preprocessing step, '\n",
    "                             'all ROIs that specify the areas for quantification must apply to all planes of the microscopy image stack.')\n",
    "        for key in rois_dict.keys():\n",
    "            if key != 'all_planes':\n",
    "                rois_dict.pop(key)\n",
    "        return rois_dict\n",
    "    \n",
    "    \n",
    "    def _add_strategy_specific_infos_to_updates(self, updates: Dict) -> Dict:\n",
    "        return updates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f998dabb-2b69-4ada-a171-f0143a55ff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# ToDo: normalization method that scales the pixels between 0 and 1 for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefa255a-80df-4ca7-a46b-81853e385f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class AdjustBrightnessAndContrastStrat(PreprocessingStrategy):\n",
    "\n",
    "    \"\"\"\n",
    "    This strategy allows you to automatically adjust brightness and contrast\n",
    "    of your images. For this, please specify the percentage of pixels that\n",
    "    you want to be saturated (default: 0.35 % - same as in ImageJ2). This \n",
    "    strategy will then ensure that this specified percentage of pixels will\n",
    "    be fully saturated in all of your images. If you have z-stack images,\n",
    "    you can furthermore also specify whether you´d like to run this operation\n",
    "    on the full z-stack (chose \"globally\"), or on each individual plane of the\n",
    "    z-stack (chose \"individually\"). I would rather recommend using \"globally\" \n",
    "    to keep a somewhat consistent meaning of pixel intensities. And, finally, \n",
    "    if you are anyhow dealing with 2D images (either from the get-go, or since\n",
    "    you applied a maximum or minimum intensity projection strategy prior to\n",
    "    this one - both \"globally\" and \"individually\" will lead to the same result.\n",
    "    \"\"\"\n",
    "    \n",
    "    @property\n",
    "    def dropdown_option_value_for_gui(self):\n",
    "        return 'Adjust brightness and constrast'\n",
    "    \n",
    "    @property\n",
    "    def default_configs(self):\n",
    "        default_values = {'percentage_saturated_pixels': 0.35,\n",
    "                          'channel_adjustment_method': 'globally'}\n",
    "        valid_types = {'percentage_saturated_pixels': [float],\n",
    "                       'channel_adjustment_method': [str]}\n",
    "        valid_ranges = {'percentage_saturated_pixels': (0.05, 49.95, 0.05)}\n",
    "        valid_options = {'channel_adjustment_method': ('globally', 'individually')}\n",
    "        default_configs = DefaultConfigs(default_values = default_values,\n",
    "                                         valid_types = valid_types,\n",
    "                                         valid_value_ranges = valid_ranges,\n",
    "                                         valid_value_options = valid_options)\n",
    "        return default_configs\n",
    "        \n",
    "    @property\n",
    "    def widget_names(self):\n",
    "        return {'percentage_saturated_pixels': 'FloatSlider',\n",
    "                'channel_adjustment_method': 'Dropdown'}\n",
    "\n",
    "    @property\n",
    "    def descriptions(self):\n",
    "        return {'percentage_saturated_pixels': 'Percentage of pixels that will be saturated:',\n",
    "                'channel_adjustment_method': 'Adjust on whole zstack level (= globally) or for each plane (= individually):'}\n",
    "    \n",
    "    @property\n",
    "    def tooltips(self):\n",
    "        return {}\n",
    "\n",
    "    def run(self, processing_object: PreprocessingObject, strategy_configs: Dict) -> PreprocessingObject:\n",
    "        processing_object.preprocessed_image = self._adjust_brightness_and_contrast(zstack = processing_object.preprocessed_image,\n",
    "                                                                                    percentage_saturated_pixels = strategy_configs['percentage_saturated_pixels'], \n",
    "                                                                                    channel_adjustment_method = strategy_configs['channel_adjustment_method'])\n",
    "        return processing_object\n",
    "    \n",
    "    \n",
    "    def _adjust_brightness_and_contrast(self, zstack: np.ndarray, percentage_saturated_pixels: float, channel_adjustment_method: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        percentage_saturated_pixels: float, less than 50.0\n",
    "        channel_adjustment_method: str, one of: 'individually', 'globally'\n",
    "        \"\"\"\n",
    "        adjusted_zstack = zstack.copy()\n",
    "        if percentage_saturated_pixels >= 50:\n",
    "            message_line0 = 'The percentage of saturated pixels cannot be set to values equal to or higher than 50.\\n'\n",
    "            message_line1 = 'Suggested default (also used by the ImageJ Auto Adjust method): 0.35'\n",
    "            error_message = message_line0 + message_line1\n",
    "            raise ValueError(error_message)\n",
    "        if channel_adjustment_method == 'individually':\n",
    "            self.min_max_ranges_per_plane_and_channel = []\n",
    "            for plane_index in range(adjusted_zstack.shape[0]):\n",
    "                min_max_ranges = []\n",
    "                for channel_index in range(adjusted_zstack.shape[3]):\n",
    "                    in_range_min = int(round(np.percentile(adjusted_zstack[plane_index, :, :, channel_index], percentage_saturated_pixels), 0))\n",
    "                    in_range_max = int(round(np.percentile(adjusted_zstack[plane_index, :, :, channel_index], 100 - percentage_saturated_pixels), 0))\n",
    "                    in_range = (in_range_min, in_range_max)\n",
    "                    adjusted_zstack[plane_index, :, :, channel_index] = exposure.rescale_intensity(image = adjusted_zstack[plane_index, :, :, channel_index], in_range = in_range)\n",
    "                    min_max_ranges.append(in_range)\n",
    "                self.min_max_ranges_per_plane_and_channel.append(min_max_ranges)\n",
    "        elif channel_adjustment_method == 'globally':\n",
    "            self.min_max_ranges_per_plane_and_channel = []\n",
    "            for plane_index in range(adjusted_zstack.shape[0]):\n",
    "                in_range_min = int(round(np.percentile(adjusted_zstack[plane_index], percentage_saturated_pixels), 0))\n",
    "                in_range_max = int(round(np.percentile(adjusted_zstack[plane_index], 100 - percentage_saturated_pixels), 0))\n",
    "                in_range = (in_range_min, in_range_max)\n",
    "                adjusted_zstack[plane_index] = exposure.rescale_intensity(image = adjusted_zstack[plane_index], in_range = in_range)\n",
    "                self.min_max_ranges_per_plane_and_channel.append(in_range)\n",
    "        else:\n",
    "            raise NotImplementedError(\"The 'channel_adjustment_method' has to be one of: ['individually', 'globally'].\\n\",\n",
    "                                      \"-->'individually': the range of intensity values wil be calculated and scaled to the \"\n",
    "                                      \"min and max values for each individual channel.\\n\"\n",
    "                                      \"-->'globally': the range of intensity values will be calculated from and scaled to the \"\n",
    "                                      \"global min and max of all channels.\\n\"\n",
    "                                      \"Either way, min and max values will be determined for each image plane individually.\")\n",
    "        return adjusted_zstack.copy()\n",
    "\n",
    "\n",
    "    def _add_strategy_specific_infos_to_updates(self, updates: Dict) -> Dict:\n",
    "        updates['min_max_ranges_per_plane_and_channel'] = self.min_max_ranges_per_plane_and_channel        \n",
    "        return updates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8718c497-98c8-4dd9-b06f-aa26a4f03be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
