{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1819fa9d-b390-4250-9c60-1e779f4aeb23",
   "metadata": {},
   "source": [
    "# Preprocessing strategies\n",
    "\n",
    "> This module defines all available preprocessing strategies (= preprocessing options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64252aad-c910-4c4b-bad9-df78816a74a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp preprocessing/strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b30d9b5-d70d-4894-b05a-8465b88db3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from typing import List, Dict, Tuple\n",
    "from shapely.geometry import Polygon\n",
    "import numpy as np\n",
    "from skimage import exposure\n",
    "\n",
    "\n",
    "from findmycells.preprocessing.specs import PreprocessingObject, PreprocessingStrategy\n",
    "from findmycells.database import Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c02d588-1495-4f60-8cd9-91f068db60c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ca9b14-cec7-4ce5-9f9c-f3d30691130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class CropStitchingArtefactsRGB(PreprocessingStrategy):\n",
    "    \n",
    "    def run(self, processing_object: PreprocessingObject) -> PreprocessingObject:\n",
    "        self.cropping_indices = self._determine_cropping_indices_for_entire_zstack(preprocessing_object = processing_object)\n",
    "        self.step_index = self.determine_correct_step_index(database = processing_object.database, file_id = processing_object.file_id)\n",
    "        processing_object.preprocessed_image = self.crop_rgb_zstack(zstack = processing_object.preprocessed_image)\n",
    "        processing_object.preprocessed_rois = self.adjust_rois(rois_dict = processing_object.preprocessed_rois)\n",
    "        return processing_object\n",
    "\n",
    "\n",
    "    def add_strategy_specific_infos_to_updates(self, updates: Dict) -> Dict:\n",
    "        updates[f'cropping_row_indices_step_{str(self.step_index).zfill(2)}'] = (self.cropping_indices['lower_row_cropping_idx'], \n",
    "                                                                                 self.cropping_indices['upper_row_cropping_idx'])\n",
    "        updates[f'cropping_column_indices_step_{str(self.step_index).zfill(2)}'] = (self.cropping_indices['lower_col_cropping_idx'], \n",
    "                                                                                    self.cropping_indices['upper_col_cropping_idx']) \n",
    "        return updates\n",
    "\n",
    "\n",
    "    def _determine_cropping_indices_for_entire_zstack(self, preprocessing_object: PreprocessingObject) -> Dict:\n",
    "        for plane_index in range(preprocessing_object.preprocessed_image.shape[0]):\n",
    "            rgb_image_plane = preprocessing_object.preprocessed_image[plane_index]\n",
    "            rows_with_black_px, columns_with_black_px = np.where(np.all(rgb_image_plane == 0, axis = -1))\n",
    "            lower_row_idx, upper_row_idx = self._get_cropping_indices(rows_with_black_px)\n",
    "            lower_col_idx, upper_col_idx = self._get_cropping_indices(columns_with_black_px)  \n",
    "            if plane_index == 0:\n",
    "                min_lower_row_cropping_idx, max_upper_row_cropping_idx = lower_row_idx, upper_row_idx\n",
    "                min_lower_col_cropping_idx, max_upper_col_cropping_idx = lower_col_idx, upper_col_idx\n",
    "            else:\n",
    "                if lower_row_idx > min_lower_row_cropping_idx:\n",
    "                    min_lower_row_cropping_idx = lower_row_idx\n",
    "                if upper_row_idx < max_upper_row_cropping_idx:\n",
    "                    max_upper_row_cropping_idx = upper_row_idx\n",
    "                if lower_col_idx > min_lower_col_cropping_idx:\n",
    "                    min_lower_col_cropping_idx = lower_col_idx\n",
    "                if upper_col_idx < max_upper_col_cropping_idx:\n",
    "                    max_upper_col_cropping_idx = upper_col_idx  \n",
    "        cropping_indices = {'lower_row_cropping_idx': min_lower_row_cropping_idx,\n",
    "                            'upper_row_cropping_idx': max_upper_row_cropping_idx,\n",
    "                            'lower_col_cropping_idx': min_lower_col_cropping_idx,\n",
    "                            'upper_col_cropping_idx': max_upper_col_cropping_idx}\n",
    "        return cropping_indices\n",
    "    \n",
    "    \n",
    "    def _get_cropping_indices(self, a, min_black_px_stretch: int=100) -> Tuple[int, int]:\n",
    "        unique, counts = np.unique(a, return_counts=True)\n",
    "        indices_with_black_pixels = unique[np.where(counts >= min_black_px_stretch)]\n",
    "        if indices_with_black_pixels.shape[0] > 0: \n",
    "            if np.where(np.diff(indices_with_black_pixels) > 1)[0].shape[0] > 0:\n",
    "                lower_cropping_index = indices_with_black_pixels[np.where(np.diff(indices_with_black_pixels) > 1)[0]][0] + 1\n",
    "                upper_cropping_index = indices_with_black_pixels[np.where(np.diff(indices_with_black_pixels) > 1)[0] + 1][0]\n",
    "            else:\n",
    "                if indices_with_black_pixels[0] == 0:\n",
    "                    lower_cropping_index = indices_with_black_pixels[-1]\n",
    "                    upper_cropping_index = a.shape[0] - 1\n",
    "                else:\n",
    "                    lower_cropping_index = 0\n",
    "                    upper_cropping_index = indices_with_black_pixels[0]\n",
    "        else:\n",
    "            lower_cropping_index = 0\n",
    "            upper_cropping_index = a.shape[0] - 1\n",
    "        return lower_cropping_index, upper_cropping_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4962248-c76c-40c0-a74c-5e3d37d85cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class CropToROIsBoundingBox(PreprocessingStrategy):\n",
    "    \n",
    "    def run(self, processing_object: PreprocessingObject) -> PreprocessingObject:\n",
    "        self.cropping_indices = self._determine_bounding_box(preprocessing_object = processing_object, pad_size = 100)\n",
    "        self.step_index = self.determine_correct_step_index(database = processing_object.database, file_id = processing_object.file_id)\n",
    "        processing_object.preprocessed_image = self.crop_rgb_zstack(zstack = processing_object.preprocessed_image)\n",
    "        processing_object.preprocessed_rois = self.adjust_rois(rois_dict = processing_object.preprocessed_rois)\n",
    "        return processing_object\n",
    "                                                  \n",
    "    \n",
    "    def _determine_bounding_box(self, preprocessing_object: PreprocessingObject, pad_size: int=100) -> Dict:\n",
    "        rois_dict = preprocessing_object.preprocessed_rois.copy()\n",
    "        max_row_idx = preprocessing_object.preprocessed_image.shape[1]\n",
    "        max_col_idx = preprocessing_object.preprocessed_image.shape[2]\n",
    "        min_lower_row_cropping_idx, min_lower_col_cropping_idx, max_upper_row_cropping_idx, max_upper_col_cropping_idx = None, None, None, None\n",
    "        for plane_id in rois_dict.keys():\n",
    "            for roi_id in rois_dict[plane_id].keys():\n",
    "                lower_row_idx, lower_col_idx, upper_row_idx, upper_col_idx =  rois_dict[plane_id][roi_id].bounds\n",
    "                if min_lower_row_cropping_idx == None:\n",
    "                    min_lower_row_cropping_idx, max_upper_row_cropping_idx = lower_row_idx, upper_row_idx\n",
    "                    min_lower_col_cropping_idx, max_upper_col_cropping_idx = lower_col_idx, upper_col_idx\n",
    "                else:\n",
    "                    if lower_row_idx < min_lower_row_cropping_idx:\n",
    "                        min_lower_row_cropping_idx = lower_row_idx\n",
    "                    if upper_row_idx > max_upper_row_cropping_idx:\n",
    "                        max_upper_row_cropping_idx = upper_row_idx\n",
    "                    if lower_col_idx < min_lower_col_cropping_idx:\n",
    "                        min_lower_col_cropping_idx = lower_col_idx\n",
    "                    if upper_col_idx > max_upper_col_cropping_idx:\n",
    "                        max_upper_col_cropping_idx = upper_col_idx\n",
    "        if min_lower_row_cropping_idx - pad_size <= 0:\n",
    "            min_lower_row_cropping_idx = 0\n",
    "        else:\n",
    "            min_lower_row_cropping_idx -= pad_size\n",
    "        if min_lower_col_cropping_idx - pad_size <= 0:\n",
    "            min_lower_col_cropping_idx = 0\n",
    "        else:\n",
    "            min_lower_col_cropping_idx -= pad_size\n",
    "        \n",
    "        if max_upper_row_cropping_idx + pad_size >= max_row_idx:\n",
    "            max_upper_row_cropping_idx = max_row_idx\n",
    "        else:\n",
    "            max_upper_row_cropping_idx += pad_size\n",
    "        if max_upper_col_cropping_idx + pad_size >= max_col_idx:\n",
    "            max_upper_col_cropping_idx = max_col_idx\n",
    "        else:\n",
    "            max_upper_col_cropping_idx += pad_size        \n",
    "    \n",
    "        cropping_indices = {'lower_row_cropping_idx': int(min_lower_row_cropping_idx),\n",
    "                            'upper_row_cropping_idx': int(max_upper_row_cropping_idx),\n",
    "                            'lower_col_cropping_idx': int(min_lower_col_cropping_idx),\n",
    "                            'upper_col_cropping_idx': int(max_upper_col_cropping_idx)}\n",
    "        return cropping_indices\n",
    "\n",
    "    \n",
    "    def add_strategy_specific_infos_to_updates(self, updates: Dict) -> Dict:\n",
    "        updates[f'cropping_row_indices_step_{str(self.step_index).zfill(2)}'] = (self.cropping_indices['lower_row_cropping_idx'], \n",
    "                                                                                 self.cropping_indices['upper_row_cropping_idx'])\n",
    "        updates[f'cropping_column_indices_step_{str(self.step_index).zfill(2)}'] = (self.cropping_indices['lower_col_cropping_idx'], \n",
    "                                                                                    self.cropping_indices['upper_col_cropping_idx']) \n",
    "        return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba98c42-71e4-4f9f-a9d3-7c09cf0a6c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class ConvertTo8Bit(PreprocessingStrategy):\n",
    "    \n",
    "    def run(self, processing_object: PreprocessingObject) -> PreprocessingObject:\n",
    "        processing_object.preprocessed_image = self._convert_to_8bit(zstack = processing_object.preprocessed_image)\n",
    "        return processing_object\n",
    "    \n",
    "    \n",
    "    def _convert_to_8bit(self, zstack: np.ndarray) -> np.ndarray:\n",
    "        max_value = zstack.max()\n",
    "        if max_value <= 255:\n",
    "            pass\n",
    "        elif max_value <= 4095:\n",
    "            for plane_index in range(zstack.shape[0]):\n",
    "                zstack[plane_index] = (zstack[plane_index] / 4095 * 255).round(0)\n",
    "        elif max_value <= 65535:\n",
    "            for plane_index in range(zstack.shape[0]):\n",
    "                zstack[plane_index] = (zstack[plane_index] / 65535 * 255).round(0)\n",
    "        if zstack.dtype.name != 'uint8':\n",
    "            zstack = zstack.astype('uint8')\n",
    "        return zstack\n",
    "    \n",
    "\n",
    "    def add_strategy_specific_infos_to_updates(self, updates: Dict) -> Dict:\n",
    "        return updates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fb6668-de8e-48ca-81b2-c376917a12e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class MaximumIntensityProjection(PreprocessingStrategy):\n",
    "\n",
    "    \n",
    "    def run(self, processing_object: PreprocessingObject) -> PreprocessingObject:\n",
    "        processing_object.preprocessed_image = self._run_maximum_projection_on_zstack(zstack = processing_object.preprocessed_image)\n",
    "        processing_object.preprocessed_rois = self._remove_all_single_plane_rois(rois_dict = processing_object.preprocessed_rois)\n",
    "        return processing_object\n",
    "    \n",
    "    \n",
    "    def _run_maximum_projection_on_zstack(self, zstack: np.ndarray) -> np.ndarray:\n",
    "        max_projection = np.max(zstack, axis=0)\n",
    "        return max_projection[np.newaxis, :]\n",
    "    \n",
    "    \n",
    "    def _remove_all_single_plane_rois(self, rois_dict: Dict[str, Dict[str, Polygon]]) -> Dict[str, Dict[str, Polygon]]:\n",
    "        if 'all_planes' not in rois_dict.keys():\n",
    "            raise ValueError('For findmycells to be able to perform a MaximumIntensityProjection as preprocessing step, '\n",
    "                             'all ROIs that specify the areas for quantification must apply to all planes of the microscopy image stack.')\n",
    "        for key in rois_dict.keys():\n",
    "            if key != 'all_planes':\n",
    "                rois_dict.pop(key)\n",
    "        return rois_dict\n",
    "    \n",
    "    \n",
    "    def add_strategy_specific_infos_to_updates(self, updates: Dict) -> Dict:\n",
    "        return updates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef5dcd0-741e-4729-8700-f99efe96863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class MinimumIntensityProjection(PreprocessingStrategy):\n",
    "\n",
    "    def run(self, processing_object: PreprocessingObject) -> PreprocessingObject:\n",
    "        processing_object.preprocessed_image = self._run_minimum_projection_on_zstack(zstack = processing_object.preprocessed_image)\n",
    "        processing_object.preprocessed_rois = self._remove_all_single_plane_rois(rois_dict = processing_object.preprocessed_rois)\n",
    "        return processing_object\n",
    "    \n",
    "    \n",
    "    def _run_minimum_projection_on_zstack(self, zstack: np.ndarray) -> np.ndarray:\n",
    "        min_projection = np.min(zstack, axis=0)\n",
    "        return min_projection[np.newaxis, :]\n",
    "    \n",
    "    \n",
    "    def _remove_all_single_plane_rois(self, rois_dict: Dict[str, Dict[str, Polygon]]) -> Dict[str, Dict[str, Polygon]]:\n",
    "        if 'all_planes' not in rois_dict.keys():\n",
    "            raise ValueError('For findmycells to be able to perform a MaximumIntensityProjection as preprocessing step, '\n",
    "                             'all ROIs that specify the areas for quantification must apply to all planes of the microscopy image stack.')\n",
    "        for key in rois_dict.keys():\n",
    "            if key != 'all_planes':\n",
    "                rois_dict.pop(key)\n",
    "        return rois_dict\n",
    "    \n",
    "    \n",
    "    def add_strategy_specific_infos_to_updates(self, updates: Dict) -> Dict:\n",
    "        return updates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefa255a-80df-4ca7-a46b-81853e385f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class AdjustBrightnessAndContrast(PreprocessingStrategy):\n",
    "\n",
    "    def run(self, processing_object: PreprocessingObject) -> PreprocessingObject:\n",
    "        self.percentage_saturated_pixels, self.channel_adjustment_method = self._get_method_specific_attributes(database= processing_object.database)\n",
    "        processing_object.preprocessed_image = self._adjust_brightness_and_contrast(zstack = processing_object.preprocessed_image,\n",
    "                                                                                    percentage_saturated_pixels = self.percentage_saturated_pixels, \n",
    "                                                                                    channel_adjustment_method = self.channel_adjustment_method)\n",
    "        return processing_object\n",
    "\n",
    "\n",
    "    def _get_method_specific_attributes(self, database: Database) -> Tuple[float, str]:\n",
    "        if hasattr(database, 'preprocessing_configs'):\n",
    "            if 'AdjustBrightnessAndContrast' in database.preprocessing_configs.keys():\n",
    "                percentage_saturated_pixels = database.preprocessing_configs['AdjustBrightnessAndContrast']['percentage_saturated_pixels']\n",
    "                channel_adjustment_method = database.preprocessing_configs['AdjustBrightnessAndContrast']['channel_adjustment_method']\n",
    "            else:\n",
    "                percentage_saturated_pixels = 0.0\n",
    "                channel_adjustment_method = 'globally'\n",
    "        else:\n",
    "            percentage_saturated_pixels = 0.0\n",
    "            channel_adjustment_method = 'globally'            \n",
    "        return percentage_saturated_pixels, channel_adjustment_method\n",
    "    \n",
    "    \n",
    "    def _adjust_brightness_and_contrast(self, zstack: np.ndarray, percentage_saturated_pixels: float, channel_adjustment_method: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        percentage_saturated_pixels: float, less than 50.0\n",
    "        channel_adjustment_method: str, one of: 'individually', 'global'\n",
    "        \"\"\"\n",
    "        adjusted_zstack = zstack.copy()\n",
    "        if percentage_saturated_pixels >= 50:\n",
    "            message_line0 = 'The percentage of saturated pixels cannot be set to values equal to or higher than 50.\\n'\n",
    "            message_line1 = 'Suggested default (also used by the ImageJ Auto Adjust method): 0.35'\n",
    "            error_message = message_line0 + message_line1\n",
    "            raise ValueError(error_message)\n",
    "        if channel_adjustment_method == 'individually':\n",
    "            self.min_max_ranges_per_plane_and_channel = list()\n",
    "            for plane_index in range(adjusted_zstack.shape[0]):\n",
    "                min_max_ranges = list()\n",
    "                for channel_index in range(adjusted_zstack.shape[3]):\n",
    "                    in_range_min = int(round(np.percentile(adjusted_zstack[plane_index, :, :, channel_index], percentage_saturated_pixels), 0))\n",
    "                    in_range_max = int(round(np.percentile(adjusted_zstack[plane_index, :, :, channel_index], 100 - percentage_saturated_pixels), 0))\n",
    "                    in_range = (in_range_min, in_range_max)\n",
    "                    adjusted_zstack[plane_index, :, :, channel_index] = exposure.rescale_intensity(image = adjusted_zstack[plane_index, :, :, channel_index], in_range = in_range)\n",
    "                    min_max_ranges.append(in_range)\n",
    "                self.min_max_ranges_per_plane_and_channel.append(min_max_ranges)\n",
    "        elif channel_adjustment_method == 'globally':\n",
    "            self.min_max_ranges_per_plane_and_channel = list()\n",
    "            for plane_index in range(adjusted_zstack.shape[0]):\n",
    "                in_range_min = int(round(np.percentile(adjusted_zstack[plane_index], percentage_saturated_pixels), 0))\n",
    "                in_range_max = int(round(np.percentile(adjusted_zstack[plane_index], 100 - percentage_saturated_pixels), 0))\n",
    "                in_range = (in_range_min, in_range_max)\n",
    "                adjusted_zstack[plane_index] = exposure.rescale_intensity(image = adjusted_zstack[plane_index], in_range = in_range)\n",
    "                self.min_max_ranges_per_plane_and_channel.append(in_range)\n",
    "        else:\n",
    "            raise NotImplementedError(\"The 'channel_adjustment_method' has to be one of: ['individually', 'globally'].\\n\",\n",
    "                                      \"-->'individually': the range of intensity values wil be calculated and scaled to the \"\n",
    "                                      \"min and max values for each individual channel.\\n\"\n",
    "                                      \"-->'globally': the range of intensity values will be calculated from and scaled to the \"\n",
    "                                      \"global min and max of all channels.\\n\"\n",
    "                                      \"Either way, min and max values will be determined for each image plane individually.\")\n",
    "        return adjusted_zstack.copy()\n",
    "\n",
    "\n",
    "    def add_strategy_specific_infos_to_updates(self, updates: Dict) -> Dict:\n",
    "        updates['percentage_saturated_pixels'] = self.percentage_saturated_pixels\n",
    "        updates['channel_adjustment_method'] = self.channel_adjustment_method\n",
    "        updates['min_max_ranges_per_plane_and_channel'] = self.min_max_ranges_per_plane_and_channel        \n",
    "        return updates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8718c497-98c8-4dd9-b06f-aa26a4f03be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
