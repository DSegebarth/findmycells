{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03fe1bab-6f2e-4819-bb37-2b5cb3e63575",
   "metadata": {},
   "source": [
    "# database\n",
    "\n",
    "> Defines a database and file history tracker that stores all relevant information of your *findmycells* project (findmycells.database)\n",
    "\n",
    "- order: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165afb16-1ecd-4410-814e-a616972fa0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363582b0-0e33-4957-84a0-ff00e1e362e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from pathlib import Path, PosixPath\n",
    "from typing import Optional, Dict, List, Union\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from shapely.geometry import Polygon\n",
    "import pickle\n",
    "\n",
    "\n",
    "from findmycells.configs import ProjectConfigs\n",
    "from findmycells import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9f1378-e7dc-415b-9c60-495ce58c4c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cc8803-51d7-4d8e-bf95-34d55eadc57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Database:\n",
    "    \n",
    "    def __init__(self, project_configs: ProjectConfigs) -> None:\n",
    "        self.project_configs = project_configs\n",
    "        self._initialize_project_in_root_dir()\n",
    "        self._create_file_infos_as_attr()\n",
    "        self._create_file_histories_as_attr()\n",
    "        \n",
    "        \n",
    "    def _initialize_project_in_root_dir(self) -> None:\n",
    "        self._initialize_all_top_level_subdirectories()\n",
    "        self._initialize_segmentation_tool_subdirectories()\n",
    "        if len(utils.list_dir_no_hidden(path = self.project_configs.root_dir.joinpath(self.microscopy_images_dir), only_dirs = True)) > 0:\n",
    "            self._assert_valid_microscopy_image_subdir_tree_structure()\n",
    "    \n",
    "          \n",
    "    def _initialize_all_top_level_subdirectories(self) -> None:\n",
    "        self._find_or_create_subdir(target_name = 'microscopy_images', keywords = ['microscopy', 'Microscopy'])\n",
    "        self._find_or_create_subdir(target_name = 'rois_to_analyze', keywords = ['rois', 'ROIs', 'ROIS', 'Rois'])\n",
    "        self._find_or_create_subdir(target_name = 'preprocessed_images', keywords = ['preprocessed', 'Preprocessed', 'pre-processed'])\n",
    "        self._find_or_create_subdir(target_name = 'segmentation_tool', keywords = ['tool', 'Tool'])\n",
    "        self._find_or_create_subdir(target_name = 'semantic_segmentations', keywords = ['semantic', 'Semantic'])\n",
    "        self._find_or_create_subdir(target_name = 'instance_segmentations', keywords = ['instance', 'Instance'])\n",
    "        self._find_or_create_subdir(target_name = 'quantified_segmentations', keywords = ['quantified', 'Quantified', 'quantification', 'Quantification'])\n",
    "        self._find_or_create_subdir(target_name = 'results', keywords = ['results', 'Results'])\n",
    "        self._find_or_create_subdir(target_name = 'inspection', keywords = ['inspect', 'Inspect'])\n",
    "        \n",
    "        \n",
    "    def _find_or_create_subdir(self, target_name: str, keywords: List[str], parent_dir: Optional[Path]=None) -> None:\n",
    "        if parent_dir == None:\n",
    "            parent_dir = self.project_configs.root_dir\n",
    "        subdir_found = False\n",
    "        for path in parent_dir.iterdir():\n",
    "            if path.is_dir():\n",
    "                for key in keywords:\n",
    "                    if key in path.name:\n",
    "                        subdir_found = True\n",
    "                        subdir_path = path\n",
    "                        break\n",
    "        if subdir_found == False:\n",
    "            subdir_path = parent_dir.joinpath(target_name)\n",
    "            subdir_path.mkdir()\n",
    "        setattr(self, f'{target_name}_dir', subdir_path.name)\n",
    "                                               \n",
    "    \n",
    "    def _initialize_segmentation_tool_subdirectories(self) -> None:    \n",
    "        self._find_or_create_subdir(target_name = 'trained_models',\n",
    "                                    keywords = ['models'],\n",
    "                                    parent_dir = self.project_configs.root_dir.joinpath(self.segmentation_tool_dir))\n",
    "        self._find_or_create_subdir(target_name = 'segmentation_tool_temp',\n",
    "                                    keywords = ['tmp', 'temp'],\n",
    "                                    parent_dir = self.project_configs.root_dir.joinpath(self.segmentation_tool_dir))\n",
    "                                               \n",
    "\n",
    "    def _create_file_infos_as_attr(self) -> None:\n",
    "        file_infos = {'file_id': [],\n",
    "                      'original_filename': [],\n",
    "                      'main_group_id': [],\n",
    "                      'subgroup_id': [],\n",
    "                      'subject_id': [],\n",
    "                      'microscopy_filepath': [],\n",
    "                      'microscopy_filetype': [],\n",
    "                      'rois_present': [],\n",
    "                      'rois_filepath': [],\n",
    "                      'rois_filetype': []}\n",
    "        setattr(self, 'file_infos', file_infos)\n",
    "        \n",
    "        \n",
    "    def _create_file_histories_as_attr(self) -> None:\n",
    "        setattr(self, 'file_histories', {})\n",
    "        \n",
    "        \n",
    "    def compute_file_infos(self) -> None:\n",
    "        self._initialize_microscopy_images_subdirectory_tree()\n",
    "        self._add_new_files_to_database()\n",
    "        self._identify_removed_files() # ToDo: not implemented yet\n",
    "        \n",
    "        \n",
    "    def _initialize_microscopy_images_subdirectory_tree(self) -> None:\n",
    "        if len(utils.list_dir_no_hidden(path = self.project_configs.root_dir.joinpath(self.microscopy_images_dir), only_dirs = True)) > 0:\n",
    "            self._assert_valid_microscopy_image_subdir_tree_structure()\n",
    "        else:\n",
    "            self._create_representative_microscopy_image_subdir_tree()\n",
    "            \n",
    "            \n",
    "    def _assert_valid_microscopy_image_subdir_tree_structure(self) -> None:\n",
    "        microscopy_images_dir_path = self.project_configs.root_dir.joinpath(self.microscopy_images_dir)\n",
    "        for main_group_id_subdir_path in utils.list_dir_no_hidden(path = microscopy_images_dir_path, only_dirs = True):\n",
    "            tmp_subgroup_subdir_paths = utils.list_dir_no_hidden(path = main_group_id_subdir_path, only_dirs = True)\n",
    "            subgroup_dirs_missing_message = f'Invalid microscopy images subdir structure! Expected at least one subdirectory in {main_group_id_subdir_path}.'\n",
    "            assert len(tmp_subgroup_subdir_paths) > 0, subgroup_dirs_missing_message\n",
    "            for subgroup_id_subdir_path in tmp_subgroup_subdir_paths:\n",
    "                tmp_subject_subdir_paths = utils.list_dir_no_hidden(path = subgroup_id_subdir_path, only_dirs = True)\n",
    "                subject_subdirs_missing_message = f'Invalid microscopy images subdir structure! Expected at least one subdirectory in {subgroup_id_subdir_path}.'\n",
    "                assert len(tmp_subject_subdir_paths) > 0, subject_subdirs_missing_message\n",
    "                           \n",
    "                            \n",
    "    def _create_representative_microscopy_image_subdir_tree(self) -> None:\n",
    "        for representative_main_group_id in ['wildtype', 'transgenic']:\n",
    "            for representative_subgroup_id in ['week_1', 'week_4']:\n",
    "                if representative_main_group_id == 'wildtype':\n",
    "                    subject_ids = ['mouse_1', 'mouse_2', 'mouse_3']\n",
    "                else:\n",
    "                    subject_ids = ['mouse_4', 'mouse_5', 'mouse_6']\n",
    "                for representative_subject_id in subject_ids:\n",
    "                    self._make_subdir_tree(main_group_id = representative_main_group_id,\n",
    "                                           subgroup_id = representative_subgroup_id,\n",
    "                                           subject_id = representative_subject_id)\n",
    "                            \n",
    "                            \n",
    "    def _make_subdir_tree(self, main_group_id: str, subgroup_id: str, subject_id: str) -> None:\n",
    "        microscopy_images_dir = self.project_configs.root_dir.joinpath(self.microscopy_images_dir)\n",
    "        microscopy_images_dir.joinpath(main_group_id).mkdir(exist_ok = True)\n",
    "        microscopy_images_dir.joinpath(main_group_id, subgroup_id).mkdir(exist_ok = True)\n",
    "        microscopy_images_dir.joinpath(main_group_id, subgroup_id, subject_id).mkdir(exist_ok = True)\n",
    "        \n",
    "        \n",
    "    def _add_new_files_to_database(self) -> None:\n",
    "        microscopy_images_dir_path = self.project_configs.root_dir.joinpath(self.microscopy_images_dir)\n",
    "        for main_group_id_subdir_path in utils.list_dir_no_hidden(path = microscopy_images_dir_path, only_dirs = True):\n",
    "            for subgroup_id_subdir_path in utils.list_dir_no_hidden(path = main_group_id_subdir_path, only_dirs = True):\n",
    "                for subject_id_subdir_path in utils.list_dir_no_hidden(path = subgroup_id_subdir_path, only_dirs = True):\n",
    "                    for filepath in utils.list_dir_no_hidden(path = subject_id_subdir_path, only_files = True):\n",
    "                        new_file_found = self._is_this_a_new_file(filepath = filepath)\n",
    "                        if new_file_found == True:\n",
    "                            file_id = self._get_next_available_file_id()\n",
    "                            self._append_details_to_file_infos(file_id = file_id, filepath = filepath)\n",
    "                            self._add_new_file_history_tracker(file_id = file_id, source_image_filepath = filepath)                                       \n",
    "        \n",
    "    \n",
    "    def _is_this_a_new_file(self, filepath: Path) -> bool:\n",
    "        subject_subdir_path = filepath.parent\n",
    "        subgroup_subdir_path = subject_subdir_path.parent\n",
    "        main_group_id = subgroup_subdir_path.parent.name\n",
    "        original_filename = filepath.name[:filepath.name.find('.')]\n",
    "        file_infos_as_df = pd.DataFrame(data = self.file_infos)\n",
    "        matching_entries_df = file_infos_as_df.loc[(file_infos_as_df['main_group_id'] == main_group_id) &\n",
    "                                                   (file_infos_as_df['subgroup_id'] == subgroup_subdir_path.name) &\n",
    "                                                   (file_infos_as_df['subject_id'] == subject_subdir_path.name) &\n",
    "                                                   (file_infos_as_df['original_filename'] == original_filename)]\n",
    "        matching_entries_count = matching_entries_df.shape[0]\n",
    "        if matching_entries_count == 0:\n",
    "            is_new_file = True\n",
    "        elif matching_entries_count == 1:\n",
    "            is_new_file = False\n",
    "        else:\n",
    "            conflicting_file_ids = matching_entries_df['file_id'].values\n",
    "            raise ValueError((f'Found multiple entries in file_infos for {filepath}.'\n",
    "                              'This is an unexpected behavior and needs to be resolved. Please '\n",
    "                              'Try to remove the file that was '\n",
    "                              'reported above by using the steps described in \"removing files '\n",
    "                              'from a findmycells project\". Since this process requires you '\n",
    "                              'to specify the respective file IDs of the files you´d like to '\n",
    "                              'remove, please find the conflicting IDs below. You have to remove '\n",
    "                              'at least all but one, yet removing all and then adding one correct '\n",
    "                              f'again is recommended.\\n Conflicting file IDs: {conflicting_file_ids}.'))\n",
    "        return is_new_file\n",
    "        \n",
    "        \n",
    "    def _get_next_available_file_id(self) -> str:\n",
    "        if len(self.file_infos['file_id']) > 0:\n",
    "            next_available_file_id = max([int(file_id_str) for file_id_str in self.file_infos['file_id']]) + 1\n",
    "        else:\n",
    "            next_available_file_id = 0\n",
    "        return str(next_available_file_id).zfill(4)\n",
    "                                               \n",
    "    \n",
    "    \n",
    "    def _append_details_to_file_infos(self, file_id: int, filepath: Path) -> None:\n",
    "        subject_subdir_path = filepath.parent\n",
    "        subgroup_subdir_path = subject_subdir_path.parent\n",
    "        main_group_subdir_path = subgroup_subdir_path.parent\n",
    "        self.file_infos['file_id'].append(str(file_id).zfill(4))\n",
    "        original_filename = filepath.name[:filepath.name.find('.')]\n",
    "        self.file_infos['original_filename'].append(original_filename)\n",
    "        self.file_infos['main_group_id'].append(main_group_subdir_path.name)\n",
    "        self.file_infos['subgroup_id'].append(subgroup_subdir_path.name)\n",
    "        self.file_infos['subject_id'].append(subject_subdir_path.name)\n",
    "        self.file_infos['microscopy_filepath'].append(filepath)\n",
    "        self.file_infos['microscopy_filetype'].append(filepath.suffix)\n",
    "        corresponding_dir_in_rois_to_analyze_dir = self.project_configs.root_dir.joinpath(self.rois_to_analyze_dir,\n",
    "                                                                                          main_group_subdir_path.name,\n",
    "                                                                                          subgroup_subdir_path.name,\n",
    "                                                                                          subject_subdir_path.name)\n",
    "        if corresponding_dir_in_rois_to_analyze_dir.is_dir() == False:\n",
    "            self.file_infos['rois_present'].append(False)\n",
    "            self.file_infos['rois_filepath'].append('not_available')\n",
    "            self.file_infos['rois_filetype'].append('not_available')\n",
    "        else:\n",
    "            matching_roi_filepaths = []\n",
    "            for roi_filepath in utils.list_dir_no_hidden(path = corresponding_dir_in_rois_to_analyze_dir, only_files = True):\n",
    "                if roi_filepath.name[:roi_filepath.name.find('.')] == original_filename:\n",
    "                    matching_roi_filepaths.append(roi_filepath)\n",
    "            if len(matching_roi_filepaths) == 0:\n",
    "                self.file_infos['rois_present'].append(False)\n",
    "                self.file_infos['rois_filepath'].append('not_available')\n",
    "                self.file_infos['rois_filetype'].append('not_available')\n",
    "            elif len(matching_roi_filepaths) == 1:\n",
    "                self.file_infos['rois_present'].append(True)\n",
    "                self.file_infos['rois_filepath'].append(matching_roi_filepaths[0])\n",
    "                self.file_infos['rois_filetype'].append(matching_roi_filepaths[0].suffix)\n",
    "            else:\n",
    "                raise ValueError('It seems like you provided more than a single ROI file in '\n",
    "                                 f'{corresponding_dir_in_rois_to_analyze_dir} that matches the microscopy '\n",
    "                                 f'image filename: {original_filename}. If you want to quantify image features '\n",
    "                                 'within multiple ROIs per image, please use RoiSets created with ImageJ as '\n",
    "                                 'described here: [Documentation link not provided yet - please raise an issue on '\n",
    "                                 'https://github.com/Defense-Circuits-Lab/findmycells - thank you!')\n",
    "\n",
    "        \n",
    "    def _add_new_file_history_tracker(self, file_id: int, source_image_filepath: PosixPath) -> None:\n",
    "        file_id = str(file_id).zfill(4)\n",
    "        self.file_histories[file_id] = FileHistory(file_id = file_id, source_image_filepath = source_image_filepath)\n",
    "                                               \n",
    "        \n",
    "    def _identify_removed_files(self) -> None:\n",
    "        file_ids_to_remove = []\n",
    "        for index, microscopy_filepath in enumerate(self.file_infos['microscopy_filepath']):\n",
    "            if microscopy_filepath.is_file() == False:\n",
    "                file_ids_to_remove.append(self.file_infos['file_id'][index])\n",
    "        for file_id in file_ids_to_remove:\n",
    "            self.remove_file_id_from_project(file_id = file_id)\n",
    "                \n",
    "\n",
    "    def get_file_infos(self, file_id: str) -> Dict:\n",
    "        assert file_id in self.file_infos['file_id'], f'The file_id you passed ({file_id}) is not a valid file_id!'\n",
    "        index = self.file_infos['file_id'].index(file_id)\n",
    "        file_infos = {}    \n",
    "        for key, list_of_values in self.file_infos.items():\n",
    "            if len(list_of_values) > 0:\n",
    "                file_infos[key] = list_of_values[index]\n",
    "        return file_infos\n",
    "    \n",
    "    \n",
    "    def update_file_infos(self, file_id: str, updates: Dict, preferred_empty_value: Union[bool, str, None]=None) -> None: \n",
    "        index = self.file_infos['file_id'].index(file_id)\n",
    "        for key, value in updates.items():\n",
    "            if key not in self.file_infos.keys():\n",
    "                self._add_new_key_to_file_infos(key, preferred_empty_value = preferred_empty_value)\n",
    "            elif len(self.file_infos[key]) != len(self.file_infos['file_id']):\n",
    "                if len(self.file_infos[key]) == 0:\n",
    "                    self._add_new_key_to_file_infos(key, preferred_empty_value = preferred_empty_value)\n",
    "                else:\n",
    "                    raise ValueError(f'Length of the list stored under the key \"{key}\" in file_infos '\n",
    "                                     'does not match with the lenght of the list stored under the key \"file_id\".')\n",
    "            self.file_infos[key][index] = value\n",
    "            \n",
    "            \n",
    "    def _add_new_key_to_file_infos(self, key: str, values: Optional[List]=None, preferred_empty_value: Union[bool, str, None]=None) -> None:\n",
    "        \"\"\"\n",
    "        Allows us to add a new key-value-pair to the file_infos dict\n",
    "        If values is not passed, a list full of 'preferred_empty_value' that matches the length of file_ids will be created\n",
    "        If values is passed, it has to be a list of the length of file_id\n",
    "        \"\"\"\n",
    "        assert key not in self.file_infos.keys(), f'The key (= {key}) you are trying to add to file_infos is already in file_infos.'\n",
    "        assert type(values) in [list, type(None)], '\"values\" has to be either None or a list of values with the same length as file_infos[\"file_id\"].'\n",
    "        length = len(self.file_infos['file_id'])\n",
    "        if values == None:\n",
    "            values = [preferred_empty_value] * length\n",
    "            self.file_infos[key] = values\n",
    "        else:\n",
    "            assert len(values) == length, '\"values\" has to be either None or a list of values with the same length as file_infos[\"file_id\"].'\n",
    "            self.file_infos[key] = values\n",
    "            \n",
    "            \n",
    "    def get_file_ids_to_process(self, input_file_ids: Optional[List[str]], processing_step_id: str, overwrite: bool) -> List[str]:\n",
    "        if input_file_ids == None:\n",
    "            input_file_ids = self.file_infos['file_id']\n",
    "        else:\n",
    "            assert type(input_file_ids) == list, '\"input_file_ids\" has to be list of file_ids (given as strings)!'\n",
    "            for elem in input_file_ids:\n",
    "                assert elem in self.file_infos['file_id'], f'\"input_file_ids\" has to be list of file_ids (given as strings)! {elem} not a valid file_id!'\n",
    "        if overwrite == True:\n",
    "            file_ids_to_process = input_file_ids\n",
    "        else:\n",
    "            file_ids_to_process = []\n",
    "            for file_id in input_file_ids:\n",
    "                if processing_step_id not in self.file_histories[file_id].completed_processing_steps.keys():\n",
    "                    file_ids_to_process.append(file_id)\n",
    "                else:\n",
    "                    if self.file_histories[file_id].completed_processing_steps[processing_step_id] == False:\n",
    "                        file_ids_to_process.append(file_id)\n",
    "        return file_ids_to_process\n",
    "\n",
    "\n",
    "    def import_rois_dict(self, file_id: str, rois_dict: Dict[str, Dict[str, Polygon]]) -> None:\n",
    "        if hasattr(self, 'area_rois_for_quantification') == False:\n",
    "            self.area_rois_for_quantification = {}\n",
    "        self.area_rois_for_quantification[file_id] = rois_dict\n",
    "\n",
    "\n",
    "    def remove_file_id_from_project(self, file_id: str) -> None:\n",
    "        self._remove_file_id_from_file_infos(file_id = file_id)\n",
    "        self._remove_file_id_from_file_histories(file_id = file_id)\n",
    "        self._remove_file_id_from_area_rois(file_id = file_id)\n",
    "        self._remove_file_id_from_quantification_results(file_id = file_id)\n",
    "        self._delete_all_associated_files_from_processing_subdirs(file_id = file_id)\n",
    "\n",
    "        \n",
    "    def _remove_file_id_from_file_infos(self, file_id: str) -> None:\n",
    "        index = self.file_infos['file_id'].index(file_id)\n",
    "        for key in self.file_infos.keys():\n",
    "            self.file_infos[key].pop(index)\n",
    "    \n",
    "    \n",
    "    def _remove_file_id_from_file_histories(self, file_id: str) -> None:\n",
    "        if hasattr(self, 'file_histories') == True:\n",
    "            self.file_histories.pop(file_id)\n",
    "       \n",
    "    \n",
    "    def _remove_file_id_from_area_rois(self, file_id: str) -> None:\n",
    "        if hasattr(self, 'area_rois_for_quantification') == True:\n",
    "            if file_id in self.area_rois_for_quantification.keys():\n",
    "                self.area_rois_for_quantification.pop(file_id)\n",
    "        \n",
    "        \n",
    "    def _remove_file_id_from_quantification_results(self, file_id: str) -> None:\n",
    "        if hasattr(self, 'quantification_results') == True:\n",
    "            for quantification_strategy_class_name in self.quantification_results.keys():\n",
    "                if file_id in self.quantification_results[quantification_strategy_class_name].keys():\n",
    "                    self.quantification_results[quantification_strategy_class_name].pop(file_id)\n",
    "                    \n",
    "                    \n",
    "    def _delete_all_associated_files_from_processing_subdirs(self, file_id: str) -> None:\n",
    "        for processing_subdir_attr_id in ['preprocessed_images', 'semantic_segmentations', 'instance_segmentations']:\n",
    "            processing_subdir_name = getattr(self, f'{processing_subdir_attr_id}_dir')\n",
    "            processing_subdir_path = self.project_configs.root_dir.joinpath(processing_subdir_name)\n",
    "            self._delete_matching_files_from_subdir(subdir_path = processing_subdir_path, file_id = file_id)\n",
    "        quantified_segmentations_subdir_path = self.project_configs.root_dir.joinpath(self.quantified_segmentations_dir)\n",
    "        all_area_id_subdir_paths = utils.list_dir_no_hidden(path = quantified_segmentations_subdir_path, only_dirs = True)\n",
    "        for area_id_subdir_path in all_area_id_subdir_paths:\n",
    "            self._delete_matching_files_from_subdir(subdir_path = area_id_subdir_path, file_id = file_id)\n",
    "            \n",
    "            \n",
    "    def _delete_matching_files_from_subdir(self, subdir_path: PosixPath, file_id: str) -> None:\n",
    "        all_filepaths_in_subdir = utils.list_dir_no_hidden(path = subdir_path, only_files = True)\n",
    "        associated_filepaths = [filepath for filepath in all_filepaths_in_subdir if filepath.name.startswith(file_id)]\n",
    "        for filepath_to_delete in associated_filepaths:\n",
    "            filepath_to_delete.delete()\n",
    "\n",
    "            \n",
    "    def export_quantification_results(self,\n",
    "                                      export_as: str='xlsx', # 'xlsx' or 'csv'\n",
    "                                     ) -> None:\n",
    "        assert hasattr(self, 'quantification_results'), 'No quantification results present yet, nothing to export.'\n",
    "        assert export_as in ['xlsx', 'csv'], f'\"export_as\" has to be either \"xlsx\" or \"csv\", not {export_as}.'\n",
    "        quantified_segmentations_dir_path = self.project_configs.root_dir.joinpath(self.quantified_segmentations_dir)\n",
    "        all_quantified_areas = utils.list_dir_no_hidden(path = quantified_segmentations_dir_path, only_dirs = True)\n",
    "        for area_roi_id_dir_path in all_quantified_areas:\n",
    "            area_roi_id = area_roi_id_dir_path.name\n",
    "            file_ids_with_quantification_results_in_this_area = self._get_file_ids_with_quantification_results_in_area_id(area_id = area_roi_id)\n",
    "            results_overview = self._get_results_overview_dataframe_for_export(file_ids_to_include = file_ids_with_quantification_results_in_this_area,\n",
    "                                                                               area_id = area_roi_id)\n",
    "            results_dir_path = self.project_configs.root_dir.joinpath(self.results_dir)\n",
    "            filepath = results_dir_path.joinpath(f'quantified_features_in_{area_roi_id}.{export_as}')\n",
    "            if export_as == 'xlsx':\n",
    "                results_overview.to_excel(filepath)\n",
    "            else:\n",
    "                results_overview.to_csv(filepath)\n",
    "    \n",
    "\n",
    "    def _get_file_ids_with_quantification_results_in_area_id(self, area_id: str) -> List[Optional[str]]:\n",
    "        file_ids_with_quantification_results_in_this_area = []\n",
    "        for file_id, quantification_results_overview in self.quantification_results['CountFeaturesInWholeAreaROIsStrat'].items():\n",
    "            if area_id in quantification_results_overview.keys():\n",
    "                file_ids_with_quantification_results_in_this_area.append(file_id)\n",
    "        return file_ids_with_quantification_results_in_this_area\n",
    "\n",
    "\n",
    "    def _get_results_overview_dataframe_for_export(self, file_ids_to_include: List[Optional[str]], area_id: str) -> pd.DataFrame:\n",
    "        results_overview = {'quantified features': [],\n",
    "                            'group ID': [],\n",
    "                            'subject ID': [],\n",
    "                            'subgroup ID': [],\n",
    "                            'file ID in fmc project': [],\n",
    "                            'microscopy filepath': [],\n",
    "                            'roi filepath': []}\n",
    "        for file_id in file_ids_to_include:\n",
    "            file_id_specific_file_infos = self.get_file_infos(file_id = file_id)\n",
    "            results_overview['quantified features'].append(self.quantification_results['CountFeaturesInWholeAreaROIsStrat'][file_id][area_id])\n",
    "            results_overview['group ID'].append(file_id_specific_file_infos['main_group_id'])\n",
    "            results_overview['subject ID'].append(file_id_specific_file_infos['subject_id'])\n",
    "            results_overview['subgroup ID'].append(file_id_specific_file_infos['subgroup_id'])\n",
    "            results_overview['file ID in fmc project'].append(file_id)\n",
    "            results_overview['microscopy filepath'].append(file_id_specific_file_infos['microscopy_filepath'])\n",
    "            results_overview['roi filepath'].append(file_id_specific_file_infos['rois_filepath'])\n",
    "        return pd.DataFrame(data = results_overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e713707-2894-4f4f-b9d1-0d36f1b7dbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class FileHistory:\n",
    "    \n",
    "    \n",
    "    def __init__(self, file_id: str, source_image_filepath: PosixPath) -> None:\n",
    "        self.file_id = file_id\n",
    "        self.source_image_filepath = source_image_filepath\n",
    "        self.datetime_added = datetime.now()\n",
    "        self._initialize_tracked_history()\n",
    "        self._initialize_tracked_settings()\n",
    "        self._initialize_completed_processing_steps()\n",
    "        \n",
    "        \n",
    "    def _initialize_tracked_history(self) -> None:\n",
    "        empty_history = {'processing_step_id': [],\n",
    "                         'processing_strategy': [],\n",
    "                         'strategy_finished_at': []}\n",
    "        empty_history_df = pd.DataFrame(data = empty_history)\n",
    "        setattr(self, 'tracked_history', empty_history_df)\n",
    "        \n",
    "        \n",
    "    def _initialize_tracked_settings(self) -> None:\n",
    "        setattr(self, 'tracked_settings', {})\n",
    "\n",
    "\n",
    "    def _initialize_completed_processing_steps(self) -> None:\n",
    "        setattr(self, 'completed_processing_steps', {})\n",
    "        \n",
    "        \n",
    "    def track_processing_strat(self, processing_step_id: str, processing_strategy_name: str, strategy_configs: Dict) -> None:\n",
    "        if processing_step_id not in self.completed_processing_steps.keys():\n",
    "            self.completed_processing_steps[processing_step_id] = False\n",
    "        tracked_details = {'processing_step_id': [processing_step_id],\n",
    "                           'processing_strategy': [processing_strategy_name],\n",
    "                           'strategy_finished_at': [datetime.now()]}\n",
    "        tracked_details_df = pd.DataFrame(data = tracked_details)\n",
    "        self.tracked_history = pd.concat([self.tracked_history, tracked_details_df], ignore_index = True)\n",
    "        self.tracked_settings[self.tracked_history.index[-1]] = strategy_configs\n",
    "        \n",
    "    \n",
    "    def mark_processing_step_as_completed(self, processing_step_id: str) -> None:\n",
    "        assert processing_step_id in self.completed_processing_steps.keys(), 'This processing step has not been started yet!'\n",
    "        self.completed_processing_steps[processing_step_id] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9528b8f-39fe-4bc3-9065-0fd0bd69359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
