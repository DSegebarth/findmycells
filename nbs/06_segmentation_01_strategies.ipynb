{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1819fa9d-b390-4250-9c60-1e779f4aeb23",
   "metadata": {},
   "source": [
    "# Segmentation strategies\n",
    "\n",
    "> This module defines all available segmentation strategies (= segmentation options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64252aad-c910-4c4b-bad9-df78816a74a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp segmentation/strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1514733-f151-4505-b9d0-219dd14ab636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from typing import Tuple, List, Dict\n",
    "from pathlib import Path, PosixPath\n",
    "\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tempfile\n",
    "import zarr\n",
    "import os\n",
    "from skimage import measure, segmentation, io\n",
    "\n",
    "from findmycells.segmentation.specs import SegmentationObject, SegmentationStrategy\n",
    "from findmycells.database import Database\n",
    "from findmycells.configs import DefaultConfigs\n",
    "from findmycells import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c02d588-1495-4f60-8cd9-91f068db60c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ca9b14-cec7-4ce5-9f9c-f3d30691130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Deepflash2SemanticSegmentationStrat(SegmentationStrategy):\n",
    "    \n",
    "    \"\"\"\n",
    "    Run semantic segmentation using deepflash2. Requires that you have already an \n",
    "    ensemble of trained models ready to use and to provide the path to the directory\n",
    "    where these models can be found. If you choose to process the files in your \n",
    "    project in smaller batches (which is highly recommended, due to a huge memory\n",
    "    load), make sure to run the segmentations \"strategy-wise\" in the processing \n",
    "    configs below before launching the processing (i.e. keep the box checked).\n",
    "    \"\"\"\n",
    "    \n",
    "    @property\n",
    "    def segmentation_type(self):\n",
    "        return 'semantic'\n",
    "\n",
    "    @property\n",
    "    def dropdown_option_value_for_gui(self):\n",
    "        return 'Semantic segmentation using deepflash2'\n",
    "    \n",
    "    @property\n",
    "    def default_configs(self):\n",
    "        default_values = {'path_to_models': Path(os.getcwd()),\n",
    "                          'compute_stats': False,\n",
    "                          'clear_zarrs_in_sys_temp_dir': True}\n",
    "        valid_types = {'path_to_models': [PosixPath, str],\n",
    "                       'compute_stats': [bool],\n",
    "                       'clear_zarrs_in_sys_temp_dir': [bool]}\n",
    "        valid_options = {'path_to_models': ('')}\n",
    "        default_configs = DefaultConfigs(default_values = default_values, valid_types = valid_types)\n",
    "        return default_configs\n",
    "        \n",
    "    @property\n",
    "    def widget_names(self):\n",
    "        return {'path_to_models': 'FileChooser',\n",
    "                'compute_stats': 'Checkbox',\n",
    "                'clear_zarrs_in_sys_temp_dir': 'Checkbox'}\n",
    "\n",
    "    @property\n",
    "    def descriptions(self):\n",
    "        return {'path_to_models': 'Please select the directory that contains your trained models:',\n",
    "                'compute_stats': '(Re-)compute inference stats (check only if you changed models)',\n",
    "                'clear_zarrs_in_sys_temp_dir': 'Attempt deleting temp. files from systems temp. dir as soon as possible'}\n",
    "    \n",
    "    @property\n",
    "    def tooltips(self):\n",
    "        return {}\n",
    "    \n",
    "    \n",
    "    def run(self, processing_object: SegmentationObject, strategy_configs: Dict) -> SegmentationObject:\n",
    "        processing_object.database = self._add_deepflash2_as_segmentation_tool(database = processing_object.database,\n",
    "                                                                               strategy_configs = strategy_configs)\n",
    "        self._copy_all_files_of_current_batch_to_temp_dir(database = processing_object.database, file_ids_in_batch = processing_object.file_ids)\n",
    "        self._run_semantic_segmentations(database = processing_object.database)\n",
    "        self._move_files(database = processing_object.database)\n",
    "        if strategy_configs['clear_zarrs_in_sys_temp_dir'] == True:\n",
    "            self._delete_temp_files_in_sys_tmp_dir(database = processing_object.database)\n",
    "        return processing_object\n",
    "\n",
    "\n",
    "    def _add_deepflash2_as_segmentation_tool(self, database: Database, strategy_configs: Dict) -> Database:\n",
    "        # ToDo: replace with something that is more consistent with rest of package\n",
    "        if type(strategy_configs['path_to_models']) != PosixPath:\n",
    "            path_to_models = Path(strategy_configs['path_to_models'])\n",
    "        else:\n",
    "            path_to_models = strategy_configs['path_to_models']\n",
    "        if hasattr(database, 'segmentation_tool_configs') == False:\n",
    "            database.segmentation_tool_configs = {'df2': dict()}\n",
    "        elif 'df2' not in database.segmentation_tool_configs.keys():\n",
    "            database.segmentation_tool_configs['df2'] = dict()\n",
    "        database.segmentation_tool_configs['df2']['ensemble_path'] = path_to_models\n",
    "        n_models_found = len([elem for elem in utils.list_dir_no_hidden(path_to_models) if elem.name.endswith('.pth')])\n",
    "        database.segmentation_tool_configs['df2']['n_models'] = n_models_found\n",
    "        if 'stats' not in database.segmentation_tool_configs['df2'].keys():\n",
    "            database.segmentation_tool_configs['df2']['stats'] = self._compute_stats(database = database)\n",
    "        elif strategy_configs['compute_stats'] == True:\n",
    "            database.segmentation_tool_configs['df2']['stats'] = self._compute_stats(database = database)\n",
    "        return database\n",
    "\n",
    "\n",
    "    def _copy_all_files_of_current_batch_to_temp_dir(self, database: Database, file_ids_in_batch: List[str]) -> None:\n",
    "        root_dir_path = database.project_configs.root_dir\n",
    "        segmentation_tool_dir = root_dir_path.joinpath(database.segmentation_tool_dir)\n",
    "        temp_copies_path = segmentation_tool_dir.joinpath('temp_copies_of_preprocessed_images')\n",
    "        for file_id in file_ids_in_batch:\n",
    "            preprocessed_images_dir = root_dir_path.joinpath(database.preprocessed_images_dir)\n",
    "            files_to_segment = [filepath for filepath in utils.list_dir_no_hidden(preprocessed_images_dir) if filepath.name.startswith(file_id)]\n",
    "            if len(files_to_segment) > 0:\n",
    "                if temp_copies_path.is_dir() == False:\n",
    "                    temp_copies_path.mkdir()\n",
    "                for filepath_source in files_to_segment:\n",
    "                    shutil.copy(filepath_source, temp_copies_path)\n",
    "                    \n",
    "                    \n",
    "    def _compute_stats(self, database: Database) -> Tuple:\n",
    "        from deepflash2.learner import EnsembleLearner\n",
    "        preprocessed_images_dir_path = database.project_configs.root_dir.joinpath(database.preprocessed_images_dir)\n",
    "        expected_file_count = sum(database.file_infos['total_planes'])\n",
    "        actual_file_count = len([filepath for filepath in utils.list_dir_no_hidden(preprocessed_images_dir_path) if filepath.name.endswith('.png')])\n",
    "        if actual_file_count != expected_file_count:\n",
    "            raise ValueError('Actual and expected counts of preprocessed images donÂ´t match.')\n",
    "        ensemble_learner = EnsembleLearner(image_dir = preprocessed_images_dir_path, \n",
    "                                           ensemble_path = database.segmentation_tool_configs['df2']['ensemble_path'])\n",
    "        stats = ensemble_learner.stats\n",
    "        del ensemble_learner\n",
    "        return stats\n",
    "\n",
    "\n",
    "    def _run_semantic_segmentations(self, database: Database) -> None:\n",
    "        from deepflash2.learner import EnsembleLearner\n",
    "        segmentation_tool_dir_path = database.project_configs.root_dir.joinpath(database.segmentation_tool_dir)\n",
    "        segmentation_tool_temp_dir_path = segmentation_tool_dir_path.joinpath(database.segmentation_tool_temp_dir)\n",
    "        image_dir = segmentation_tool_dir_path.joinpath('temp_copies_of_preprocessed_images')\n",
    "        ensemble_learner = EnsembleLearner(image_dir = image_dir,\n",
    "                                           ensemble_path = database.segmentation_tool_configs['df2']['ensemble_path'],\n",
    "                                           stats = database.segmentation_tool_configs['df2']['stats'])\n",
    "        ensemble_learner.get_ensemble_results(ensemble_learner.files, \n",
    "                                              zarr_store = segmentation_tool_temp_dir_path,\n",
    "                                              export_dir = segmentation_tool_dir_path,\n",
    "                                              use_tta = True)\n",
    "        del ensemble_learner\n",
    "\n",
    "\n",
    "    def _move_files(self, database: Database) -> None:\n",
    "        semantic_segmentations_target_dir_path = database.project_configs.root_dir.joinpath(database.semantic_segmentations_dir)\n",
    "        segmentation_tool_dir_path = database.project_configs.root_dir.joinpath(database.segmentation_tool_dir)      \n",
    "        current_semantic_masks_dir_path = segmentation_tool_dir_path.joinpath('masks')\n",
    "        for mask_filepath in utils.list_dir_no_hidden(current_semantic_masks_dir_path):\n",
    "            shutil.move(mask_filepath, semantic_segmentations_target_dir_path)\n",
    "        shutil.rmtree(segmentation_tool_dir_path.joinpath('temp_copies_of_preprocessed_images'))\n",
    "\n",
    "\n",
    "    def _delete_temp_files_in_sys_tmp_dir(self, database: Database) -> None:\n",
    "        temp_zarr_paths = [elem for elem in Path(tempfile.gettempdir()).iterdir() if 'zarr' in elem.name]\n",
    "        for dir_path in temp_zarr_paths:\n",
    "            shutil.rmtree(dir_path)       \n",
    "\n",
    "            \n",
    "    def _add_strategy_specific_infos_to_updates(self, updates: Dict) -> Dict:\n",
    "        updates['semantic_segmentations_done'] = True\n",
    "        return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5f850a-b96a-4d0d-b597-f6590aaccbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class LosslessConversionOfDF2SemanticSegToInstanceSegWithCPStrat(SegmentationStrategy):\n",
    "    \n",
    "    @property\n",
    "    def segmentation_type(self):\n",
    "        return 'instance'\n",
    "\n",
    "    @property\n",
    "    def dropdown_option_value_for_gui(self):\n",
    "        return 'Instance segmentation using cellpose'\n",
    "    \n",
    "    @property\n",
    "    def default_configs(self):\n",
    "        default_values = {'net_avg': True,\n",
    "                          'model_type': 'nuclei',\n",
    "                          'diameter': 0.0}\n",
    "        valid_types = {'net_avg': [bool],\n",
    "                       'model_type': [str],\n",
    "                       'diameter': [float]}\n",
    "        valid_ranges = {'diameter': (0.0, 1_000.0, 0.1)}\n",
    "        valid_options = {'model_type': ('nuclei', 'cyto')}\n",
    "        default_configs = DefaultConfigs(default_values = default_values,\n",
    "                                         valid_types = valid_types,\n",
    "                                         valid_value_ranges = valid_ranges,\n",
    "                                         valid_value_options = valid_options)\n",
    "        return default_configs\n",
    "        \n",
    "    @property\n",
    "    def widget_names(self):\n",
    "        return {'net_avg': 'Checkbox',\n",
    "                'model_type': 'Dropdown',\n",
    "                'diameter': 'FloatSlider'}\n",
    "\n",
    "    @property\n",
    "    def descriptions(self):\n",
    "        return {'net_avg': 'Use average result of multiple attempts (recommended)',\n",
    "                'model_type': 'Select the cellpose model type to use',\n",
    "                'diameter': 'Diameter of a single feature [px] (select 0 to compute automatically)'}\n",
    "    \n",
    "    @property\n",
    "    def tooltips(self):\n",
    "        return {}\n",
    "    \n",
    "    \n",
    "    def run(self, processing_object: SegmentationObject, strategy_configs: Dict) -> SegmentationObject:\n",
    "        self._assert_all_semantic_segmentations_are_done()\n",
    "        processing_object.database = self._add_cellpose_as_segmentation_tool(database = processing_object.database, strategy_configs = strategy_configs)        \n",
    "        self._run_instance_segmentations(segmentation_object = processing_object)\n",
    "        return processing_object\n",
    "        \n",
    "        \n",
    "    def _assert_all_semantic_segmentations_are_done(self) -> None:\n",
    "        #if not all(database.file_infos['semantic_segmentations_done']):\n",
    "            #raise ValueError('Before you can proceed with instance segmentations, you have to finish semantic segmentation of all files first!')    \n",
    "        # ToDo: Implementation with new file history pending!\n",
    "        pass\n",
    "    \n",
    "    def _add_cellpose_as_segmentation_tool(self, database: Database, strategy_configs: Dict) -> Database:\n",
    "        semantic_masks_dir = database.project_configs.root_dir.joinpath(database.semantic_segmentations_dir)\n",
    "        if hasattr(database, 'segmentation_tool_configs') == False:\n",
    "            database.segmentation_tool_configs = {'cp': dict()}\n",
    "        elif 'cp' not in database.segmentation_tool_configs.keys():\n",
    "            database.segmentation_tool_configs['cp'] = dict()\n",
    "        database.segmentation_tool_configs['cp']['net_avg'] = True\n",
    "        database.segmentation_tool_configs['cp']['model_type'] = 'nuclei'\n",
    "        if 'diameter' not in database.segmentation_tool_configs['cp'].keys():\n",
    "            database.segmentation_tool_configs['cp']['diameter'] = self._compute_cellpose_diameter(semantic_masks_dir = semantic_masks_dir)\n",
    "        elif strategy_configs['diameter'] == 0:\n",
    "            database.segmentation_tool_configs['cp']['diameter'] = self._compute_cellpose_diameter(semantic_masks_dir = semantic_masks_dir)        \n",
    "        return database\n",
    "\n",
    "\n",
    "    def _compute_cellpose_diameter(self, semantic_masks_dir: PosixPath) -> float:\n",
    "        all_median_equivalent_diameters = []\n",
    "        for mask_filepath in semantic_masks_dir.iterdir():\n",
    "            if mask_filepath.name.endswith('.png'):\n",
    "                mask = io.imread(mask_filepath)\n",
    "                median_equivalent_diameter = self._calculate_median_equivalent_diameter_of_features_in_mask(segmentation_mask = mask)\n",
    "                all_median_equivalent_diameters.append(median_equivalent_diameter)\n",
    "        if len(all_median_equivalent_diameters) > 0:\n",
    "            cellpose_diameter = np.nanmedian(all_median_equivalent_diameters)\n",
    "            if np.isnan(cellpose_diameter):\n",
    "                raise ValueError('Findmycells could not determine what diameter to use for the Cellpose instance segmentations (diameter = np.NaN). '\n",
    "                                 'This could happen if you a) have no semantic segmentation masks in the corresponding directory, or '\n",
    "                                 'b) there were no features detected during the semantic segmentation process! Please check your semantic segmentations.')\n",
    "        else:\n",
    "            raise ValueError('Cellpose diameter could not be calculated, as there were no semantic segmentation masks found. Please check your semantic segmentation masks!')\n",
    "        return cellpose_diameter\n",
    "            \n",
    "\n",
    "    def _calculate_median_equivalent_diameter_of_features_in_mask(self, segmentation_mask: np.ndarray) -> float:\n",
    "        labeled_mask = measure.label(segmentation_mask)\n",
    "        unique_label_ids, pixel_counts_per_label_id = np.unique(labeled_mask, return_counts=True)\n",
    "        unique_label_ids = list(unique_label_ids)\n",
    "        if 0 in unique_label_ids:\n",
    "            background_label_index = unique_label_ids.index(0)\n",
    "            pixel_counts_per_label_id = np.delete(pixel_counts_per_label_id, background_label_index)\n",
    "        if pixel_counts_per_label_id.shape[0] > 0:\n",
    "            equivalent_diameters = []\n",
    "            for area_in_pixels in pixel_counts_per_label_id:\n",
    "                equivalent_diameters.append(((area_in_pixels / np.pi)**0.5) * 2)\n",
    "            median_equivalent_diameter = np.median(equivalent_diameters)\n",
    "        else:\n",
    "            median_equivalent_diameter = np.nan\n",
    "        return median_equivalent_diameter\n",
    "\n",
    "\n",
    "    def _run_instance_segmentations(self, segmentation_object: SegmentationObject):\n",
    "        database = segmentation_object.database\n",
    "        segmentation_tool_dir_path = database.project_configs.root_dir.joinpath(database.segmentation_tool_dir)\n",
    "        segmentation_tool_temp_dir_path = segmentation_tool_dir_path.joinpath(database.segmentation_tool_temp_dir)\n",
    "        print(segmentation_tool_temp_dir_path)\n",
    "        zarr_group = zarr.open(segmentation_tool_temp_dir_path, mode='r')\n",
    "        for image_filename in zarr_group['/smx'].__iter__():\n",
    "            file_id = image_filename[:4]\n",
    "            if file_id in segmentation_object.file_ids:\n",
    "                df2_softmax = zarr_group[f'/smx/{image_filename}'][..., 1]\n",
    "                df2_pred = np.zeros_like(df2_softmax)\n",
    "                df2_pred[np.where(df2_softmax >= 0.5)] = 1\n",
    "                # check if there was any feature predicted - if not, there is no need to run cellpose\n",
    "                if df2_pred.max() == 1:\n",
    "                    cp_mask = self._compute_cellpose_mask(df2_softmax = df2_softmax, \n",
    "                                                         model_type = database.segmentation_tool_configs['cp']['model_type'],\n",
    "                                                         net_avg = database.segmentation_tool_configs['cp']['net_avg'],\n",
    "                                                         diameter = database.segmentation_tool_configs['cp']['diameter'])            \n",
    "                    instance_mask = self._lossless_conversion_of_df2_semantic_to_instance_seg_using_cp(df2_pred = df2_pred, cp_mask = cp_mask)\n",
    "                else: \n",
    "                    instance_mask = df2_pred.copy()\n",
    "                instance_mask = instance_mask.astype('uint16')\n",
    "                filepath = database.project_configs.root_dir.joinpath(database.instance_segmentations_dir, image_filename)\n",
    "                io.imsave(filepath, instance_mask, check_contrast=False)\n",
    "\n",
    "\n",
    "    def _compute_cellpose_mask(self, df2_softmax: np.ndarray, model_type: str, net_avg: bool, diameter: int) -> np.ndarray:\n",
    "        from torch.cuda import empty_cache\n",
    "        from cellpose import models\n",
    "        empty_cache()\n",
    "        model = models.Cellpose(gpu = True, model_type = model_type)\n",
    "        cp_mask, _, _, _ = model.eval(df2_softmax, net_avg = net_avg, augment = True, normalize = False, diameter = diameter, channels = [0,0])\n",
    "        empty_cache()\n",
    "        return cp_mask\n",
    "\n",
    "\n",
    "    def _lossless_conversion_of_df2_semantic_to_instance_seg_using_cp(self, df2_pred: np.ndarray, cp_mask: np.ndarray) -> np.ndarray:\n",
    "        lossless_converted_mask = np.zeros_like(df2_pred)\n",
    "        labeled_df2_pred = measure.label(df2_pred)\n",
    "        unique_df2_labels = list(np.unique(labeled_df2_pred))\n",
    "        unique_df2_labels.remove(0)\n",
    "        for original_df2_label in unique_df2_labels:\n",
    "            black_pixels_present = self._check_if_df2_label_is_fully_covered_in_cp_mask(df2_pred = labeled_df2_pred,\n",
    "                                                                                       df2_label_id = original_df2_label,\n",
    "                                                                                       cp_mask = cp_mask)                                                        \n",
    "            if black_pixels_present:\n",
    "                lossless_converted_mask = self._fill_entire_df2_label_area_with_instance_label(df2_pred = labeled_df2_pred, \n",
    "                                                                                              df2_label_id = original_df2_label, \n",
    "                                                                                              cp_mask = cp_mask,\n",
    "                                                                                              converted_mask = lossless_converted_mask)\n",
    "            else:\n",
    "                cp_labels_within_df2_label = np.unique(cp_mask[np.where(labeled_df2_pred == original_df2_label)])\n",
    "                tmp_cp_mask = cp_mask.copy()\n",
    "                tmp_cp_mask[np.where(labeled_df2_pred != original_df2_label)] = 0\n",
    "                for cp_label_id in cp_labels_within_df2_label:\n",
    "                    next_label_id = lossless_converted_mask.max() + 1\n",
    "                    lossless_converted_mask[np.where(tmp_cp_mask == cp_label_id)] = next_label_id\n",
    "        return lossless_converted_mask\n",
    "\n",
    "\n",
    "    def _check_if_df2_label_is_fully_covered_in_cp_mask(self, df2_pred: np.ndarray, df2_label_id: int, cp_mask: np.ndarray) -> bool:\n",
    "        cp_labels_within_df2_label = np.unique(cp_mask[np.where(df2_pred == df2_label_id)])\n",
    "        if 0 in cp_labels_within_df2_label:\n",
    "            black_pixels_present = True\n",
    "        else:\n",
    "            black_pixels_present = False\n",
    "        return black_pixels_present\n",
    "\n",
    "\n",
    "    def _fill_entire_df2_label_area_with_instance_label(self, df2_pred: np.ndarray, df2_label_id: int, cp_mask: np.ndarray, converted_mask: np.ndarray) -> np.ndarray:\n",
    "        cp_labels_within_df2_label = list(np.unique(cp_mask[np.where(df2_pred == df2_label_id)]))\n",
    "        cp_labels_within_df2_label.remove(0)\n",
    "        if len(cp_labels_within_df2_label) > 0:\n",
    "            expanded_cp_mask = cp_mask.copy()\n",
    "            expanded_cp_mask[np.where(df2_pred != df2_label_id)] = 0\n",
    "            black_pixels_present, expansion_distance = True, 0\n",
    "            while black_pixels_present:\n",
    "                expansion_distance += 500\n",
    "                expanded_cp_mask = segmentation.expand_labels(expanded_cp_mask, distance = expansion_distance)\n",
    "                black_pixels_present = self._check_if_df2_label_is_fully_covered_in_cp_mask(df2_pred = df2_pred,\n",
    "                                                                                           df2_label_id = df2_label_id,\n",
    "                                                                                           cp_mask = expanded_cp_mask)\n",
    "            # remove all overflow pixels\n",
    "            expanded_cp_mask[np.where(df2_pred != df2_label_id)] = 0\n",
    "            for cp_label_id in cp_labels_within_df2_label:\n",
    "                next_label_id = converted_mask.max() + 1\n",
    "                converted_mask[np.where(expanded_cp_mask == cp_label_id)] = next_label_id\n",
    "        else:\n",
    "            next_label_id = converted_mask.max() + 1\n",
    "            converted_mask[np.where(df2_pred == df2_label_id)] = next_label_id        \n",
    "        return converted_mask\n",
    "\n",
    "    def _add_strategy_specific_infos_to_updates(self, updates: Dict) -> Dict:\n",
    "        updates['instance_segmentations_done'] = True\n",
    "        return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8718c497-98c8-4dd9-b06f-aa26a4f03be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
